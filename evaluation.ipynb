{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "from trulens.core import TruSession, Feedback, Select\n",
    "from trulens.apps.custom import TruCustomApp, instrument\n",
    "from trulens.providers.cortex import Cortex\n",
    "\n",
    "from snowflake.core import Root\n",
    "from snowflake.cortex import Complete\n",
    "\n",
    "from utility.data_models import Video\n",
    "\n",
    "snow_conn = st.connection(\"snowflake\")\n",
    "snow_session = snow_conn.session()\n",
    "tru_session = TruSession()\n",
    "tru_session.reset_database()\n",
    "\n",
    "course_name = \"machine_learning_for_health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedbacks(session):\n",
    "    provider = Cortex(session, model_name=\"mistral-large2\")\n",
    "\n",
    "    f_groundedness = (\n",
    "        Feedback(\n",
    "            provider.groundedness_measure_with_cot_reasons,\n",
    "            name=\"Groundedness\",\n",
    "            provider=provider,\n",
    "        )\n",
    "        .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "        .on_output()\n",
    "    )\n",
    "\n",
    "    f_answer_relevance = (\n",
    "        Feedback(\n",
    "            provider.relevance_with_cot_reasons,\n",
    "            name=\"Answer Relevance\",\n",
    "            provider=provider,\n",
    "        )\n",
    "        .on_input()\n",
    "        .on_output()\n",
    "    )\n",
    "\n",
    "    f_context_relevance = (\n",
    "        Feedback(\n",
    "            provider.context_relevance_with_cot_reasons,\n",
    "            name=\"Context Relevance\",\n",
    "            provider=provider,\n",
    "        )\n",
    "        .on_input()\n",
    "        .on(Select.RecordCalls.retrieve.rets[:])\n",
    "        .aggregate(np.mean)\n",
    "    )\n",
    "\n",
    "    return [f_groundedness, f_answer_relevance, f_context_relevance]\n",
    "\n",
    "feedbacks = get_feedbacks(snow_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRetriever:\n",
    "\n",
    "    def __init__(self, session, service_name: str, model_name: str = \"mistral-large2\"):\n",
    "\n",
    "        root = Root(session)\n",
    "        db, schema = (\n",
    "            session.get_current_database(),\n",
    "            session.get_current_schema(),\n",
    "        )\n",
    "\n",
    "        self.service = (\n",
    "            root.databases[db].schemas[schema].cortex_search_services[service_name]\n",
    "        )\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.system_prompt = \"\"\"\n",
    "        You are a knowledgeable teaching assistant helping university students learn from their lecture materials. \n",
    "        Use the provided context from lecture videos and notes to answer questions. If the context doesn't contain \n",
    "        relevant information, simply state that you don't know. Keep responses friendly but concise, using no more \n",
    "        than three sentences. For general greetings or casual conversation, respond naturally without needing context.\n",
    "        \"\"\"\n",
    "\n",
    "    @instrument\n",
    "    def complete(self, query: str, context: list[str]) -> str:\n",
    "        \"\"\"\n",
    "        Get a completion from the Snowflake Cortex model.\n",
    "        \"\"\"\n",
    "        context_str = \"\\n\".join(context)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context: {context_str}\\nQuestion: {query}\\nAnswer:\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        return Complete(model=self.model_name, prompt=messages)\n",
    "\n",
    "    @instrument\n",
    "    def retrieve(self, query: str, limit: int = 3) -> list[str]:\n",
    "        \"\"\"\n",
    "        Retrieve documents from cortex search service.\n",
    "        \"\"\"\n",
    "        documents = self.service.search(query, columns=[\"text\"], limit=limit)\n",
    "        return [doc[\"text\"] for doc in documents.results]\n",
    "\n",
    "    @instrument\n",
    "    def search(self, query: str, n_context: int = 3) -> str:\n",
    "        context = self.retrieve(query, n_context)\n",
    "        answer = self.complete(query, context)\n",
    "        return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions_for_lecture():\n",
    "    questions = {}\n",
    "    for file in os.listdir(\"qna_for_eval\"):\n",
    "        df = pd.read_csv(os.path.join(\"qna_for_eval\", file))\n",
    "        lecture_name = os.path.splitext(file)[0]\n",
    "        questions[lecture_name] = df[\"Question\"].tolist()\n",
    "    return questions\n",
    "\n",
    "questions_for_lecture = get_questions_for_lecture()\n",
    "eval_questions = []\n",
    "for questions in questions_for_lecture.values():\n",
    "    eval_questions.extend(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for content_type in [\"Video\", \"PDF\"]:\n",
    "    print(f\"\\nEvaluating {content_type} content\")\n",
    "    table_name = f\"{course_name}_{content_type.lower()}\"\n",
    "    retriever = ContentRetriever(snow_session, table_name)\n",
    "    tru_app = TruCustomApp(\n",
    "        retriever,\n",
    "        app_name=f\"{content_type} Retriever\",\n",
    "        app_version=\"base\",\n",
    "        feedbacks=feedbacks,\n",
    "    )\n",
    "\n",
    "    with tru_app as recording:\n",
    "        for question in eval_questions:\n",
    "            response = retriever.search(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does metadata filtering help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRetrieverWithFilter(ContentRetriever):\n",
    "    @instrument\n",
    "    def search(self, query: str, lecture_name: str) -> str:\n",
    "        context = self.retrieve(query, lecture_name)\n",
    "        answer = self.complete(query, context)\n",
    "        return answer\n",
    "\n",
    "    @instrument\n",
    "    def retrieve(self, query: str, lecture_name: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Retrieve documents from cortex search service.\n",
    "        \"\"\"\n",
    "        filter_query = {\"@eq\": {\"lecture_name\": lecture_name}}\n",
    "        documents = self.service.search(query, columns=[\"text\"], limit=3, filter=filter_query)\n",
    "        return [doc[\"text\"] for doc in documents.results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for content_type in [\"Video\", \"PDF\"]:\n",
    "    print(f\"\\nEvaluating {content_type} content\")\n",
    "    table_name = f\"{course_name}_{content_type.lower()}\"\n",
    "    retriever = ContentRetrieverWithFilter(snow_session, table_name)\n",
    "    tru_app = TruCustomApp(\n",
    "        retriever,\n",
    "        app_name=f\"{content_type} Retriever\",\n",
    "        app_version=\"metadata filter\",\n",
    "        feedbacks=feedbacks,\n",
    "    )\n",
    "\n",
    "    with tru_app as recording:\n",
    "        for lecture_name, questions in questions_for_lecture.items():\n",
    "            for question in questions:\n",
    "                response = retriever.search(question, lecture_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Chunk Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query: str, data=None):\n",
    "    cursor = snow_conn.cursor()\n",
    "    try:\n",
    "        if data:\n",
    "            cursor.executemany(query, data)\n",
    "        else:\n",
    "            cursor.execute(query)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error executing query: {str(e)}\")\n",
    "    finally:\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(table_name):\n",
    "    print(f\"Creating table: {table_name}\")\n",
    "    table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        text STRING,\n",
    "        start_time INTEGER,\n",
    "        end_time INTEGER,\n",
    "        file_name STRING,\n",
    "        lecture_name STRING\n",
    "    )\n",
    "    \"\"\"\n",
    "    run_query(table_query)\n",
    "\n",
    "def insert_data(table_name, data):\n",
    "    data_query = f\"\"\"\n",
    "    INSERT INTO {table_name} (text, start_time, end_time, file_name, lecture_name)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    run_query(data_query, data)\n",
    "\n",
    "def create_search_service(table_name):\n",
    "    service_query = f\"\"\"\n",
    "    CREATE CORTEX SEARCH SERVICE IF NOT EXISTS {table_name}\n",
    "    ON text\n",
    "    ATTRIBUTES lecture_name\n",
    "    warehouse = COMPUTE_WH\n",
    "    TARGET_LAG = '1 minute'\n",
    "        as (\n",
    "            SELECT *\n",
    "            FROM {table_name}\n",
    "        );\n",
    "        \"\"\"\n",
    "    run_query(service_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_transcripts = {}\n",
    "course_path = f\"courses/{course_name}\"\n",
    "chunk_configs = [(30, 5), (60, 10), (120, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk_size, overlap in chunk_configs:\n",
    "    print(f\"\\nProcessing chunk size: {chunk_size}s with overlap: {overlap}s\")\n",
    "    table_name = f\"{course_name}_video_{chunk_size}_{overlap}\"\n",
    "    create_table(table_name)\n",
    "\n",
    "    for lecture in os.listdir(course_path):\n",
    "        print(f\"\\nProcessing lecture: {lecture}\")\n",
    "        lecture_path = os.path.join(course_path, lecture)\n",
    "        video_file = [\n",
    "            file_name\n",
    "            for file_name in os.listdir(lecture_path)\n",
    "            if file_name.endswith(\".mp4\")\n",
    "        ]\n",
    "        video_path = os.path.join(lecture_path, video_file[0])\n",
    "\n",
    "        video = Video(file_path=video_path)\n",
    "\n",
    "        if lecture not in video_transcripts.keys():\n",
    "            print(f\"Transcribing video for lecture: {lecture}\")\n",
    "            _, _, transcript = video._transcribe()\n",
    "            video_transcripts[lecture] = transcript\n",
    "        else:\n",
    "            print(f\"Using cached transcript for lecture: {lecture}\")\n",
    "            transcript = video_transcripts[lecture]\n",
    "\n",
    "        print(\"Chunking transcript...\")\n",
    "        chunks = video._chunk_text(transcript, chunk_size, overlap)\n",
    "        print(f\"Generated {len(chunks)} chunks\")\n",
    "\n",
    "        data = [\n",
    "            (chunk.text, chunk.start, chunk.end, video_file[0], lecture)\n",
    "            for chunk in chunks\n",
    "        ]\n",
    "        print(f\"Inserting chunks into table: {table_name}\")\n",
    "        insert_data(table_name, data)\n",
    "    \n",
    "    print(f\"\\nCreating search service for table: {table_name}\")\n",
    "    create_search_service(table_name)\n",
    "    print(\"Search service created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Chunk Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk_size, overlap in chunk_configs:\n",
    "    print(f\"\\nEvaluating chunk size: {chunk_size}s with overlap: {overlap}s\")\n",
    "    table_name = f\"{course_name}_video_{chunk_size}_{overlap}\"\n",
    "    retriever = ContentRetriever(snow_session, table_name)\n",
    "    tru_app = TruCustomApp(\n",
    "        retriever,\n",
    "        app_name=\"Video Retriever\",\n",
    "        app_version=f's_{chunk_size}_o_{overlap}',\n",
    "        feedbacks=feedbacks,\n",
    "    )\n",
    "\n",
    "    with tru_app as recording:\n",
    "        for question in eval_questions:\n",
    "            response = retriever.search(question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
