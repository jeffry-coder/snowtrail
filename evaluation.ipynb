{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "from trulens.core import TruSession, Feedback, Select\n",
    "from trulens.apps.custom import TruCustomApp, instrument\n",
    "from trulens.providers.cortex import Cortex\n",
    "\n",
    "from snowflake.core import Root\n",
    "from snowflake.cortex import Complete\n",
    "\n",
    "from utility.data_models import Video\n",
    "\n",
    "snow_conn = st.connection(\"snowflake\")\n",
    "snow_session = snow_conn.session()\n",
    "tru_session = TruSession()\n",
    "tru_session.reset_database()\n",
    "\n",
    "course_name = \"machine_learning_for_health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedbacks(session):\n",
    "    provider = Cortex(session, model_name=\"mistral-large2\")\n",
    "\n",
    "    f_groundedness = (\n",
    "        Feedback(\n",
    "            provider.groundedness_measure_with_cot_reasons,\n",
    "            name=\"Groundedness\",\n",
    "            provider=provider,\n",
    "        )\n",
    "        .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "        .on_output()\n",
    "    )\n",
    "\n",
    "    f_answer_relevance = (\n",
    "        Feedback(\n",
    "            provider.relevance_with_cot_reasons,\n",
    "            name=\"Answer Relevance\",\n",
    "            provider=provider,\n",
    "        )\n",
    "        .on_input()\n",
    "        .on_output()\n",
    "    )\n",
    "\n",
    "    f_context_relevance = (\n",
    "        Feedback(\n",
    "            provider.context_relevance_with_cot_reasons,\n",
    "            name=\"Context Relevance\",\n",
    "            provider=provider,\n",
    "        )\n",
    "        .on_input()\n",
    "        .on(Select.RecordCalls.retrieve.rets[:])\n",
    "        .aggregate(np.mean)\n",
    "    )\n",
    "\n",
    "    return [f_groundedness, f_answer_relevance, f_context_relevance]\n",
    "\n",
    "feedbacks = get_feedbacks(snow_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRetriever:\n",
    "\n",
    "    def __init__(self, session, service_name: str, model_name: str = \"mistral-large2\"):\n",
    "\n",
    "        root = Root(session)\n",
    "        db, schema = (\n",
    "            session.get_current_database(),\n",
    "            session.get_current_schema(),\n",
    "        )\n",
    "\n",
    "        self.service = (\n",
    "            root.databases[db].schemas[schema].cortex_search_services[service_name]\n",
    "        )\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.system_prompt = \"\"\"\n",
    "        You are a knowledgeable teaching assistant helping university students learn from their lecture materials. \n",
    "        Use the provided context from lecture videos and notes to answer questions. If the context doesn't contain \n",
    "        relevant information, simply state that you don't know. Keep responses friendly but concise, using no more \n",
    "        than three sentences. For general greetings or casual conversation, respond naturally without needing context.\n",
    "        \"\"\"\n",
    "\n",
    "    @instrument\n",
    "    def complete(self, query: str, context: list[str]) -> str:\n",
    "        \"\"\"\n",
    "        Get a completion from the Snowflake Cortex model.\n",
    "        \"\"\"\n",
    "        context_str = \"\\n\".join(context)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context: {context_str}\\nQuestion: {query}\\nAnswer:\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        return Complete(model=self.model_name, prompt=messages)\n",
    "\n",
    "    @instrument\n",
    "    def retrieve(self, query: str, limit: int = 3) -> list[str]:\n",
    "        \"\"\"\n",
    "        Retrieve documents from cortex search service.\n",
    "        \"\"\"\n",
    "        documents = self.service.search(query, columns=[\"text\"], limit=limit)\n",
    "        return [doc[\"text\"] for doc in documents.results]\n",
    "\n",
    "    @instrument\n",
    "    def search(self, query: str, n_context: int = 3) -> str:\n",
    "        context = self.retrieve(query, n_context)\n",
    "        answer = self.complete(query, context)\n",
    "        return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions_for_lecture():\n",
    "    questions = {}\n",
    "    for file in os.listdir(\"qna_for_eval\"):\n",
    "        df = pd.read_csv(os.path.join(\"qna_for_eval\", file))\n",
    "        lecture_name = os.path.splitext(file)[0]\n",
    "        questions[lecture_name] = df[\"Question\"].tolist()\n",
    "    return questions\n",
    "\n",
    "questions_for_lecture = get_questions_for_lecture()\n",
    "eval_questions = []\n",
    "for questions in questions_for_lecture.values():\n",
    "    eval_questions.extend(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What challenge does cardiac motion pose to high-quality imaging scans?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What challenge does cardiac motion pose to high-quality imaging scans?', [\"And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself. And so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you want to have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately doesn't deal well with with the moving aspect. So coronary angiography has very, very fast frame rates. So that's x-ray, and that's sort of very fast. Echocardiography can be quite fast. MRI and CT are not quite as good, and so there's some degradation of the image. As a result, people do something called gating, where they'll take the electrocardiogram, the ECG, and try to line up different portions of different heartbeats and say, well, you know, we'll take this image from here, we'll line it up with this one from there, this one from there. I'm going to talk a little bit about that from about registration, but ultimately that's a problem that people have to deal with.\", \"So you have the raw imaging data, but all the clinical stuff is somewhere else. So you have to sometimes link that, and so you need to get access there. And so just to give you a little bit of an idea of scale, so we're about to get all of the ECGs from Brigham and Women's, which is about 30,000,000, stored kind of historically. And this is all related to cost. So positron emission tomography, you can get about 8,000 or so, and we're one of the busiest centers for that. You know, echocardiograms are in the 300,000 to 500,000 ranges archived, so that gets a little bit more interesting. Okay. So what a DICOM header looks like. You have some sort of, identifiers, and then you have some information there, attributes of the images, patient name, date of birth, frame rate, these kind of things are there, and there's some variability. So it's never never quite easy. Okay. So, these different modalities have some different benefits to them, and this is why they're used for for one disease or the other. And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself.\", \"This is a not just a problem for us, but a problem for many people in this field. So so we need to be a little bit more adventurous in terms of trying some of these other methods. We did try a little bit of of that and didn't find huge huge gains, but I think ultimately there still needs to be a little bit more work there. Okay. So last thing I'm going to talk about before getting into to to my work is really this idea of image registration. So I talked about how there are sometimes some techniques that have limitations either in terms of spatial resolution or temporal resolution. So this is a PET scan here, this sort of reddish glow here. And in the background, we have a CAT scan of the of the heart. And so clearly this is a poorly registered image where you have this the PET scan kind of floating out here, but it really should be lined up here, and so you have something that's registered better there. Also mentioned this problem about gating. So ultimately, if you have a a image taken from different parts mature problem in the computer vision world. We haven't done anything in this space, but ultimately it has sort of been around for decades.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is a significant benefit of applying machine learning to cardiac imaging?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is a significant benefit of applying machine learning to cardiac imaging?', [\"So welcome, everyone. Today is the first of what will be a series of 4 guest lectures throughout the semester. There will be 2 guest lectures the week from starting the week from today, and then there'll be another one towards the end of the semester. And what Pete and I decided to do is to bring in people who know a lot more than us about some area of expertise. And today's instance is going to be about, about cardiovascular medicine, in particular, about how to use imaging and machine learning on images in that context. And for today's lecture, we're we're, very excited to have, professor Rahul Deo to speak. Rahul's name kept on showing up as I did research over the last couple of years. First, I my group was starting to get interested in echocardiography, and we said, oh, here's an interesting paper to read on it. We read it, and then we wrote another paper on doing subtyping of of ejection fraction as a type of heart failure, and we read it.\", \"And in some places, radiologist consults could take days depending on the urgency of the condition. So this is an area where data is quite standardized. In fact, MIT just released last week a dataset of 300,000 chest x rays with associated labels on them. And one could try to ask the question of, could we build machine learning algorithms using the convolutional neural network type techniques that we've seen play a big role in object recognition to try to understand what's going on with this patient. For example, in this case, the prediction is the patient has pneumonia from this chest X-ray. And and using those systems, it could help both reduce the load of radiology consults, and it could allow us to really translate these algorithms to settings which are might be much more resource poor, for example, in developing nations. Now the same sort of techniques can be used for other data modalities. So this is an example of of data that could be obtained from an EKG. And from looking at this EKG, one can try to predict, does the patient have a heart condition such as an arrhythmia?\", \"Many of the starting things we're doing are kind of already picking up what everybody else here is already doing, but at the same time so it it's it's it's it's okay from that standpoint, but it really has to make its way. And that means that we have to have some mature understanding of what makes its way into practice, where the resistance will be. So the the lecture will be kind of peppered throughout with some kind of opinions and comments in that, and hopefully that will be useful. So just a quick outline. Just gonna introduce cardiac structure and function. Probably not part of the the sort of the regular undergraduate and graduate training here at MIT. Talk a little bit about what the major sort of cardiac diagnostics are and how they're used. And and all of this is really to help guide the the sort of the thought and the decision making about how we would ever automate and and bring this into sort of how to bring machine learning artificial intelligence to actual clinical practice. Because you need to give enough background so you realize what the sort of the the challenges are. And then the question probably everybody has is where's the data? How how would how would one get access to some of this stuff to be able to potentially do work in this area? And then I'm gonna sort of venture a little bit into computer vision and just talk about some of the the topics that that at least I've been thinking about that are relevant to to what we're doing.\"])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\miniconda3\\envs\\snow_env\\Lib\\site-packages\\trulens\\feedback\\llm_provider.py:1521: UserWarning: Failed to process and remove trivial statements. Proceeding with all statements.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', [\"Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks, specifically in cancer and also, obviously, risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 2009 to 2016. This started off with about 280,000 cancers. And once we kinda filtered for at least 1 year follow-up, we ended up with this, you know, final setting where we had, 220,000 mammograms for training, and about 26,000 for development and testing. And the way we had our outcomes to say, you know, is this a positive mammogram or not? We didn't look at what cancers were caught by the radiologist. We'll say, you know, what was cancer that was fine in any means within a year? And where we looked, we looked through the radiology, HR, and the partners kind of 5 hospital registry. And they were really trying to say if a cancer if any way we can tell a cancer occurred, let's mark it as such, regardless of whether it was caught on MRI or some kind of later stage. And so the thing we're trying to do here is just mimic, you know, the real world of whether we not trying to catch cancer.\", \"Okay. Great. Well, thank you for the great setup. So for this section, I'm gonna talk about some of our work in interpreting mammograms for cancer. Specifically, it's gonna go into cancer detection and triaging mammograms. Next, we'll talk about kind of our technical approach to breast cancer risk. And then finally, close-up in the many many different ways to mess up and the way things can go wrong and how does a poor clinical implementation. So let's kind of look more closely at the numbers of the actual breast cancer screening workflow. So as Kanye already said, you might, you know, see something like a 1,000 patients, all of them take mammograms, and of that 1,000, on average, maybe a 100 be called back for additional imaging. Of that 100, something like 20 will get biopsied and end up with maybe 5 or 6 diagnoses of breast cancer. So one very clear thing you see about, you know, problems when you look at this funnel is that way over 99% of people that you see in a given day are cancer free, so your actual incidence is very low. And so there's kind of a natural question that can come up, what can you do in terms of modeling if you have, you know, an even okay cancer detection model to raise the incidence of this population but automatically reading a portion of the population is healthy?\", \"And in that, the actual can't show the confer might be 50 by 50 pixels. So intuitively, your signal to noise ratio is very different. Whereas, in ImageNet, my dog is like the entire image. She's huge, in real life and in that photo. And the image itself is much smaller. So not only do you have much smaller images, but you're kind of like the relative size of the object in there is much larger. To kind of further compounded difficulty, the pattern that you're looking for inside the mammogram is really context dependent. So if you saw that pattern somewhere else in the breast, it's not it doesn't indicate the same thing, and so you really care about where in this kind of global context this comes out. And if you kind of take the mammogram at different times with different compressions, you have this kind of non rigid morphing of the image that's much more difficult to model, whereas that's a more or less context independent dog. You see that kind of frame kind of anywhere you know it's a dog, and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just, like, the number of cancers we have, it's gonna be the cancer might be less than 1% of the mammogram and about 0.7% of your images have cancers.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are the four categories of breast tissue density used in medical practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are the four categories of breast tissue density used in medical practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are the four categories of breast tissue density used in medical practice?', [\"So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively, and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about?\", \"So if you can tell from an image that is gonna be healthy for a long time, you're really trying to model what's the likelihood of this breast developing cancer in the future. Now, modeling breast cancer risk, as Connie already said, is not a new problem. It's been a quite researched one in the community, and the more classical approach that we're gonna look at, other kind of global health factors, the person's age, their family history, whether or not they've had menopause, and kind of any other or these kind of factor we can try to say our markers of their health to try to predict whether or not those persons at risk of developing breast cancer. People have thought that the image contained something before. The way they've thought about this is through this kind of subjective breast density marker, and the improvements seen across this are kind of marginal from 61 to 63. And as before, the kind of sketch we're gonna go through is data collection, modeling, and analysis. In data collection, we followed a very similar template. We sought for the consecutive mammograms from 2009 to 2012. We took outcomes from the EHR, once again, and the partner's registry. We didn't do exclusions based on race or anything of that sort or implants, but we did exclude negatives for follow-up.\", \"So, for example but the kind of key core takeaway here is that the there was no noticeable gap in terms of by age group. We repeated this analysis by race and we saw, the same trend again. The performance kind of ranged generally around 82, and in places where the gap was bigger, the just confidence interval was bigger accordingly, due to smaller sample sizes because MGH is 80% white. We saw the exact same trend by density. The outline here is very dense breasts, but there's only like a 100 of those on test sets, so like this confidence level actually goes from like 60 to 90. So, as far as we know, for the other 3 categories, it is very much tighter confidence interval and very similar, once again, around 82. Okay. So we have a decent idea that this model seems at least with a population MGH, actually serve the relevant populations, you know, that exist as far as we know so far. The next question is, how does this how does a model assessment relate to the radiology assessment? So to look at that, we looked at on the test side, if you look at the radiology, true positives, false positives, true negatives, false negatives, where do they fall within the model distribution of, like, percentile risk?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', [\"So, it shows that they're kind of picking up on different things and where they disagree gives us both areas to improve and some ancillary benefits because now we can reduce false positives. This directly leads into simulating the impact. So one of the things we did, we said, okay, if people retrospectively on the test set as a simulation before we truly plug it in, if people didn't re blow the triage threshold, so we can't catch anymore, catch it this way, but we can reduce false positives, what would have happened? So at the top, we have the original performance. So this is looking a 100% of mammogram, sensitivity was 90.6 with specificity of 93, And in the simulation, the sensitivity dropped, not significantly to 90.1, but significantly improved to 93.7 while looking at 80% or 81% of the mammograms. So this is like promising preliminary data, but to reevaluate this and go forward, our next step see if I oh, I'm gonna get to that in a second. Our next step is really do clinical implementation, to really figure out, because there's like a core assumption here was that people read it the same way. But if you have this higher incidence, what does that mean? Can you focus more on the people that are more suspicious, and is the right way to do this just a single threshold to not read, or have a double ender with the same, these are much more likely to have cancer.\", \"Okay. Great. Well, thank you for the great setup. So for this section, I'm gonna talk about some of our work in interpreting mammograms for cancer. Specifically, it's gonna go into cancer detection and triaging mammograms. Next, we'll talk about kind of our technical approach to breast cancer risk. And then finally, close-up in the many many different ways to mess up and the way things can go wrong and how does a poor clinical implementation. So let's kind of look more closely at the numbers of the actual breast cancer screening workflow. So as Kanye already said, you might, you know, see something like a 1,000 patients, all of them take mammograms, and of that 1,000, on average, maybe a 100 be called back for additional imaging. Of that 100, something like 20 will get biopsied and end up with maybe 5 or 6 diagnoses of breast cancer. So one very clear thing you see about, you know, problems when you look at this funnel is that way over 99% of people that you see in a given day are cancer free, so your actual incidence is very low. And so there's kind of a natural question that can come up, what can you do in terms of modeling if you have, you know, an even okay cancer detection model to raise the incidence of this population but automatically reading a portion of the population is healthy?\", \"Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks, specifically in cancer and also, obviously, risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 2009 to 2016. This started off with about 280,000 cancers. And once we kinda filtered for at least 1 year follow-up, we ended up with this, you know, final setting where we had, 220,000 mammograms for training, and about 26,000 for development and testing. And the way we had our outcomes to say, you know, is this a positive mammogram or not? We didn't look at what cancers were caught by the radiologist. We'll say, you know, what was cancer that was fine in any means within a year? And where we looked, we looked through the radiology, HR, and the partners kind of 5 hospital registry. And they were really trying to say if a cancer if any way we can tell a cancer occurred, let's mark it as such, regardless of whether it was caught on MRI or some kind of later stage. And so the thing we're trying to do here is just mimic, you know, the real world of whether we not trying to catch cancer.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', [\"You see that kind of frame kind of anywhere you know it's a dog, and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just, like, the number of cancers we have, it's gonna be the cancer might be less than 1% of the mammogram and about 0.7% of your images have cancers. Even in this data set, which is from 2000 to 2016 NGH, a massive imaging center, in total, across all of that, we all still have, like, less than 2,000 cancers. And this is super tiny compared to, like, regular object classification data sets. And this is, you know, looking at over a 1,000,000 images if you look at all the four views of the exams. And at the same time, it's also too big. So, even if I down sample these images, I can only really fit 3 of them for a single GPU, and so this kind of limits the batch size I can work with. And whereas the kind of comparable, if I took just the regular ImageNet size, I could fit batch sizes of 128, easily happy days, and do all this parallelization stuff, and it's just much easier to play with. And finally, the actual data set itself is quite large, and so you have to do some, there's no uses to deal with in terms of, like, just setting up your server infrastructure to handle these massive data sets, while still being able to train efficiently.\", \"So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively, and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about?\", \"But in general, our, like, a true deeper derecognizing, what it says, it still eludes us and isn't something I can give too much conclusions about, unfortunately. Okay. So that's generalization, and if you don't get this right, kind of nothing works for a very long time. So just if you're gonna start a project in the space, try this. Next, another important decision that if you don't do kind of breaks, is your optimization and architecture choice. So as I said before, kind of a core problem in stability here is this idea that our signal to noise ratio is really low. And so, a very common approach throughout a lot of the prior work and things I actually have tried myself before is to say, okay, let's just break down this problem. We can train at a patch level first. We're gonna take just subsets of the mammogram, maybe this little bounding box, have it annotated for radiology findings, like benign masses or calcification, things of that sort. We're gonna pre train on that task that has this kind of pixel level prediction. And then once we're done with that, we're gonna just fine tune that initialize model across the entire image. So you kinda have this, like, 2 stage training procedure.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', [\"So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts. So in terms of looking at high risk cohorts, our best model plays about 30% of all the cancers in the population in the top 10%, and 3% of all the cancers in the bottom 10%, compared to 185 to the prior state of the art. And so, what this enables you to do if you're gonna say that, you know, this 10% should actually qualify for MRI, you can start fighting this problem of majority of people that get cancer don't have MRI and the majority of people that get it don't need it. It's all about is your risk model actually placed the right people into the right buckets. Now, we saw that this trend of outperforming the prior state of the art held across races, and one of the things that was kind of astonishing was that, though Thai cuisine performed by white women, which makes sense because it was developed only using white women in the UK, it was worse than random in our data set of African American women. And so, this kind of, emphasizes the importance of this kind of analysis to make sure that the kind of data set that you have is reflective of the population you're trying to serve, and actually doing the analysis, accordingly.\", \"Our kind of goals for the analysis as before, we wanna see, does this model actually serve the whole the whole population? Is it gonna be discriminative across race, menopause, status, and family history? And how does this relate to kind of classical portions of risk, and are we actually doing any better? And so just diving directly into that, assuming there's no questions. Good. Just kinda remind you, this is the kind of the setting. One thing I forgot to mention, that's why I had the slide here to remind me, is that we excluded cancers from the 1st year from the test set, so there's truly a negative screening population. So the way we we kind of disentangle cancer detection from cancer risk. Okay. Cool. So Tyre Cusick is the kind of prior state of the art model. It's a model based out of the UK. They're developed by someone named Sir Cusick, who's knighted over this work. It's very commonly used. So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts.\", \"So, for example but the kind of key core takeaway here is that the there was no noticeable gap in terms of by age group. We repeated this analysis by race and we saw, the same trend again. The performance kind of ranged generally around 82, and in places where the gap was bigger, the just confidence interval was bigger accordingly, due to smaller sample sizes because MGH is 80% white. We saw the exact same trend by density. The outline here is very dense breasts, but there's only like a 100 of those on test sets, so like this confidence level actually goes from like 60 to 90. So, as far as we know, for the other 3 categories, it is very much tighter confidence interval and very similar, once again, around 82. Okay. So we have a decent idea that this model seems at least with a population MGH, actually serve the relevant populations, you know, that exist as far as we know so far. The next question is, how does this how does a model assessment relate to the radiology assessment? So to look at that, we looked at on the test side, if you look at the radiology, true positives, false positives, true negatives, false negatives, where do they fall within the model distribution of, like, percentile risk?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the primary challenge with using billing codes for clinical research?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the primary challenge with using billing codes for clinical research?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the primary challenge with using billing codes for clinical research?', [\"What and and there's a systematic reason, because those billing codes were not created in order to specify what's wrong with the patient. They were created in order to tell an insurance company or Medicare or somebody how much of a payment is deserved by the doctors taking care of them. And so what this means is that, for example, if I clutch my chest and go, and an ambulance rushes me over to Mass General, And they do a whole bunch of tests, and they decide that I'm not having a heart attack. The correct billing code for that visit is myocardial infarction, because, of course, the work that they had to do in order to figure out that I'm not having a heart attack is the same as the work they would have had to do to figure out that I was having a heart attack. And so, the billing codes, we've talked about this a little bit before, but they're a very imperfect representation of reality. So we said, well, okay. What if we insisted that, you have 3 billing codes for rheumatoid arthritis rather than just one?\", \"And so we went to the research patient data repository of Mass General and and the Brigham Partners Healthcare. And we said, okay. Who are the patients who have been billed for a rheumatoid arthritis visit? And there are many thousands of those people. Okay? And then we selected a random set of, I think, 400 of those patients. We gave them to rheumatologists, and we said, which of these people actually have rheumatoid arthritis? K. So these were based on billing codes. So what would you guess is the, positive predictive value of having a billing code for rheumatoid arthritis in this data set? I mean, how many people think it's more than 50%? Okay. That would be nice, but it's not. How many people think it's more than 25%?\", \"The the I think the biggest challenge right now is the mapping. So ICD 9, you know, is now doesn't map directly to ICD 10 or back because there are diseases that we didn't know when they developed ICD 9 that exist in ICD 10. In ICT 10, they talk about diseases in ways that weren't described in ICD 9. So when you're trying to harmonize the data, and this is actively something we're dealing with right now at the VA, how do you now count the ICD codes? How do you consider that someone has an ICD code for RA? So those are all things that are being developed now. CMS, Center For Medicaid and Medicare, again, this is for billing purposes, has come up with a mapping system that many of us are using now given what we have. And by the way, the the committee that is designing ICD 11 Yeah. Has been very active for years. And so there's another one coming down down the pike. Although from what I understood you posit that?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', [\"So what we did is to say, well, if you train a data set that tries to tell you whether somebody really has rheumatoid arthritis or not based on just codified data. So codified data is things like lab values and prescriptions and demographics and stuff that is in tabular form. Then we were getting a positive predictive value of about 88%. And we said, well, how how well could we do by instead of looking at that codified data, looking at the narrative text in nursing notes, doctors' notes, discharge summaries, various other sources, could we do as well or better? And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%.\", \"And the natural language queries were also extracted in different ways, because Vanderbilt, for example, already had a tool in place where they would try to translate any text in their notes into UMLS concepts, which we'll talk about again in a little while. So my expectation when I heard about this study is that this would be a disaster, okay, that it would simply not work, because there are local effects, local factors, local ways that people have of describing patients that I thought would be very different between Nashville, Chicago, and Boston. And much to my surprise, what they found was that, in fact, it kind of worked. So the model performance, even taking into account that the way the data was extracted out of the notes and the clinical systems was different, was fairly similar. Now one thing that is worrisome is that the PPV of our algorithm on our data, the way we calculated PPV they calculated PPV in this study came in lower than the way we had done it when we when we found it.\", \"And the, predictors actually are an interesting mix of ones based on natural language processing and ones that are codified. So, for example, you have rheumatoid arthritis. If if a note says the patient has rheumatoid arthritis, that's pretty good evidence that they do. If somebody has characterized this being seropositive, that's, again, good evidence. And then, erosions and so on. But there are also codified things, like if you see that the rheumatoid factor in a lab test was negative, then actually, what? I don't know why that's oh, no. That counts against. Okay. And then various exclusions. So these were the things selected by our regularized logistic regression algorithm. And I showed you the results before. So we were able to get a positive predictive value of about 0.94.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some goals of NLP in healthcare as discussed in the lecture?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some goals of NLP in healthcare as discussed in the lecture?', [\"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations. But I'm not sure where the the boundary is going to fall. I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview.\", \"And this is probably not meant to be readable by anybody except the person who wrote it or maybe their immediate friends and colleagues. So this is a real issue and one that we don't have a very good solution for yet. Now what do you use NLP for? Well, I had mentioned that one of the things we want to do is to codify things that appear in a note. So if it says rheumatoid arthritis, we want to say, well, that's equivalent to a particular ICD 9 code. We might want to use natural language processing for de identification of data. I mentioned that before. You know, Mimic, the only way that that Roger Marks' group got permission to release that data and make it available for people like you to use is by persuading the IRB that we had done a good enough job of getting rid of the all the identifying information in all of those records so that it's probably not technically impossible, but it's very difficult to figure out, who the the patients actually were in that cohort, in in that database.\", \"So one of the things that we didn't know when we first started out was how many gold standard labels did we need, and how many features did we need, and which of those features would be important. So by features, I mean ICD codes, the diagnosis code, medications, and all that list of NLP terms that might be related to the condition. And so now we have ways to try to whittle down that list before we even use those gold standard labels. And so may let me think about so this is NLP. The focus here is on NLP. So there are couple ways we're doing this. So one rate limiting step was getting the clinicians to come up with a list of terms that are important for a certain condition. You can imagine if you get 5 doctors in a room to try to agree on a list, takes forever. And so we tried to get that out of the way. So one thing we started doing was we took, just common things that are freely available on the Web, Wikipedia, Medline, the Merck Manual, that have medical information. And we actually now process those articles, look for medical terms, pull those out, map them to concepts, and that becomes that term list now that goes into so now instead of if you think about in the old days, we came up with a list.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', [\"And so the recursive machine learning problem is how best to identify the things associated with the term. And this is generally known as phenotyping. Now, how many of you have used the UMLS? Just a few. So in 1985 or 'eighty 4, the newly appointed director of the National Library of Medicine, which is one of the NIH institutes, decided to make a big investment in creating this unified medical language system, which was an attempt to take all of the terminologies that various medical professional societies had developed and unify them into a single, what they called a metathesaurus. So it's not really a thesaurus, because it's not completely well integrated, but it does include all of this terminology.\", \"So one of the things that we didn't know when we first started out was how many gold standard labels did we need, and how many features did we need, and which of those features would be important. So by features, I mean ICD codes, the diagnosis code, medications, and all that list of NLP terms that might be related to the condition. And so now we have ways to try to whittle down that list before we even use those gold standard labels. And so may let me think about so this is NLP. The focus here is on NLP. So there are couple ways we're doing this. So one rate limiting step was getting the clinicians to come up with a list of terms that are important for a certain condition. You can imagine if you get 5 doctors in a room to try to agree on a list, takes forever. And so we tried to get that out of the way. So one thing we started doing was we took, just common things that are freely available on the Web, Wikipedia, Medline, the Merck Manual, that have medical information. And we actually now process those articles, look for medical terms, pull those out, map them to concepts, and that becomes that term list now that goes into so now instead of if you think about in the old days, we came up with a list.\", \"And one can try to standardize those by mapping them to what's called the Unified Medical Language System, which is a ontology with millions of different medical concepts in them. So I'm not going to go too much more into these. They'll be the subject of much discussion in this in this semester, but particularly in the next two lectures by Pete. But I wanna talk very briefly about what you can do once you have a standardized vocabulary. So one thing you can do is you could build APIs or application programming interfaces for now sending that data from place to place. And FHIR, f h I r, is a new standard which has widespread adoption now here in the United States for for hospitals to provide data both to downstream for downstream clinical purposes, but also directly to patients. And in this standard, it will use many of the vocabularies I mentioned to you in the previous slides to encode diagnoses, medications, allergies, problems, and and even financial aspects that are relevant to the care of this patient.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the role of term spotting and negation handling in clinical NLP?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the role of term spotting and negation handling in clinical NLP?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the role of term spotting and negation handling in clinical NLP?', [\"And then as people did this, they said, well, there must be more sophisticated ways of doing this. And so a whole industry developed of people saying that not only should we use the terms that we got originally from the doctors who were interested in doing these queries, but we can define a machine learning problem, which is how do we learn the set of terms that we should actually use that will give us better results than just the terms we started with? And so I'm gonna talk about a little bit of of that approach. First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary.\", \"First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary. So I'll talk a little bit about that. But basically, it's a dictionary lookup. You look up in this very large database of medical terms and translate them into some kind of expression that represents what that term means. And then you find 2 kinds of patterns. One pattern is a negation phrase followed within 5 words by one of these UMLS terms, and the other is a UMLS term followed within 5 words by a negation phrase, different set of negation phrases. So if you see no sign of something, that means it's not present. Or if you see ruled out unlikely something, then it's not present.\", \"I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview. So roughly, the outline of these two lectures is that I want to talk a little bit about why we care about clinical text. And then I'm going to talk about some conceptually very appealing, but practically not very feasible methods that involve analyzing these narrative texts as linguistic entities, as linguistic objects, in the way that a linguist might approach them. And then we're going to talk about what is very often done, which is a kind of term spotting approach that says, well, we may not be able to understand exactly everything that that goes on in the narratives, but we can identify certain words and certain phrases that are very highly indicative that the patient has a certain disease, a certain symptom, that some particular thing was done to them.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is risk stratification and why is it important in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is risk stratification and why is it important in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is risk stratification and why is it important in healthcare?', [\"Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring. Now, risk stratification is quite different from diagnosis. Diagnosis often has very, very stringent criteria on performance. If you do a misdiagnosis of something, that can have very severe consequences in terms of patients being treated for conditions that they didn't need to be treated for and patients dying because they were were not diagnosed in time. Now risk stratification, you think of as a little bit more fuzzy in nature. We wanna do our best job of trying to push patients into each of these categories, high dose, low risk, and so on.\", \"Although today's lecture is going to be a little bit more high level, next Thursday's lecture is where we're going to really start to get into mathematical details about how one should tackle machine learning problems with sensor data. And then the following lecture after that is going to be on physiological data. And that lecture will also be much more technical in nature compared to the first couple of weeks of the course. So what is risk stratification? At a high level, you should think about risk stratification as a way of taking in a patient population and separating out all of your patients into 1 of 2 or more categories. Patients with high risk, patients with low risk, and maybe patients somewhere in the middle. Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring.\", \"But every single project that I've been a part of has been an effort to bring in data that has always been there, but we haven't been able to to learn from until now. And whether that's, you know, at the VA building out their genomic, science infrastructure and recruiting and enrolling a million veterans to to to donate their blood and their EMR or at Ariadne Labs over out of Harvard School of Public Health in the Brigham, improving childbirth in India. It it's all about how can we get a little bit better over and over again to make health care, you know, better place for folks. So so tell me, what is risk stratification from your perspective? Right? Defining that, I found to be one of the most difficult parts of today's lecture. Well, thank you for challenging me with it. So So it's a rather generic term, and I think it depends entirely on the problem you're trying to solve. And every time I I go at this, you really have to ground yourself in the problem that you're trying to solve. Risk could be running out of a medical supply, in an operating room. Risk could be an APGAR score. Risk could be, from pre diabetic to diabetic. Risk could be an older person falling down in their home.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the difference between traditional scoring systems and ML-based risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', [\"And each one of those steps takes a lot of time. Now with these machine learning based approaches, it raises the possibility of a research assistant sitting in a hospital or in a computer science department saying, oh, I think it would be really useful to derive a score for this problem. You apply your machine learning algorithm. And even if it's a condition or an outcome, which occurs very infrequently, if you have access to a large enough data set, you'll be able to get enough samples in order to actually predict that somewhat very narrow outcome. And so as a result, it really opens the door to rethinking about the way that risk stratification can be can be used. But as a result, there are also new dangers that are introduced. And we'll talk about some of those in today's lecture, and we'll continue to talk about those in next Thursday's lecture. So these models are being widely commercialized.\", \"Well, the traditional approaches to risk stratification are based on scoring systems. So I mentioned to you a few minutes ago the APGAR scoring system. It's shown here. You're going to say for each of these different criteria, activity, pulse, grimace, appearance, respiration, You look at the baby and you say, well, activity is absent or maybe their active movement. Appearance might be pale or blue, which would get 0 points, or completely pink, which gets 2 points. And for each one of these answers, you add up the corresponding points. So you get a total number of points. And you look over here and you say, okay. Well, baby is at risk, at severe risk. If they have 7 to 10 points, then then the baby is low risk. And there are hundreds of such scoring rules which have been very carefully derived through studies not dissimilar to the one that you read for today's readings and which are actually widely used in the health care system today.\", \"So one has to think to do the score. One has to figure out what the corresponding inputs are. And as a result of that, often they're not used as frequently as they should be. 2nd, the new machine learning approaches can get higher accuracy, potentially, due to their ability to use many more features than the traditional approaches. And finally, they can be much quicker to drive. So all of the traditional scoring systems had a very long research and development process that lead that led to their adoption. First, you gather the data, then you build the models, then you sanity check the models, then you do an evaluation in 1 hospital, then you do a prospective evaluation in many hospitals. And each one of those steps takes a lot of time. Now with these machine learning based approaches, it raises the possibility of a research assistant sitting in a hospital or in a computer science department saying, oh, I think it would be really useful to derive a score for this problem.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How is label leakage managed in diabetes prediction models?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How is label leakage managed in diabetes prediction models?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How is label leakage managed in diabetes prediction models?', [\"So for example, for this prediction task, we're going to exclude patients who have developed type 2 diabetes between 2,009 and 2,011. And we're only going to count as positives patients who get newly diagnosed with type 2 diabetes between 2,011 and 2,013. And one of the reasons why you might want to include a gap in the model is because often there's label leakage. So if you look at the very top setup, often what happens is that a clinician might have a really good idea that the patient might be diabetic, but it's not yet coded in a way which our algorithms can pick up. And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list.\", \"And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list. We're gonna say this patient is someone you should be going after. But that's really not an interesting patient to be going after because the clinicians are probably already doing interventions that are relevant for that patient. Rather, we want to find the patients where the diabetes might be more unexpected. And so this is one of the subtleties that really arises when you try to use retrospective clinical data to derive your labels to use within machine learning for risk stratification. So in the result result I'll tell you about, I'm going to use a 1 year gap. Another problem is that the data is highly censored. So, what I mean by censoring is that we often don't have full visibility into the the the data for patients. For example, patients might have only come into the health insurance in 2013.\", \"And so that, then, would be a sign of obesity. So I talked about how the criteria which we use to evaluate risk stratification models are a little bit different from the criteria used to evaluate diagnosis models. Here, I'll tell you, one of the measures that we often use, and it's called positive predictive value. So what we'll do is we'll look at after you've learned your model, look at the top 100 predictions, top 1,000 predictions, top 10,000 predictions, and look to see what fraction of those patients went on to actually develop type 2 diabetes. And, of course, this is done using held out data. Now the reason why you might be interested in different levels is because you might want to target different interventions depending on on the risk and cost. For example, a very low cost intervention, one of the ones that that we did was sending a text message to patients who have who who are who are suspected to have high risk of developing type 2 diabetes.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What types of data are used in risk stratification for diabetes?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What types of data are used in risk stratification for diabetes?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What types of data are used in risk stratification for diabetes?', [\"And so that, then, would be a sign of obesity. So I talked about how the criteria which we use to evaluate risk stratification models are a little bit different from the criteria used to evaluate diagnosis models. Here, I'll tell you, one of the measures that we often use, and it's called positive predictive value. So what we'll do is we'll look at after you've learned your model, look at the top 100 predictions, top 1,000 predictions, top 10,000 predictions, and look to see what fraction of those patients went on to actually develop type 2 diabetes. And, of course, this is done using held out data. Now the reason why you might be interested in different levels is because you might want to target different interventions depending on on the risk and cost. For example, a very low cost intervention, one of the ones that that we did was sending a text message to patients who have who who are who are suspected to have high risk of developing type 2 diabetes.\", \"Creatinine, potassium, glucose, liver enzymes are all the most popular lab tests. And that's not surprising because often, there is a panel called the CBC panel, which is what you would get in your annual physical. And that has many of these top laboratory test results. But then, as you look down into the tail, there are many other laboratory test results that are more specialized in nature. For example, hemoglobin a 1 c is used to track roughly 3 month average of blood glucose and is used to understand a patient's diabetes status. So that's just to give you a sense of what is the data behind the scenes. Now let's think about how do we really derive how do we tackle how do we formulate this risk stratification problem as a machine learning problem? Well, today, I'll give you one example of how to formulate it as a machine learning problem. But in in Tuesday's lecture, I'll tell you several other ways. Here, we're going to think about a reduction to binary classification. And we're going to ask we're gonna go back in time.\", \"But as I mentioned, these scores haven't had the impact that we had hoped that they might have. And and the reason really is because they haven't been actually used nearly as much as they should be. So what we will be thinking through is can we change the way in which risk stratification is done rather than it having to be something which is manually done when you think to do it, we can make it now population wide. We could, for example, take data that's already available from a health insurance company, use machine learning. Maybe we don't have access to all of those features I showed you earlier. Like, maybe we don't know the patient's weight, but we'll we'll use machine learning on the data that we do have to try to find other surrogates of those things we don't have, which might predict diabetes risk. And then we can apply it automatically behind the scenes for millions of different patients and find the high risk population and perform interventions for those patients. And by the way, the work that I'm telling you about today is work that really came out of my lab's research in the last few years.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Why is L1 regularization used in logistic regression for risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Why is L1 regularization used in logistic regression for risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'Why is L1 regularization used in logistic regression for risk stratification?', [\"1st, it can help prevent overfitting in settings where there exists a very good risk model that uses a small number of features. And to point out, that's not a crazy idea that there might exist a risk model that uses a small number of features. Right? Because remember, think back to that Apgar score or the FINRISK, which was used to predict diabetes in in Finland. Each of those had only 5 to 20 questions. And based on the answers to those 5 to 20 questions, one could get a pretty good idea of what the risk is of that patient. Right? So the fact that there might be a small number of features that are that are together sufficient is actually a very reasonable prior. And it's one reason why l one regularization is actually very well suited to these types of risk stratification problems on this type of data. The second reason is one of interpretability. If one wants to then ask, well, what are the features that actually were used by this model to make predictions? When you find only 20 or a few hundred features, you can enumerate all of them and look to see what they are, and that way understand what is going on into the predictions that are that are made.\", \"Then, we've excluded that patient from the population, and we might be really biasing the results of the model by now taking away a whole set of the of the population where this model would have been really important to apply. So thinking about how you really do this inclusion exclusion, how that changes the generalizability of the model you get is something that should be at the top of your mind. So the the machine learning algorithm used in in that paper which you've read is l one regularized logistic regression. One of the reasons for using l one regularized logistic regression is because it provides a way to use a high dimensional feature set. But at the same time, it allows one to do feature selection. So I'll go more into detail on that in just a moment. I imagine most of you have sorry. All of you should be familiar with the idea of formulating machine learning as an optimization problem, where you have some loss function and you have some regularization term. W, in this case, is the weights of your linear model, which we're trying to learn.\", \"Well, the solution the optimal solution is going to be, in essence, the closest point along the circle, which gets as close as possible to the middle of that level set. So over here, the closest point is over is that one. And you'll see that this point has a non zero w 1 and w 2. Over here, the closest point is over here. Right? Notice that that has a zero value of w 1 and a non zero value of w 2. Thus, it's found a sparser solution than this one. So this is just to give you some intuition about why using l one regularization results in sparse solutions to your optimization problem. And that can be beneficial for 2 purposes. 1st, it can help prevent overfitting in settings where there exists a very good risk model that uses a small number of features. And to point out, that's not a crazy idea that there might exist a risk model that uses a small number of features.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is MYCIN and why was it never used in practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is MYCIN and why was it never used in practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What is MYCIN and why was it never used in practice?', [\"And this knowledge base, which was probabilistic in nature because it captured the idea that some symptoms would only occur with some probability for for disease, took over 15 person years to elicit from a large medical team. Right? So it was a lot of effort. And even in, you know, going forward to today's time, there have been few similar efforts at a scale as as as impressive as this one. But, again, what happened? These algorithms are not being used anywhere today in our clinical workflows. And the challenges that have prevented them from being used today are numerous. But, but I used a word in my in my explanation which should really hint at it. I used the word clinical workflow. And this, I think, is one of the biggest challenges, which is that the algorithms were designed to solve narrow problems. They weren't necessarily even the most important problems because clinicians generally do a very good job at diagnosis. And there was a big gap between the input that they expected and the current clinical workflow. So imagine that you have now a mainframe computer.\", \"It's a it's an autoimmune condition, where for each patient over a series of different visits, one would record, for example, here it shows this is visit number 1. The date was January 17, 2007, 1979. The knee pain, patients with knee pain was reported as severe. Their fatigue was moderate. Temperature was 38.5 Celsius. The diagnosis for this patient was actually a different autoimmune condition called systemic lupus. We have some laboratory test values for their creatinine and blood urea nitrogen. And we know something about their medication. In this case, they were on prednisone, a steroid. And one has this data at every point in time. This is recorded almost certainly was recorded on paper, and then later, these were collected into into a computer format. But then it provides the possibility to ask questions and make new discoveries. So, for example, in this work, there was a discovery module which would make causal hypotheses about what what aspects might cause other aspects.\", \"The computer responds, my understanding is the name of the patient is Joe. Respiratory tract is one of the symptoms the patient had. Then the clinician writes, a couple of days before the admission, he had malaise, which is general tiredness. The computer responds, please give me a date of admission. The clinician responds, March 12, 1979, and the computer again confirms that it's understood appropriately. And this is the preface to the later diagnostic stages. So the ideas of how AI can really impact medicine have been around a long time, yet these algorithms, which have been shown to be very effective, even going back to the 19 seventies, didn't translate into clinical care. A second example, oh, so equally impressive in its nature, was work from the 19 eighties at at in Pittsburgh, developing what's known as the Internist 1 or Quick Medical Reference System. This was now used not for infectious diseases, but for primary care. Here, one might ask, how can we try to do diagnosis at a much larger scale where patients might come in with 1 of 100 of different diseases and could report thousands of different symptoms, each one giving you some view, noisy view, into what might be going on with patients' health.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some reasons why AI in healthcare is more promising today compared to the past?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', [\"And I'll point out a few examples of that in the rest of today's lecture. So all of this coming together, the data availability, the advances in other fields of machine learning, and the huge amount of financial potential financial gain in health care and the potential social impact it could have has not gone unnoticed. And there's a huge amount of industry interest in this field. These are just some examples from, from names I think many of you are familiar with, like DeepMind Health and IBM Watson, to start up companies like Bay Labs and PathAI, which is here in Boston, all of which are really trying to build the next generation of tools for health care now based on machine learning algorithms. There's been quite a 1,000,000,000 of dollars of funding in in the recent quarters towards digital health efforts with hundreds of different start ups that are focused specifically on using artificial intelligence in health care.\", \"They might be 60 neurons, then 7, then 6, for example, in terms of each of the layers of of the of the neural network. By the way, that that sort of makes sense given the type of data that was fed into it. So none of this is new in terms of the goals. So what's changed? Why do I think that despite that the fact that we've had what could arguably be called a failure for the last 30 or 40 years, that we might actually have some chance of succeeding now? And the big differentiator, what I'll call now the opportunity, is data. So whereas in the past, much of the work in artificial intelligence in medicine was not data driven, it was based on trying to elicit as much domain knowledge as one can from clinical domain experts, in some cases, gathering a little bit of data. Today, we have an amazing opportunity because of the prevalence of electronic medical records, both in United States and elsewhere. Now here in the United States, for example, the story wasn't that way even back in 2,008, when the adoption of electronic medical records was under 10% across the US.\", \"The the answer is that it's there's a huge amount of difference, and there are a lot of subtleties to doing machine learning right here. And we'll talk about that throughout the whole entire semester. So to begin, this isn't a new field. Artificial intelligence in medicine goes back to the 19 seventies or sometime even in the sixties. One of the earliest examples of trying to use artificial intelligence for diagnosis was this Mison system developed at Stanford where the goal was try to identify bacteria that might might cause infection and then to try to guide what would be the appropriate therapy for that bacteria. Now it was found that this algorithm, this machine learning, this simple AI algorithm, was able to propose a good therapy in 69% of cases, which at the time was better than the best or very good infectious disease experts.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How can machine learning transform emergency departments?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How can machine learning transform emergency departments?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'How can machine learning transform emergency departments?', [\"In a few lectures, I'll talk to you about techniques from the eighties nineties, which were based on trying to signal processing, trying to detect where are the peaks of this signal, look at the distance between peaks. And more recently, because of the large wealth of data that's available, we've been using convolutional neural network based approaches to try to understand this data and predict from it. Yet another example from the ER really has to do with not how do we care for the patient today, but how do we get better data, which will then result in taking better care of the patient tomorrow. And so one example of that, which which my group deployed at Beth Israel Deaconess, and it's still running there in the emergency department, has to do with getting higher quality chief complaints. The chief complaint is the, it's usually a very short 2 or 3 word quantity, like, left knee pain, rectal pain, right right upper quadrant, RUQ, abdominal pain. And it's just a very quick summary of why did the patient come into the ER today.\", \"Which is, again, an important question when it comes to deploying algorithms here. So I'll I'll run through a couple of very high level examples, driven from from my own work, focused on the provider space, and then I'll bump up to talk a bit more broadly. So for the last 7 or 8 years, I've been doing a lot of work in collaboration with Beth Israel Deaconess Medical Center across the river with their emergency department. And the emergency department is a really interesting clinical setting because you have a very short period of time from when a patient comes into the hospital to diagnose what's going on with them, to initiate therapy, and then to decide what to do next. Do you keep them in the hospital? Do you send them home? If you for each one of those things, what should the most immediate actions be? And at least here in the US, we're always understaffed. So we've got limited resources and very critical decisions to make. So this is one example of a setting where algorithms that are running behind the scenes could potentially really help with some of the challenges I mentioned earlier.\", \"And here's one example where it says, the ED dashboard, the emergency department dashboard, decision support algorithms have determined this patient may be eligible for the atrial cellulitis pathway. Cellulitis is often caused by infections. Please choose from one of the options. Enroll in the pathway, decline. And if you decline, you must include a comment for the reviewers. Now, if you clicked on enroll in the pathway, at that moment, machine learning disappears. Rather, there's a standardized process. It's an algorithm, but it's a deterministic algorithm for how patients with cellulitis should be properly managed, diagnosed, and treated. That algorithm comes from best practices, comes from clinicians coming together, analyzing past data, understanding what would be good ways to treat patients of this type, and then formalizing that in a document. The challenge is that there might be 100 or even 1000 of these best practices.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some challenges unique to machine learning in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some challenges unique to machine learning in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some challenges unique to machine learning in healthcare?', [\"I'll just stick to your independence. We hope. So what's unique about machine learning health care? I gave you already some hints at this. So first, health care is ultimately, unfortunately, about life or death decisions. Right? So we need robust algorithms that don't screw up. A prime example of this, which I'll tell you a little bit more about, in towards the end of the semester, is, from a major software error that occurred something like, 20, 30 years ago, in a, in an x-ray type device where an overwhelming amount of radiation was exposed to a patient just because of a software overflow problem, a bug. And, of course, that resulted in a number of patients dying. So that was a software error from decades ago where there was no machine learning in the loop.\", \"Now more broadly, this is a young field. So for example, there just recently, just about 3 years ago, was created the first conference on machine learning in health care by that name. And new publication venues are being created every single day by Nature, Landsat, and and also machine learning journals for publishing research on machine learning healthcare. Because of some of the issues we talked about, like access to data and not very good benchmarks, reproducibility has been a major challenge. And this is, again, something that the field is only now starting to really grapple with. And so as part of this course, also many of you are going to be are currently PhD students or will soon be PhD students. We're going to think through what are some of the challenges for the research field. What are some of the open problems that you might wanna work on either during your PhD or during your future career?\", \"Another challenge is about the difficulty in deploying machine learning algorithms due to the challenge of integration. So you build a good algorithm. You wanna deploy it at your favorite hospital. But guess what? That hospital has Epic or Cerner or or Athena or some other commercial electronic medical record system, and that electronic medical record system is not built for your algorithm to plug into. So there's a big gap, big, large amount of difficulty to to getting your algorithms into production systems, which which we'll talk about as well during the semester. So the goals that Pete and I have for you are as follows. We want you to get intuition for working with health care data. And so the next two lectures after today are going to focus on what health care is really like and what is the health care data that's created by the practice of health care like. We want you to get intuition for how to formalize machine learning challenges as health care problems.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some examples of publicly available healthcare datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some examples of publicly available healthcare datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E868739890>, 'What are some examples of publicly available healthcare datasets?', [\"And, of course, also medications that are being prescribed as as it goes. And so this is a wealth of data that now one could use to try to study at least study in a very narrow setting of intensive care unit how machine learning could be used in that in that location. And I don't wanna underemphasize the importance of this database, both through this course and to the broader field. This is really the only publicly available electronic medical record dataset of any reasonable size in the whole world. And it was created here at MIT. And we'll be using it extensively in our homework assignments as a result. There are other datasets that aren't publicly available, but which have been gathered by by industry. And one prime example is the Truven MarketScan database, which is which was created by a company called Truven, which was later acquired by IBM, as I'll tell you about more in a few minutes. Now this data, and there are many competing companies that that have similar datasets, is created not from electronic medical records, but rather from typically, it's created from insurance claims.\", \"And fingers crossed, it looks like we'll get access to this database for our homework and projects for this semester. Now there are a lot a lot of other initiatives that are that are creating large datasets. A really important example here in the US is President Obama's Precision Medicine Initiative, which has since been renamed to the All of Us Initiative. And this initiative is creating a dataset of 1,000,000 patients drawn in a representative manner from across the United States to capture patients, both poor and rich, patients who are healthy and have chronic disease, with a goal of trying to create a research database where all of us and other people, both inside and outside the US, could do research to make medical discoveries. And this will include data such as data from a baseline health exam where the typical vitals are taken, blood blood is drawn. It'll combine data of the previous tube types I've mentioned, including both data from electronic medical records and health insurance claims. And then a lot of this work is also happening here in Boston.\", \"And then there's a lot of money that passes behind the scenes between insurers and hospitals to corporate companies such as Truven, which collect that data and then resell it for research purposes. And one of the biggest purchasers of data like this is the pharmaceutical industry. So this data, unfortunately, is not usually publicly available, and that's actually a big problem both in US and elsewhere. It's a big obstacle to research in this field that only people who have 1,000,000 of dollars to pay for it really get access to it. It's something that I'm gonna return to throughout the semester. It's, again, something where I think policy can make a big difference. But luckily, here at MIT, the story is gonna be a bit different. So thanks to the MIT IBM Watson AI Lab. MIT has a close relationship with IBM. And fingers crossed, it looks like we'll get access to this database for our homework and projects for this semester. Now there are a lot a lot of other initiatives that are that are creating large datasets.\"])\n",
      "\n",
      "Evaluating PDF content\n",
      "instrumenting <class '__main__.ContentRetriever'> for base <class '__main__.ContentRetriever'>\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting search\n",
      "skipping base <class 'object'> because of class\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the primary function of the heart in the circulatory system?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the primary function of the heart in the circulatory system?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the primary function of the heart in the circulatory system?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 10: Application of Machine Learning to Cardiac Imaging Instructors: David Sontag, Peter Szolovits 1 Background This lecture was a guest lecture by Rahul Deo, the lead investigator of the One Brave Idea project at Brigham and Women's Hospital. Rahul is also Adjunct Associate Professor at UC San Francisco and a member of the faculty at Harvard Medical School. He talked about how machine learning techniques are being used and can be used further to augment cardiac imaging. 2 Introduction to Cardiac Structure and Function Before considering the applications of machine learning to cardiology, it's important to understand the field of cardiology a bit better. In particular, why should we care about cardiology in the first place? For one, coronary heart disease, or CHD (the hardening of arteries that transport blood to the heart), is the leading cause of death globally. And this is something that holds true for both developing and developed countries alike. Since cardiology is ultimately about biological diseases like CHD, it's a good idea to get a better understanding of the biology of the heart before moving on to look at how machine learning can disrupt the field. 2.1 Cardiac Function The heart's primary function is to pump oxygenated blood throughout our circulatory system. The continual flow of blood is not only critical to deliver oxygen necessary for ATP (energy) production to all our tissues, but also to transport signaling molecules throughout our body and remove waste from cells. As a result, the volume of blood flow is quite large: the heart pumps 5 liters of blood every minute, a number that can grow to as much as 35 liters per minute during intense exercise. One crucial aspect of cardiac function is that the body must maintain extremely rhythmic beating of the heart, a not inconsequential task given that the average human heart generates a total of more than 2 billion heartbeats over a lifetime. 2.2 Structure of the Heart Figure 1 above gives an overview of the structure of the human heart. Blood comes in through the superior vena cava into a chamber called the right atrium, from where it passes into the right ventricle. The right ventricle pumps blood to the lungs, and the newly oxygenated blood then flows via the pulmonary veins to the left atrium. Finally, the left ventricle pumps blood to the rest of the body via the aorta. Thus, the heart essentially conducts 2 circulations in series: a pulmonary circulation to pump deoxygenated blood to the lungs, and a systemic circulation to pump newly oxygenated blood to the rest of the body. In addition, the heart also has 4 different valves (mitral, tricuspid, aortic, pulmonary) that control flow of blood out of the heart's four chambers. 2.3 The Cardiac Cycle As the heart pumps, it cycles between periods of relaxation called diastole, in which the heart is filled with blood, and periods of contraction called systole, in which the heart pumps out blood. This regular mechanical motion is coordinated by synchronized electrical activity, which can be visualized in an electrocardiogram (EKG). A Wiggers Diagram can be used to demonstrate the interconnectedness of these electrical and 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 1\", \"Courtesy of OpenStax. Used under CC BY. Aorta Superior vena cava Left pulmonary artery Right pulmonary artery Left atrium Pulmonary trunk Left pulmonary veins Right pulmonary veins Mitral (bicuspid) valve Right atrium Aortic valve Fossa ovalis Tricuspid valve Pulmonary valve Right ventricle Left ventricle Chordae tendineae Papillary muscle Trabeculae carneae Interventricular septum Epicardium Moderator band Myocardium Inferior vena cava Endocardium Anterior view Figure 1: The major chambers, valves, and blood vessels of the human heart. mechanical systems, allowing one to see how events in an EKG align with the physical state of the heart, as shown in Figure 2. 2.4 Cardiac Diseases Given the complex structure of the heart, cardiac diseases are organized based on abnormalities or failures in the following different functions (with example diseases in parentheses): Contractile Function (heart failure) Coronary Blood Supply (coronary artery disease, myocardial infarction) Circulatory Flow (aortic or mitral stenosis/regurgitation) Heart Rhythm (atrial fibrillation, ventricular tachycardia) 2.5 Wrapup of Cardiac Biology So far, our discussion of the heart has focused on examining it as a muscular organ responsible for pumping blood. However, there is a ton of biology here apart from pumping - in fact, only 31% of of cardiac cells are cardiomyocytes, the muscle cells responsible for the heart's contractions. As a result, cardiac function (and, as a result, cardiac disease) comes from the interaction of a very diverse and large group of cells, ranging from endothelial cells, fibroblasts, leukocytes, and more. 3 Major Types of Cardiac Diagnostics and How They are Used Cardiology is by its nature extremely imaging-centric, making it an expensive field of medical study. There exist a large variety of various imaging techniques that each play critical roles in diagnosis. Here is a brief overview of some of the most important ones: EKG - An extremely cheap technique based on measuring voltage differences in the heart over time. Can be used, for example, to diagnose myocardial infarction. 6.S897/HST.956 Machine Learning for Healthcare - Lec10\", 'Time Risk factors Hemming and deviate from hawing regarding Death optimal values lifestyle changes and disability blood pressure LDL/VLDL cholesterol Treatment may be weight (grudgingly) blood sugar initiated Symptoms develop anti-hypertensives cholesterol-lowering dyspnea Therapeutic anti-diabetics angina Responsiveness $$$ Figure 4: A rough timeline on patients with cardiovascular disease. (a) Expressive - captures complex underlying processes (molecular, cellular, imaging ...) (b) Multidimensional - Can\\'t readily be \"gamed\" 3. Pipeline should be ameliorated with therapy (c.f. genetic risk) The role for the fully automated pipeline for echocardiogram interpretation would be at the \"low risk - high reward\" portion of the current spectrum. See Figure 5 6.3 Focus of machine learning in cardiac diseases We can use machine learning to: 1. enable much greater of volumes of data to be interpreted, SO that we reduce costs of acquisition and interpretation, as well as augment interpretations of simple data. 2. augment surveillance within a hospital system, e.g. patient identification for therapies 3. perform triage, i.e. automating ECG interpretation in urgent situations in the ambulance/ER To illustrate the need of machine learning to perform rapid triage, we provide an example. In the early 2000\\'s, it was recognized that any delay in angioplasty and stenting would result in irreversible damage to the heart. Thus, the solution was to replace a cardiologist reviewing the ECG with a rapid triage system by ambulance personnel or ED physicians for quicker turnover. However, this resulted in an increase in false positives. Thus, there is still a need for a fast pipeline that has high quality. 6.4 Zhang, Deo, et al. approach to Automated Approach for Echo interpreta- tion An echo study is typically a collection of up to 70 videos of the heart taken over multiple cardiac cycles and focusing on different viewpoints. The heart is visualized from ¿10 different views, and still images are typi- cally included to enable manual measurements. ¿7,000,000 echo studies are performed annually in Medicare population alone, and there are likely (an estimate by Deo) of about 100,000,000\\'s of archived echo studies. Zhang et al. built a pipeline using 14k raw echo studies and traditional computer vision algorithms for view classification and segmentation into 5 views to perform cardiac structural and functional analysis. This is an automated and low cost approach to echo interpretation. See Figure 6. 6.S897/HST.956 Machine Learning for Healthcare - Lec10 7'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the two circulations the heart conducts in series?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the two circulations the heart conducts in series?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the two circulations the heart conducts in series?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 10: Application of Machine Learning to Cardiac Imaging Instructors: David Sontag, Peter Szolovits 1 Background This lecture was a guest lecture by Rahul Deo, the lead investigator of the One Brave Idea project at Brigham and Women's Hospital. Rahul is also Adjunct Associate Professor at UC San Francisco and a member of the faculty at Harvard Medical School. He talked about how machine learning techniques are being used and can be used further to augment cardiac imaging. 2 Introduction to Cardiac Structure and Function Before considering the applications of machine learning to cardiology, it's important to understand the field of cardiology a bit better. In particular, why should we care about cardiology in the first place? For one, coronary heart disease, or CHD (the hardening of arteries that transport blood to the heart), is the leading cause of death globally. And this is something that holds true for both developing and developed countries alike. Since cardiology is ultimately about biological diseases like CHD, it's a good idea to get a better understanding of the biology of the heart before moving on to look at how machine learning can disrupt the field. 2.1 Cardiac Function The heart's primary function is to pump oxygenated blood throughout our circulatory system. The continual flow of blood is not only critical to deliver oxygen necessary for ATP (energy) production to all our tissues, but also to transport signaling molecules throughout our body and remove waste from cells. As a result, the volume of blood flow is quite large: the heart pumps 5 liters of blood every minute, a number that can grow to as much as 35 liters per minute during intense exercise. One crucial aspect of cardiac function is that the body must maintain extremely rhythmic beating of the heart, a not inconsequential task given that the average human heart generates a total of more than 2 billion heartbeats over a lifetime. 2.2 Structure of the Heart Figure 1 above gives an overview of the structure of the human heart. Blood comes in through the superior vena cava into a chamber called the right atrium, from where it passes into the right ventricle. The right ventricle pumps blood to the lungs, and the newly oxygenated blood then flows via the pulmonary veins to the left atrium. Finally, the left ventricle pumps blood to the rest of the body via the aorta. Thus, the heart essentially conducts 2 circulations in series: a pulmonary circulation to pump deoxygenated blood to the lungs, and a systemic circulation to pump newly oxygenated blood to the rest of the body. In addition, the heart also has 4 different valves (mitral, tricuspid, aortic, pulmonary) that control flow of blood out of the heart's four chambers. 2.3 The Cardiac Cycle As the heart pumps, it cycles between periods of relaxation called diastole, in which the heart is filled with blood, and periods of contraction called systole, in which the heart pumps out blood. This regular mechanical motion is coordinated by synchronized electrical activity, which can be visualized in an electrocardiogram (EKG). A Wiggers Diagram can be used to demonstrate the interconnectedness of these electrical and 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 1\", \"Courtesy of OpenStax. Used under CC BY. Aorta Superior vena cava Left pulmonary artery Right pulmonary artery Left atrium Pulmonary trunk Left pulmonary veins Right pulmonary veins Mitral (bicuspid) valve Right atrium Aortic valve Fossa ovalis Tricuspid valve Pulmonary valve Right ventricle Left ventricle Chordae tendineae Papillary muscle Trabeculae carneae Interventricular septum Epicardium Moderator band Myocardium Inferior vena cava Endocardium Anterior view Figure 1: The major chambers, valves, and blood vessels of the human heart. mechanical systems, allowing one to see how events in an EKG align with the physical state of the heart, as shown in Figure 2. 2.4 Cardiac Diseases Given the complex structure of the heart, cardiac diseases are organized based on abnormalities or failures in the following different functions (with example diseases in parentheses): Contractile Function (heart failure) Coronary Blood Supply (coronary artery disease, myocardial infarction) Circulatory Flow (aortic or mitral stenosis/regurgitation) Heart Rhythm (atrial fibrillation, ventricular tachycardia) 2.5 Wrapup of Cardiac Biology So far, our discussion of the heart has focused on examining it as a muscular organ responsible for pumping blood. However, there is a ton of biology here apart from pumping - in fact, only 31% of of cardiac cells are cardiomyocytes, the muscle cells responsible for the heart's contractions. As a result, cardiac function (and, as a result, cardiac disease) comes from the interaction of a very diverse and large group of cells, ranging from endothelial cells, fibroblasts, leukocytes, and more. 3 Major Types of Cardiac Diagnostics and How They are Used Cardiology is by its nature extremely imaging-centric, making it an expensive field of medical study. There exist a large variety of various imaging techniques that each play critical roles in diagnosis. Here is a brief overview of some of the most important ones: EKG - An extremely cheap technique based on measuring voltage differences in the heart over time. Can be used, for example, to diagnose myocardial infarction. 6.S897/HST.956 Machine Learning for Healthcare - Lec10\", '© Julian Andrés Betancur Acevedo. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Electrocardiogram Phonocardiogram 1st 2nd 120 Aortic valve Aortic pressure LV pressure LA pressure 80 Aortic valve closes Pressure (mmHg) 40 valve AV valve closes opens 0 130 Ventricular volume (mL) 100 70 Atrio-ventricular valves Open Close Open Aortic and pulmonary valves Close Open Close Phase 2a 2b Left atrium Right atrium Left ventricle Right ventricle Ventricular filling Contraction of atria Isovolumetric Ventricular Isovolumetric Ventricular filling contraction ejection relaxation Ventricular filling Ventricular systole Protodiestole (mid-diastole to end-diastole) (atria in diastole) Figure 2: An example of a Wiggers Diagram. Echocardiography - A more expensive technique that uses ultrasound tech to make measurements. Can be used to get general understanding of cardiac structure and thus diagnose, for example, heart failure, valvular disease, and pulmonary hypertension. MRI - One of the most expensive imaging techniques. More expensive than echocardiography but achieves very similar diagnostic functions, SO it is not used all that much in the US. SPECT/PET - Non-invasive techniques, but also extremely expensive. Can be used, for example, to infer coronary artery disease or diagnose microvascular disease. One interesting characteristic of cardiac diagnostics is that diseases are not defined based on biology, but rather based on measurements that depart from \"normal\" anatomic or phsiological values. This may be due to the limitations in our ability to study or image the human heart, but it\\'s not clear whether this is ultimately for the better or worse. In cardiology, clinical decisions regarding treatments for diagnosed diseases are often, but not always, guided in part by inputs from cardiac imaging. Ultimately, a few different factors affect the role of imaging in cardiology. First, although imaging can lead to data with extremely high information content, decisions regarding treatment are affected in large part by historical studies that follow patients with the disease of interest over long time periods. Secondly, cardiologists are often stuck with the data that is already out there because someone decided it was worth paying for. The available data often controls the risk model and decision analysis you can undertake. Finally, while imaging data can be found for patients with diseases for which the imaging process is seen as an essential part of the commonly accepted management plan, it is much more difficult to obtain imaging data for other diseases or patient populations given the high cost. As a result, doctors are often stuck with the stuff that they already know something about. 6.S897/HST.956 Machine Learning for Healthcare - Lec10'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', ['© Julian Andrés Betancur Acevedo. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Electrocardiogram Phonocardiogram 1st 2nd 120 Aortic valve Aortic pressure LV pressure LA pressure 80 Aortic valve closes Pressure (mmHg) 40 valve AV valve closes opens 0 130 Ventricular volume (mL) 100 70 Atrio-ventricular valves Open Close Open Aortic and pulmonary valves Close Open Close Phase 2a 2b Left atrium Right atrium Left ventricle Right ventricle Ventricular filling Contraction of atria Isovolumetric Ventricular Isovolumetric Ventricular filling contraction ejection relaxation Ventricular filling Ventricular systole Protodiestole (mid-diastole to end-diastole) (atria in diastole) Figure 2: An example of a Wiggers Diagram. Echocardiography - A more expensive technique that uses ultrasound tech to make measurements. Can be used to get general understanding of cardiac structure and thus diagnose, for example, heart failure, valvular disease, and pulmonary hypertension. MRI - One of the most expensive imaging techniques. More expensive than echocardiography but achieves very similar diagnostic functions, SO it is not used all that much in the US. SPECT/PET - Non-invasive techniques, but also extremely expensive. Can be used, for example, to infer coronary artery disease or diagnose microvascular disease. One interesting characteristic of cardiac diagnostics is that diseases are not defined based on biology, but rather based on measurements that depart from \"normal\" anatomic or phsiological values. This may be due to the limitations in our ability to study or image the human heart, but it\\'s not clear whether this is ultimately for the better or worse. In cardiology, clinical decisions regarding treatments for diagnosed diseases are often, but not always, guided in part by inputs from cardiac imaging. Ultimately, a few different factors affect the role of imaging in cardiology. First, although imaging can lead to data with extremely high information content, decisions regarding treatment are affected in large part by historical studies that follow patients with the disease of interest over long time periods. Secondly, cardiologists are often stuck with the data that is already out there because someone decided it was worth paying for. The available data often controls the risk model and decision analysis you can undertake. Finally, while imaging data can be found for patients with diseases for which the imaging process is seen as an essential part of the commonly accepted management plan, it is much more difficult to obtain imaging data for other diseases or patient populations given the high cost. As a result, doctors are often stuck with the stuff that they already know something about. 6.S897/HST.956 Machine Learning for Healthcare - Lec10', \"Courtesy of OpenStax. Used under CC BY. Aorta Superior vena cava Left pulmonary artery Right pulmonary artery Left atrium Pulmonary trunk Left pulmonary veins Right pulmonary veins Mitral (bicuspid) valve Right atrium Aortic valve Fossa ovalis Tricuspid valve Pulmonary valve Right ventricle Left ventricle Chordae tendineae Papillary muscle Trabeculae carneae Interventricular septum Epicardium Moderator band Myocardium Inferior vena cava Endocardium Anterior view Figure 1: The major chambers, valves, and blood vessels of the human heart. mechanical systems, allowing one to see how events in an EKG align with the physical state of the heart, as shown in Figure 2. 2.4 Cardiac Diseases Given the complex structure of the heart, cardiac diseases are organized based on abnormalities or failures in the following different functions (with example diseases in parentheses): Contractile Function (heart failure) Coronary Blood Supply (coronary artery disease, myocardial infarction) Circulatory Flow (aortic or mitral stenosis/regurgitation) Heart Rhythm (atrial fibrillation, ventricular tachycardia) 2.5 Wrapup of Cardiac Biology So far, our discussion of the heart has focused on examining it as a muscular organ responsible for pumping blood. However, there is a ton of biology here apart from pumping - in fact, only 31% of of cardiac cells are cardiomyocytes, the muscle cells responsible for the heart's contractions. As a result, cardiac function (and, as a result, cardiac disease) comes from the interaction of a very diverse and large group of cells, ranging from endothelial cells, fibroblasts, leukocytes, and more. 3 Major Types of Cardiac Diagnostics and How They are Used Cardiology is by its nature extremely imaging-centric, making it an expensive field of medical study. There exist a large variety of various imaging techniques that each play critical roles in diagnosis. Here is a brief overview of some of the most important ones: EKG - An extremely cheap technique based on measuring voltage differences in the heart over time. Can be used, for example, to diagnose myocardial infarction. 6.S897/HST.956 Machine Learning for Healthcare - Lec10\", \"Non-skilled acquisition Skilled sonographer (primary care) Low cost handheld ultrasound Costly full ultrasound system Automated interpretation Expert cardiologist interpretation Early in disease course Late in disease course Decision support regarding initiation Difficult decisions regarding or intensification of therapy surgery Low liability $ High liability $$$ Figure 5: The left side shows the benefits of having an automated pipeline for echocardiogram interpretation in contrast to the right side without it. We see that both niches fulfill high reward, but the left is low risk and the right is high risk. For early stages, it would be beneficial to use the automated pipeline for low liability, low cost, and quick decisions for whether further analysis is needed. For late stages, it would be better to use a more trusted skilled sonographer, more expensive ultrasound equipment, and an expert interpretation. 6.5 Purpose of automated disease detection Several rare diseases (e.g. mitral valve prolapse) would benefit from referral to cardiologist or specialty centers Diagnoses tend to be missed at centers that see them infrequently (e.g. cardiac amyloidosis) Automated disease detection provides another pillar of support for definitive diagnoses 7 Rethinking the future of automated interpretation: lessons Deo's predictions for the future of cardiac imaging: 1. Routine measurements will be made in an automated way 2. Some automated diagnoses may happen at point-of-care, e.g. heart function and fluid accumulation around heart 3. Until image data acquisition is facilitated, the benefits of automated interpretation will be muted 4. Pharmaceutical companies have high motivation to perform high frequency serial imaging to assess whether there are any benefits to medications in clinical trials, and an accurate scalable quantification will be needed for this. 5. Surveillance of daily studies may be useful to enable identification of individuals who may be eligible for clincal trials or newly approved therapies. Deo's uncertainties on automated interpretation: 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 8\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What challenge does cardiac motion pose to high-quality imaging scans?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What challenge does cardiac motion pose to high-quality imaging scans?', [\"4 Where's the Data? 4.1 How is Medical Imaging Data Stored DICOM is the major international standard for storing imaging information. Image/video files are stored in a compressed DICOM format, which includes a header that contains info or characteristics about the image. Several free, open access libraries or software exist for compressing/uncompressing DICOM files, viewing the corresponding images, and reading or editing the header. Most imaging data data can be found stored in data archives. 4.2 Gaining Access to Data Ultimately, access to imaging data can be quite limited due to the following reasons: Some images have burned in pixels with patient PII Vendors don't necessarily make it easy for users to download or de-identificate data, perhaps due to their motivation to make it difficult for users to switch vendors Some systems have monetized the data access pipelines, making it almost prohibitively expensive to access imaging data Another obstacle is that labels (like physiological measurements or diagnoses) are, in many cases, stored separately in electronic health record data, forcing researchers to look for data across multiple sources. One clear trend related to imaging data is that, as the cost of the study increases and/or the perceived utility of the data decreases, the availability of data goes down. As an example, an imaging technique like PET that is very expensive has only 8000 studies available at Brigham and Women's Hospital, whereas over 30 million EKGs can be accessed. 4.3 Characteristics of Medical Imaging Data One of the major issues with obtaining high quality cardiac images is that, as the patient breathes, the chest wall and the heart are both continuously moving. Thus, high quality scans need to get enough temporal frequency on their data acquisition SO that the movement of the heart doesn't affect the imaging. Another solution to image corruption resulting from cardiac motion can be found in the technique known as gating, in which the cardiologist lines up corresponding portions of different heartbeats from EKG data with images, allowing him or her to average the images to obtain a lower noise measurement. A summary of the characteristics of various cardiac imaging techniques can be found in Figure 3. 5 Computer Vision Topics Relevant to Cardiac Imaging The major question to ask when trying to apply machine learning techniques to cardiology is: what physician practices can we mimic? Currently, all cardiac measurements, ranging from computing volumes of cardiac chambers to measuring ventricular thickness, are performed manually by hand. Moreover, some disease diagnoses require cardiologists manually classifying images or videos. Fortunately, many current priorities in CV are of great interest to cardiac imaging as a result. 5.1 Image Classification In image classification, the goal is to assign a label to a given image or video. This is a ripe candidate for applying supervised machine learning techniques to cardiology. There are many simple disease recognition tasks in medicine such as identifying lung cancer, pneumonia, or breast cancer, although physicians are 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 4\", '© Julian Andrés Betancur Acevedo. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Electrocardiogram Phonocardiogram 1st 2nd 120 Aortic valve Aortic pressure LV pressure LA pressure 80 Aortic valve closes Pressure (mmHg) 40 valve AV valve closes opens 0 130 Ventricular volume (mL) 100 70 Atrio-ventricular valves Open Close Open Aortic and pulmonary valves Close Open Close Phase 2a 2b Left atrium Right atrium Left ventricle Right ventricle Ventricular filling Contraction of atria Isovolumetric Ventricular Isovolumetric Ventricular filling contraction ejection relaxation Ventricular filling Ventricular systole Protodiestole (mid-diastole to end-diastole) (atria in diastole) Figure 2: An example of a Wiggers Diagram. Echocardiography - A more expensive technique that uses ultrasound tech to make measurements. Can be used to get general understanding of cardiac structure and thus diagnose, for example, heart failure, valvular disease, and pulmonary hypertension. MRI - One of the most expensive imaging techniques. More expensive than echocardiography but achieves very similar diagnostic functions, SO it is not used all that much in the US. SPECT/PET - Non-invasive techniques, but also extremely expensive. Can be used, for example, to infer coronary artery disease or diagnose microvascular disease. One interesting characteristic of cardiac diagnostics is that diseases are not defined based on biology, but rather based on measurements that depart from \"normal\" anatomic or phsiological values. This may be due to the limitations in our ability to study or image the human heart, but it\\'s not clear whether this is ultimately for the better or worse. In cardiology, clinical decisions regarding treatments for diagnosed diseases are often, but not always, guided in part by inputs from cardiac imaging. Ultimately, a few different factors affect the role of imaging in cardiology. First, although imaging can lead to data with extremely high information content, decisions regarding treatment are affected in large part by historical studies that follow patients with the disease of interest over long time periods. Secondly, cardiologists are often stuck with the data that is already out there because someone decided it was worth paying for. The available data often controls the risk model and decision analysis you can undertake. Finally, while imaging data can be found for patients with diseases for which the imaging process is seen as an essential part of the commonly accepted management plan, it is much more difficult to obtain imaging data for other diseases or patient populations given the high cost. As a result, doctors are often stuck with the stuff that they already know something about. 6.S897/HST.956 Machine Learning for Healthcare - Lec10', \"Echo Studies (14035) View Classification View Probability (277) Quality Score Segmentation Disease Detection: for 5 views HCM (495/2244) (791*) PAH (584/2487) Amyloid (179/804) Cardiac Structure: Cardiac Function: Mass and Volume Ejection Fraction (8666) (6407) Longitudinal Strain (526) Figure 6: Zhang, Deo, et al.'s [TZDD18] approach to an automated pipeline for echocardiogram interpre- tation. 1. We should be using automated interpretation to elevate medicine beyond the current practice, but we need larger dataset and more images than what we currently have. 2. Disease classifications are currently crude and finer distinctions can be made between disease states. 3. Survival models are crude and better predictive models should be possible with imaging data and emerging algorithms. 4. Physicians are only interested in classifications or risk models that will change and improve practice, thus evidence is required to justify a shift. 5. There is the question of how more data will be obtained and dispersed for research. 8 Biology There are some goals in biology that can be accomplished to facilitate cardiac machine learning. First, clinical datasets lack the scale and expressivity needed to reflect underlying biological processes. We need a data type that has the dimensionality to capture biological heterogeneity and complexity and yet can still be collected in a very scaleable manner. It is likely that we shouldn't look at expensive sequencing technolo- gies and costly medical imaging to accomplish this. Accomplishing this would help expand the biological phenotypic space. Another thing is that we should focus on studying individual circulating blood cells. Circulating blood cells are causally implicated in coronary heart disease (CHD) pathogensis. These blood cells are also easily 6.S897/HST.956 Machine Learning for Healthcare - Lec10\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is a significant benefit of applying machine learning to cardiac imaging?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is a significant benefit of applying machine learning to cardiac imaging?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 10: Application of Machine Learning to Cardiac Imaging Instructors: David Sontag, Peter Szolovits 1 Background This lecture was a guest lecture by Rahul Deo, the lead investigator of the One Brave Idea project at Brigham and Women's Hospital. Rahul is also Adjunct Associate Professor at UC San Francisco and a member of the faculty at Harvard Medical School. He talked about how machine learning techniques are being used and can be used further to augment cardiac imaging. 2 Introduction to Cardiac Structure and Function Before considering the applications of machine learning to cardiology, it's important to understand the field of cardiology a bit better. In particular, why should we care about cardiology in the first place? For one, coronary heart disease, or CHD (the hardening of arteries that transport blood to the heart), is the leading cause of death globally. And this is something that holds true for both developing and developed countries alike. Since cardiology is ultimately about biological diseases like CHD, it's a good idea to get a better understanding of the biology of the heart before moving on to look at how machine learning can disrupt the field. 2.1 Cardiac Function The heart's primary function is to pump oxygenated blood throughout our circulatory system. The continual flow of blood is not only critical to deliver oxygen necessary for ATP (energy) production to all our tissues, but also to transport signaling molecules throughout our body and remove waste from cells. As a result, the volume of blood flow is quite large: the heart pumps 5 liters of blood every minute, a number that can grow to as much as 35 liters per minute during intense exercise. One crucial aspect of cardiac function is that the body must maintain extremely rhythmic beating of the heart, a not inconsequential task given that the average human heart generates a total of more than 2 billion heartbeats over a lifetime. 2.2 Structure of the Heart Figure 1 above gives an overview of the structure of the human heart. Blood comes in through the superior vena cava into a chamber called the right atrium, from where it passes into the right ventricle. The right ventricle pumps blood to the lungs, and the newly oxygenated blood then flows via the pulmonary veins to the left atrium. Finally, the left ventricle pumps blood to the rest of the body via the aorta. Thus, the heart essentially conducts 2 circulations in series: a pulmonary circulation to pump deoxygenated blood to the lungs, and a systemic circulation to pump newly oxygenated blood to the rest of the body. In addition, the heart also has 4 different valves (mitral, tricuspid, aortic, pulmonary) that control flow of blood out of the heart's four chambers. 2.3 The Cardiac Cycle As the heart pumps, it cycles between periods of relaxation called diastole, in which the heart is filled with blood, and periods of contraction called systole, in which the heart pumps out blood. This regular mechanical motion is coordinated by synchronized electrical activity, which can be visualized in an electrocardiogram (EKG). A Wiggers Diagram can be used to demonstrate the interconnectedness of these electrical and 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 1\", 'Time Risk factors Hemming and deviate from hawing regarding Death optimal values lifestyle changes and disability blood pressure LDL/VLDL cholesterol Treatment may be weight (grudgingly) blood sugar initiated Symptoms develop anti-hypertensives cholesterol-lowering dyspnea Therapeutic anti-diabetics angina Responsiveness $$$ Figure 4: A rough timeline on patients with cardiovascular disease. (a) Expressive - captures complex underlying processes (molecular, cellular, imaging ...) (b) Multidimensional - Can\\'t readily be \"gamed\" 3. Pipeline should be ameliorated with therapy (c.f. genetic risk) The role for the fully automated pipeline for echocardiogram interpretation would be at the \"low risk - high reward\" portion of the current spectrum. See Figure 5 6.3 Focus of machine learning in cardiac diseases We can use machine learning to: 1. enable much greater of volumes of data to be interpreted, SO that we reduce costs of acquisition and interpretation, as well as augment interpretations of simple data. 2. augment surveillance within a hospital system, e.g. patient identification for therapies 3. perform triage, i.e. automating ECG interpretation in urgent situations in the ambulance/ER To illustrate the need of machine learning to perform rapid triage, we provide an example. In the early 2000\\'s, it was recognized that any delay in angioplasty and stenting would result in irreversible damage to the heart. Thus, the solution was to replace a cardiologist reviewing the ECG with a rapid triage system by ambulance personnel or ED physicians for quicker turnover. However, this resulted in an increase in false positives. Thus, there is still a need for a fast pipeline that has high quality. 6.4 Zhang, Deo, et al. approach to Automated Approach for Echo interpreta- tion An echo study is typically a collection of up to 70 videos of the heart taken over multiple cardiac cycles and focusing on different viewpoints. The heart is visualized from ¿10 different views, and still images are typi- cally included to enable manual measurements. ¿7,000,000 echo studies are performed annually in Medicare population alone, and there are likely (an estimate by Deo) of about 100,000,000\\'s of archived echo studies. Zhang et al. built a pipeline using 14k raw echo studies and traditional computer vision algorithms for view classification and segmentation into 5 views to perform cardiac structural and functional analysis. This is an automated and low cost approach to echo interpretation. See Figure 6. 6.S897/HST.956 Machine Learning for Healthcare - Lec10 7', \"4 Where's the Data? 4.1 How is Medical Imaging Data Stored DICOM is the major international standard for storing imaging information. Image/video files are stored in a compressed DICOM format, which includes a header that contains info or characteristics about the image. Several free, open access libraries or software exist for compressing/uncompressing DICOM files, viewing the corresponding images, and reading or editing the header. Most imaging data data can be found stored in data archives. 4.2 Gaining Access to Data Ultimately, access to imaging data can be quite limited due to the following reasons: Some images have burned in pixels with patient PII Vendors don't necessarily make it easy for users to download or de-identificate data, perhaps due to their motivation to make it difficult for users to switch vendors Some systems have monetized the data access pipelines, making it almost prohibitively expensive to access imaging data Another obstacle is that labels (like physiological measurements or diagnoses) are, in many cases, stored separately in electronic health record data, forcing researchers to look for data across multiple sources. One clear trend related to imaging data is that, as the cost of the study increases and/or the perceived utility of the data decreases, the availability of data goes down. As an example, an imaging technique like PET that is very expensive has only 8000 studies available at Brigham and Women's Hospital, whereas over 30 million EKGs can be accessed. 4.3 Characteristics of Medical Imaging Data One of the major issues with obtaining high quality cardiac images is that, as the patient breathes, the chest wall and the heart are both continuously moving. Thus, high quality scans need to get enough temporal frequency on their data acquisition SO that the movement of the heart doesn't affect the imaging. Another solution to image corruption resulting from cardiac motion can be found in the technique known as gating, in which the cardiologist lines up corresponding portions of different heartbeats from EKG data with images, allowing him or her to average the images to obtain a lower noise measurement. A summary of the characteristics of various cardiac imaging techniques can be found in Figure 3. 5 Computer Vision Topics Relevant to Cardiac Imaging The major question to ask when trying to apply machine learning techniques to cardiology is: what physician practices can we mimic? Currently, all cardiac measurements, ranging from computing volumes of cardiac chambers to measuring ventricular thickness, are performed manually by hand. Moreover, some disease diagnoses require cardiologists manually classifying images or videos. Fortunately, many current priorities in CV are of great interest to cardiac imaging as a result. 5.1 Image Classification In image classification, the goal is to assign a label to a given image or video. This is a ripe candidate for applying supervised machine learning techniques to cardiology. There are many simple disease recognition tasks in medicine such as identifying lung cancer, pneumonia, or breast cancer, although physicians are 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 4\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', ['6.S897/HST.956 Machine Learning for Healthcare Lecture 13: Machine Learning for Mammography Instructors: David Sontag, Peter Szolovits 1 Breast Image Interpretation: Background and Challenges Breast cancer affects over 2 million women of the 3.8 billion women globally, and is estimated to contribute to over 40,000 U.S. deaths and 600,000 worldwide deaths annually. The primary method for breast cancer diagnosis is the interpretation of mammography images, which are breast X-ray images. Mammograms are normally acquired from two different angles: craniocaudal (CC, which is a 2D projection of the axial view), and mediolateral oblique (MLO, which is a 2D projection of the frontal coronal view). Ideally, we would like to use these images for early detection of breast cancer, which would allow for more effective treatments and potential cures. It is particularly important to detect cancerous tissue before the non- metatstatic to metastatic transition, after which a cure is no longer feasible. The two primary challenges with mammographic analysis for this purpose are: Accurate risk assessment tools Effective screening tests Specifically, the three main problems that need to be addressed to resolve these challenges are: No risk assessment models are able to predict individual risk accurately There is significant variability in human interpretation of mammograms Widespread standardization and application of mammography are limited by the dearth of specialial- ists. 1.1 Mammogram interpretation The two questions that radiologists ask when analyzing a mammogram are: How dense is the breast tissue? Is it a normal or abnormal mammogram? In a mammogram (an example of which is given in Figure 1, the white pixels represent the breast tissue and black pixels represent fatty tissue inside the breasts; thus, breasts with higher densities of white pixels have higher breast density. The current standard medical practice is for radiologists to bin the tissue density into four categories: fatty (low density), scattered, heterogeneously dense, and dense. However, since cancerous tumors are also small blobs of white pixels, dense breast tissue can sometimes obscure or make it more difficult to detect anomalous cancerous tissues. The difficulty of finding small cancerous tissue in mammograms is illustrated by the case studies in Figure 2. Because of the 2D nature of traditional mammograms, patients with higher breast densities tend to receive more false negative mammograms, in which cancerous tissue is mistakenly diagnosed as healthy. This is shown in Figure 3, in which a 3D reconstruction of the breast tissue acquired using tomosynthesis (in which optical slices in the axial dimension are taken for 3D tomography) shows that cancerous tissue was missed in the 2D projection due to breast density. Although false negatives are the least frequent type of mammogram, it is particularly devastating because of the consequences it entails for the affected patient, who does not receive the appropriate treatment or care. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 1', \"2.1.2 Challenges of applying DL to mammogram triaging While many aspects of the task of cancer detection based on mammograms are similar to that of natural image classification (ImageNet), there are some key differences that make this task tricky. First of all, the signal-to-noise-ratio (SNR) is much lower in mammograms compared to natural images. In other words, the cancerous tissue and region that is relevant for image classification is much smaller (tends to be around 1% of the image, exemplified in Figure 2) than the size of the relevant object(s) in natural images. The images in mammogram datasets are also much larger than natural images. For instance, mammograms tend to be on the order of 3000 by 2600 pixels, whereas ImageNet images tend to be orders of magnitude smaller. This leads to issues with memory and parallelization - in particular, the batch size is limited, which makes the stochastic gradient updates much noisier, and can impede model learning. Large individual images also just presents memory and storage issues in general; for example, the data set for this particular project was over 12 TB. Image size and low SNR ratio both lead to a separate challenge: if patches are used, this can lead to removal of important context, which can make it difficult to differentiate between cancerous and non-cancerous tissues. Lastly, if patch-based data is used, there is a heavy class imbalance, in that only around 0.7% of the inputs are positive, while the vast majority are negatives. While there are methods for resolving this being actively researched and implemented in the machine learning community, it is still a non-trivial challenge. 2.1.3 Building the model In building the DL model, the first thign considered was initialization of the model. Adam Yala and colleagues decided to use ImageNet pre-trained CNN models (e.g. VGG, ResNet, Wide-ResNet, DenseNet) to initialize the network, and then to mitigate the small batch size issue (talked about in section 2.1.2) that is a result of the large size of the images, they performed several forward and backpropagation steps through the network before updating the weights via gradient descent. In essence, this allows them to use a larger batch size than GPU memory allows, but doing it in series rather than in parallel. For this, they utilized a batch size of 24 (by taking 2 full steps with batch size 3 distributed over 4 GPU's). They found that initializing with ImageNet allowed for learning to occur much quicker (demonstrated in Figure 5) than when initializing the model randomly. One possible explanation for this is that the batch normalization statistics are more stable to begin with when using pre-trained weights from ImageNet. ImageNet-Init Random-Init 10 7.5 Train Loss 5 2.5 0 0 5 10 15 20 25 Figure 5: Loss VS. Epoch with ImageNet initialization and random initialization. ImageNet initialization allows for learning to occur quicker. In selecting a base architecture of the model, they preferred models that were fully convolutional to allow for flexibility in feeding in inputs of varying resolutions; thus, the ResNet-18 model was chosen. This was 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 5\", \"[Image removed due to copyright restrictions.] Figure 1: Mediolateral oblique (MLO) view of a breast mammography with relevant components labeled. [And12] Prior Current Prior Current Figure 2: Two examples of time-evolving mammograms with developing cancerous tissue, indicated by the red circles. The cancerous tissue is small and blends in with the rest of the breast tissue. © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ 1.2 Risk assessment For early detection of breast cancer, it's important for accurate risk assessment tools to be available to interpret mammograms. With more accurate risk forecasting, more action can be taken prior to lymph node localization or metastasis. While false negatives (as described in Section 1.1) are particularly harmful to individuals, false positive mammograms can also have deleterious effects on patients. The side effects of chemotherapy or radiation therapy can be particularly damaging to a patient, especially if they are a false positive. Thus, the preferred method of investigating perceived high-risk patients is through the use of magnetic resonance imaging (MRI), which is an extremely useful but expensive non-invasive imaging tool. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 2\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the four categories of breast tissue density used in medical practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the four categories of breast tissue density used in medical practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are the four categories of breast tissue density used in medical practice?', ['6.S897/HST.956 Machine Learning for Healthcare Lecture 13: Machine Learning for Mammography Instructors: David Sontag, Peter Szolovits 1 Breast Image Interpretation: Background and Challenges Breast cancer affects over 2 million women of the 3.8 billion women globally, and is estimated to contribute to over 40,000 U.S. deaths and 600,000 worldwide deaths annually. The primary method for breast cancer diagnosis is the interpretation of mammography images, which are breast X-ray images. Mammograms are normally acquired from two different angles: craniocaudal (CC, which is a 2D projection of the axial view), and mediolateral oblique (MLO, which is a 2D projection of the frontal coronal view). Ideally, we would like to use these images for early detection of breast cancer, which would allow for more effective treatments and potential cures. It is particularly important to detect cancerous tissue before the non- metatstatic to metastatic transition, after which a cure is no longer feasible. The two primary challenges with mammographic analysis for this purpose are: Accurate risk assessment tools Effective screening tests Specifically, the three main problems that need to be addressed to resolve these challenges are: No risk assessment models are able to predict individual risk accurately There is significant variability in human interpretation of mammograms Widespread standardization and application of mammography are limited by the dearth of specialial- ists. 1.1 Mammogram interpretation The two questions that radiologists ask when analyzing a mammogram are: How dense is the breast tissue? Is it a normal or abnormal mammogram? In a mammogram (an example of which is given in Figure 1, the white pixels represent the breast tissue and black pixels represent fatty tissue inside the breasts; thus, breasts with higher densities of white pixels have higher breast density. The current standard medical practice is for radiologists to bin the tissue density into four categories: fatty (low density), scattered, heterogeneously dense, and dense. However, since cancerous tumors are also small blobs of white pixels, dense breast tissue can sometimes obscure or make it more difficult to detect anomalous cancerous tissues. The difficulty of finding small cancerous tissue in mammograms is illustrated by the case studies in Figure 2. Because of the 2D nature of traditional mammograms, patients with higher breast densities tend to receive more false negative mammograms, in which cancerous tissue is mistakenly diagnosed as healthy. This is shown in Figure 3, in which a 3D reconstruction of the breast tissue acquired using tomosynthesis (in which optical slices in the axial dimension are taken for 3D tomography) shows that cancerous tissue was missed in the 2D projection due to breast density. Although false negatives are the least frequent type of mammogram, it is particularly devastating because of the consequences it entails for the affected patient, who does not receive the appropriate treatment or care. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 1', '100 75 50 25 © American College of Physicians. All rights reserved. This content is 0 excluded from our Creative Commons license. For Radiologist (n=83) more information, see https://ocw.mit.edu/help/ Extremely dense Heterogeneously dense Scattered fibroglandular elements faq-fair-use/ Almost entirely fat Figure 4: Variation in radiologist assessment of breast density. Radiologists vary in \"dense\" breast tissue classification rates from 6% to 85% [SCO+16] 3. Clinical implementation In this section, we introduce the development of a model for automated mammogram triaging and another model for risk assessment. 2.1 Mammogram triaging The goal of the mammogram triaging model is to improve efficiency by reducing the false positives of cancer triaging (especially since >99% of patients are cancer-free). Given a cancer-free threshold that is set from training and development of the algorithm, the triaging process can be streamlined for radiologists by having them skip analysis of mammograms below the threshold. 2.1.1 Dataset collection Data was collected from mammograms in 5 hospital registries, and patient outcomes from Radiology EHR and Partners. These data were pulled from all available screening mammograms between January 2009 and December 2016 (inclusive), with no exclusions made based on race, age, implants or other features of that nature; however, patients with other cancers in the breast were excluded as well as patients with negative exams that did not have a 1-year followup. After these exclusions, there remained 223,109 distinct mammograms from 66,661 unique patients. Since some patients had multiple data points, the training, developmental (dev), and test sets were split by patient to prevent model memorization of patient inputs. The training set contained 1,472 positive exams (1,453 unique patients) and 210,804 negative exams (56,790 unique patients); the development set contained 167 positive exams (163 unique patients) and 25,832 negative exams (7,019 unique patients); the test set contained 191 positive exams (187 unique patients) and 26,349 negative exams (7,170 unique patients). 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 4', '2D FFDM Tomosynthesis Slice VENETU LECCS Cyst Lobular Carcinoma Figure 3: 2D VS. 3D Tomosynthesis mammograms. The 2D projection obscures the cancerous tissues that the tomosynthesis reveals. Images courtesy of Drs. Di Maggio G Gennaro, Istituto Oncologico Veneto I.R.C.C.S. (Padova, Italia) © Maggio and Gennaro. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ However, classical risk models are quite limited, in that they use some basic patient features (e.g. age, race, breast density, family history) to generate risk assessment, and oftentimes are quite sensitive to certain vari- ables. Additionally, the subjective categorization of tissue density (as described in Section 1.1) is subject to high variance between different radiologists, making that qualitative feature somewhat unreliable in classical risk models. We can see this exemplified in Figure 4. The limitations of current clinical risk assessment procedures are elegantly captured by the fact that 75% of all early MRI screens are performed in women with less than 20% lifetime risk, while only 2% of the women with over 20% lifetime risk receive an early MRI. In this sense, the current risk assessment tools are unable to be effective because they are not correctly screening the at-risk population. 2 Deep learning models for mammogram interpretation The usual process for triaging mammograms can be described by the following steps: 1. Routine screening (1000 patients) 2. Callback for additional imaging (100 patients) 3. Biopsy sample collection (20 patients) 4. Diagnosis / triage (6 patients) To harness deep learning (DL) for mammogram triaging or risk assessment, we follow a standard procedure for clinical deployment and utilization: 1. Dataset collection 2. Modeling 6.S897/HST.956 Machine Learning for Healthcare - Lec13 3'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', ['2D FFDM Tomosynthesis Slice VENETU LECCS Cyst Lobular Carcinoma Figure 3: 2D VS. 3D Tomosynthesis mammograms. The 2D projection obscures the cancerous tissues that the tomosynthesis reveals. Images courtesy of Drs. Di Maggio G Gennaro, Istituto Oncologico Veneto I.R.C.C.S. (Padova, Italia) © Maggio and Gennaro. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ However, classical risk models are quite limited, in that they use some basic patient features (e.g. age, race, breast density, family history) to generate risk assessment, and oftentimes are quite sensitive to certain vari- ables. Additionally, the subjective categorization of tissue density (as described in Section 1.1) is subject to high variance between different radiologists, making that qualitative feature somewhat unreliable in classical risk models. We can see this exemplified in Figure 4. The limitations of current clinical risk assessment procedures are elegantly captured by the fact that 75% of all early MRI screens are performed in women with less than 20% lifetime risk, while only 2% of the women with over 20% lifetime risk receive an early MRI. In this sense, the current risk assessment tools are unable to be effective because they are not correctly screening the at-risk population. 2 Deep learning models for mammogram interpretation The usual process for triaging mammograms can be described by the following steps: 1. Routine screening (1000 patients) 2. Callback for additional imaging (100 patients) 3. Biopsy sample collection (20 patients) 4. Diagnosis / triage (6 patients) To harness deep learning (DL) for mammogram triaging or risk assessment, we follow a standard procedure for clinical deployment and utilization: 1. Dataset collection 2. Modeling 6.S897/HST.956 Machine Learning for Healthcare - Lec13 3', '6.S897/HST.956 Machine Learning for Healthcare Lecture 13: Machine Learning for Mammography Instructors: David Sontag, Peter Szolovits 1 Breast Image Interpretation: Background and Challenges Breast cancer affects over 2 million women of the 3.8 billion women globally, and is estimated to contribute to over 40,000 U.S. deaths and 600,000 worldwide deaths annually. The primary method for breast cancer diagnosis is the interpretation of mammography images, which are breast X-ray images. Mammograms are normally acquired from two different angles: craniocaudal (CC, which is a 2D projection of the axial view), and mediolateral oblique (MLO, which is a 2D projection of the frontal coronal view). Ideally, we would like to use these images for early detection of breast cancer, which would allow for more effective treatments and potential cures. It is particularly important to detect cancerous tissue before the non- metatstatic to metastatic transition, after which a cure is no longer feasible. The two primary challenges with mammographic analysis for this purpose are: Accurate risk assessment tools Effective screening tests Specifically, the three main problems that need to be addressed to resolve these challenges are: No risk assessment models are able to predict individual risk accurately There is significant variability in human interpretation of mammograms Widespread standardization and application of mammography are limited by the dearth of specialial- ists. 1.1 Mammogram interpretation The two questions that radiologists ask when analyzing a mammogram are: How dense is the breast tissue? Is it a normal or abnormal mammogram? In a mammogram (an example of which is given in Figure 1, the white pixels represent the breast tissue and black pixels represent fatty tissue inside the breasts; thus, breasts with higher densities of white pixels have higher breast density. The current standard medical practice is for radiologists to bin the tissue density into four categories: fatty (low density), scattered, heterogeneously dense, and dense. However, since cancerous tumors are also small blobs of white pixels, dense breast tissue can sometimes obscure or make it more difficult to detect anomalous cancerous tissues. The difficulty of finding small cancerous tissue in mammograms is illustrated by the case studies in Figure 2. Because of the 2D nature of traditional mammograms, patients with higher breast densities tend to receive more false negative mammograms, in which cancerous tissue is mistakenly diagnosed as healthy. This is shown in Figure 3, in which a 3D reconstruction of the breast tissue acquired using tomosynthesis (in which optical slices in the axial dimension are taken for 3D tomography) shows that cancerous tissue was missed in the 2D projection due to breast density. Although false negatives are the least frequent type of mammogram, it is particularly devastating because of the consequences it entails for the affected patient, who does not receive the appropriate treatment or care. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 1', 'incomplete version of the data set. Another potential pitfall to automated mammogram interpretation is to interpret performance on reader studies as if they were clinical implementations. Reader studies should not be interpreted this way not only because of the dataset pitfalls mentioned previously, but because oftentimes inconvenient cases are excluded from the data set. For instance, a research study might filter out a dataset by breast size, or race, due to insufficient data points, or some other reason of analysis inconvenience. This will certainly further bias the dataset towards certain demographics and types of mammograms, thus making it non-generalizable and unsuitable for clinical implementation. 3 Future outlook In the past, traditional computer-aided diagnosis (CAD) did not perform well in mammogram interpretation, and was primarily used as a money-driven endeavor. With the development of new imaging modalities such as tomosynthesis (which takes 2D optical sections of the breast to provide a 3D reconstruction), AI technology and hospitals have struggled to keep up. However, combined with ever-increasing amounts of data, recent applications of deep learning towards mammogram triaging and risk assessment have greatly improved upon classical methods, providing a promising outlook of a more efficient and life-saving clinical pipeline. References [And12] Savvas Andronikou. The Breast, pages 359-375. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012. [SCO+16] B.L. Sprague, E.F. Conant, T. Onega, E.F. Beaber, S.D. Herschorn, C.D. Lehman, A.N. Toste- son, R. Lacson, M.D. Schnall, D. Kontos, J.S. Haas, D.L. Weaver, W.E. Barlow, and PROSPR Consortium. Variation in mammographic breast density assessments among radiologists in clinical practice: A multicenter observational study. Ann Intern Med, 165(7):457-464, 2016. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 9'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', [\"2.1.2 Challenges of applying DL to mammogram triaging While many aspects of the task of cancer detection based on mammograms are similar to that of natural image classification (ImageNet), there are some key differences that make this task tricky. First of all, the signal-to-noise-ratio (SNR) is much lower in mammograms compared to natural images. In other words, the cancerous tissue and region that is relevant for image classification is much smaller (tends to be around 1% of the image, exemplified in Figure 2) than the size of the relevant object(s) in natural images. The images in mammogram datasets are also much larger than natural images. For instance, mammograms tend to be on the order of 3000 by 2600 pixels, whereas ImageNet images tend to be orders of magnitude smaller. This leads to issues with memory and parallelization - in particular, the batch size is limited, which makes the stochastic gradient updates much noisier, and can impede model learning. Large individual images also just presents memory and storage issues in general; for example, the data set for this particular project was over 12 TB. Image size and low SNR ratio both lead to a separate challenge: if patches are used, this can lead to removal of important context, which can make it difficult to differentiate between cancerous and non-cancerous tissues. Lastly, if patch-based data is used, there is a heavy class imbalance, in that only around 0.7% of the inputs are positive, while the vast majority are negatives. While there are methods for resolving this being actively researched and implemented in the machine learning community, it is still a non-trivial challenge. 2.1.3 Building the model In building the DL model, the first thign considered was initialization of the model. Adam Yala and colleagues decided to use ImageNet pre-trained CNN models (e.g. VGG, ResNet, Wide-ResNet, DenseNet) to initialize the network, and then to mitigate the small batch size issue (talked about in section 2.1.2) that is a result of the large size of the images, they performed several forward and backpropagation steps through the network before updating the weights via gradient descent. In essence, this allows them to use a larger batch size than GPU memory allows, but doing it in series rather than in parallel. For this, they utilized a batch size of 24 (by taking 2 full steps with batch size 3 distributed over 4 GPU's). They found that initializing with ImageNet allowed for learning to occur much quicker (demonstrated in Figure 5) than when initializing the model randomly. One possible explanation for this is that the batch normalization statistics are more stable to begin with when using pre-trained weights from ImageNet. ImageNet-Init Random-Init 10 7.5 Train Loss 5 2.5 0 0 5 10 15 20 25 Figure 5: Loss VS. Epoch with ImageNet initialization and random initialization. ImageNet initialization allows for learning to occur quicker. In selecting a base architecture of the model, they preferred models that were fully convolutional to allow for flexibility in feeding in inputs of varying resolutions; thus, the ResNet-18 model was chosen. This was 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 5\", 'incomplete version of the data set. Another potential pitfall to automated mammogram interpretation is to interpret performance on reader studies as if they were clinical implementations. Reader studies should not be interpreted this way not only because of the dataset pitfalls mentioned previously, but because oftentimes inconvenient cases are excluded from the data set. For instance, a research study might filter out a dataset by breast size, or race, due to insufficient data points, or some other reason of analysis inconvenience. This will certainly further bias the dataset towards certain demographics and types of mammograms, thus making it non-generalizable and unsuitable for clinical implementation. 3 Future outlook In the past, traditional computer-aided diagnosis (CAD) did not perform well in mammogram interpretation, and was primarily used as a money-driven endeavor. With the development of new imaging modalities such as tomosynthesis (which takes 2D optical sections of the breast to provide a 3D reconstruction), AI technology and hospitals have struggled to keep up. However, combined with ever-increasing amounts of data, recent applications of deep learning towards mammogram triaging and risk assessment have greatly improved upon classical methods, providing a promising outlook of a more efficient and life-saving clinical pipeline. References [And12] Savvas Andronikou. The Breast, pages 359-375. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012. [SCO+16] B.L. Sprague, E.F. Conant, T. Onega, E.F. Beaber, S.D. Herschorn, C.D. Lehman, A.N. Toste- son, R. Lacson, M.D. Schnall, D. Kontos, J.S. Haas, D.L. Weaver, W.E. Barlow, and PROSPR Consortium. Variation in mammographic breast density assessments among radiologists in clinical practice: A multicenter observational study. Ann Intern Med, 165(7):457-464, 2016. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 9', 'shown in Figure 9. Thus, we see that harnessing deep learning can have real potential to improve the risk assessment models that are used currently. Tyrer-Cuzick Image DL Image + RF DL 0.68 0.70 0.62 Full Test Set Figure 7: AUC on the test set using various risk models. The deep learning combined with classical features model performed the best. Tyrer-Cuzick Image DL Image + RF DL 0.69 0.71 0.69 0.71 0.62 0.45 White Women African American Women Figure 8: AUC comparison between models on white and African American women sub-populations Tyrer-Cuzick Image + RF DL 0.79 0.73 0.70 0.70 0.71 0.66 0.58 0.59 Figure 9: AUC comparison for various sub-populations, showing that the novel image + features DL model outperforms classical approaches. 2.2.3 Potential pitfalls While deep learning is able to perform particularly well in mammogram interpretation, there are still chal- lenges associated with it before it can achieve widespread clinical implementation. In particular, most data sets collected for mammogram interpretation are enriched, potentially not reflecting the true distribution of the data, and certainly contain biases (e.g. machine-specific collection at a certain hospital). For example, one dataset collected at a hospital in Shanghai had collected all of the cancer-positive data first, before collecting the negatives consecutively. This resulted in a skew dataset when researchers tried to use an 6.S897/HST.956 Machine Learning for Healthcare - Lec13 8'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', ['shown in Figure 9. Thus, we see that harnessing deep learning can have real potential to improve the risk assessment models that are used currently. Tyrer-Cuzick Image DL Image + RF DL 0.68 0.70 0.62 Full Test Set Figure 7: AUC on the test set using various risk models. The deep learning combined with classical features model performed the best. Tyrer-Cuzick Image DL Image + RF DL 0.69 0.71 0.69 0.71 0.62 0.45 White Women African American Women Figure 8: AUC comparison between models on white and African American women sub-populations Tyrer-Cuzick Image + RF DL 0.79 0.73 0.70 0.70 0.71 0.66 0.58 0.59 Figure 9: AUC comparison for various sub-populations, showing that the novel image + features DL model outperforms classical approaches. 2.2.3 Potential pitfalls While deep learning is able to perform particularly well in mammogram interpretation, there are still chal- lenges associated with it before it can achieve widespread clinical implementation. In particular, most data sets collected for mammogram interpretation are enriched, potentially not reflecting the true distribution of the data, and certainly contain biases (e.g. machine-specific collection at a certain hospital). For example, one dataset collected at a hospital in Shanghai had collected all of the cancer-positive data first, before collecting the negatives consecutively. This resulted in a skew dataset when researchers tried to use an 6.S897/HST.956 Machine Learning for Healthcare - Lec13 8', \"Radiologist False Positive Assessments by Risk Percentile FP triaged below threshold FP triaged above threshold 200 150 100 50 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 Risk Percentile Figure 6: With the cancer-free triage threshold of just above 0.2 model-predicted risk percentile, the radiologist's false positives colored in blue can be eliminated by the automated triaging done by the model. triage dataset) patients with negative exams which lacked a 5-year followup exam were excluded because the goal was to predict 5-year breast cancer risk. Once again, the train/dev/test sets were split by patient to prevent model memorization. In the end, the train set had 71,689 mammograms (31,806 unique patients), the validation set had 8,554 mammograms (3,804 unique patients), and the test set contained 8,751 mammograms (3,937 unique patients). The test set was constructed with an additional exclusion of excluding exams within one year of a cancer diagnosis. In this manner, the predictive value of the model could be limited to one temporal image per patient. 2.2.2 Results The objectives of this study were to: Is the model discriminative across all populations? How does the DL model relate to classical models? The same considerations for building the DL model from the previous section are used for this one, and the researchers decided to compare the risk assessment performance of (1) the DL model using image only, (2) DL using image and other classical features (e.g. age, race, breast density), and (3) Tyrer-Cuzick (a classical approach). Briefly, the Tyrer-Cuzick model estimates breast cancer risk from various family history, physical statistics, and demographic data. As shown in Figure 7, the hybrid method using DL image + features achieved an AUC of 0.7, whereas the DL image only model achieved an AUC of 0.68, and the traditional feature-based Tyrer-Cuzick achieved an AUC of 0.62. It is particularly interesting to note that the Tyrer-Cuzick model, since it was trained on only white women, performed especially poorly on risk assessment of African-American women, achieving an AUC of 0.45 (the DL + features model achieved 0.71 AUC, as seen in Figure 8). This is worse than a model that is guessing randomly. Additionally, we see that the DL image + features model is discriminative across different populations by performing significantly better than the Tyrer-Cuzick model on various sub-populations, as 6.S897/HST.956 Machine Learning for Healthcare - Lec13 7\", \"especially important in implementing a two-stage training method in which patches from the mammograms were sampled and fed to the network to pre-train the network, and then followed by fine tuning the model using the full-sized images. The researchers found that with the aforementioned serial batch size method, they could resolve the noisy stochastic gradient problem and directly train the model using the full sized images. Finally, in order to calibrate the class balance to the real incidence of either class, Platt's method is used, in which a sigmoid function is learned to scale and shift the probabilities calculated from the model (based on training data) to the true incidence rate. In this manner, the incidence rate of classes in the training data does not skew the distribution of predictions during inference. The model triaged by ranking radiologist true positives by the probability assigned by the model, and then returning the minimum probability of radiologist-identified true positive in the development set. To evaluate the best model, instead of using AUC, the triage ability of the model on the dev set was used. 2.1.4 Results The objectives of the model during analysis were: Is the model discriminative across all populations? Does the model capture radiologist mistakes or do they overlap? Assess the triage on test set The model achieved an AUC of 0.82 (confidence interval: [0.8, 0.85]) on the dev set, with no statistically significant difference in predictive value between varying ages, races, and breast densities. The main goal of the model was to not miss a single cancer the radiologist would have caught, in order to be used as an aid (and not replacement) for medical professionals. Thus, it is important to assess how the performance compared to radiologist assessments. It was determined that the model was able to triage significant portions of radiologist-assigned true positives, false positives, and true negatives that were below the model's triage threshold, both reducing radiologist labor (on the true positives and negatives) and limiting the false positives (by triaging those below the threshold as cancer-free, shown in Figure 6). These results are summarized quantitatively in Table 1, with the model increasing specificity by 0.7% and reducing the % of mammograms read by radiologist by 20%. Setting Sensitivey (95% Specificity (95% Mammograms CI) CI) Read (95% CI) Original Interpreting Radiologist 90.6% (86.7, 94.8) 93.0% (92.7, 93.3) 100% (100, 100) Original Interpreting Radiologist 90.1% (86.1, 94.5) 93.7% (93.0, 94.4) 80.7% (80.0, 81.5) + Triage Table 1: Test set triage simulation results. 2.2 Mammogram risk assessment 2.2.1 Dataset collection and model construction A similar method was followed to build a DL model for mammogram risk assessment. Here, the data set was constructed similarly by using mammogram images from a 5 Hospital Registry and patient outcomes from Radiology EHR and Partners from January 2009 to December 2012 with no exclusions based on race and other factors. Again, patients with other cancers in the breast were excluded, but (different from the 6.S897/HST.956 Machine Learning for Healthcare - Lec13 6\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the primary challenge with using billing codes for clinical research?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the primary challenge with using billing codes for clinical research?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the primary challenge with using billing codes for clinical research?', [\"in this dataset turned out to be really low (~ 19%)! There is a systematic reason for this as the billing codes were not created to specify what was actually wrong with the patient; instead the billing codes were meant to tell insurance companies/medicare that how much of the payment is reserved for the doctors taking care of them. So the billing codes are very imperfect versions of reality as the billing codes for a patient who is diagnosed with the disease eventually has the same billing codes as the ones for a patient who doesn't eventually get diagnosed with the same disease as the diagnostic procedure is the same! Next, they insisted that instead of just a single billing code for RA, they selected patients from a pool of patients who had three billing codes for RA. This raised the positive predictive value to about 27%. This was again surprising. The reason for such a low PPV even with 3 billing codes was because you can have multiple billing codes during the same visit e.g. one billing code for x-ray, another billing code for blood test for anti-CCP titre. It is entirely possible that all of this is negative and the patient doesn't even have the disease. These aspects are important to consider in clinical data. In order to understand the relation between genetics and the disease, they required a PPV of more than 95% to get a very pure sample of people with RA to get some meaningful results. 1KDRA EMR n=25,830 RA Mart Classification Predicted OR n=29, 432 algorithm RA Cases million Arti-CCP n=3,602 n=3,585 Training set Validation set n=500 training n-400 High sensitivity High specificity © American College of Rheumatology. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 1: Finding a Cohort of Rheumatoid Arthritis Cases. The methodology followed by Professor Solovitz is shown in Fig. 1. This was done by first taking 4 million patients in EMR and selecting ~ 29,000 patients who had atleast one ICD-9 code for RA, or they had an anti-CCP titre. They selected 500 cases on which they got gold standard readings from rheumatologists and then trained an algorithm to predict whether the patient really had RA or not and that predicted 3, 585 cases out of the 29, 432 had RA. Then, they sampled a validation set of 400 out of those and got those evaluated by rheumatologists to give them gold standard on those! Note that they removed people with ICD-9 codes that fell under the general category of rheumatoid diseases because those people were not appropriate for the data sample they required. They dealt with multiple coding for the same visit by ignoring codes that occurred within a week of each other. They looked for electronic prescriptions of various sorts and lab tests. Counting the number of facts in the database for a patient served as a good proxy for how sick the patient was. For the narrative text, they used a system called HITEx that extracted entities from narrative text [1]. This was done from health care provider notes, radiology reports, pathology reports, discharge summaries, and operative reports. They also used diagnoses notes, medications, laboratory data and radiology findings. This list from the system was augmented with a hand-curated list of alternative ways of saying the same thing to expand the text. They also ensured that they dealt with negation. The model used was logistic regression. It was interesting to see the positive predictors were a mixture of those dependent on codified data and others dependent on NLP. This work built a compelling reason to show there is real value in narrative text. Using codified data (e.g. lab values, demographics) only to predict whether a patient has rheumatoid arthritis lead to a PPV of 88% On the other hand, using natural language processing on clinical text (nursing notes, discharge summaries etc.) gave a PPV of 89%. Not surprisingly, a combination of both codified data and NLP gave a PPV of 94% [2]. Another interesting study tried to replicate the results at Vanderbilt and Northwestern [3]. Even though you couldn't run exactly the same methodology based on the fact that all three had different systems. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 2\", 'to those challenges, patient data is particularly sensitive, SO de-identification is necessary and negotiating data sharing agreements is time-consuming. Due to the complexity of the healthcare system, there is often missing data and different training data VS testing data distributions. Production EHR systems might be difficult to work with, as each commercial system is slightly different. 5 Overview of course syllabus The goals for this class are to provide intuition for healthcare data and machine learning algorithms along with understanding of the subtleties in applying these methods to the real world and challenges for future research. References [Blu19] Robert Blum. RX Project Notes. https://www.bobblum.com/ESSAYS/COMPSCI/rx-project. html, 2019. [Online; accessed 05-February-2019 [Mil10] RA Miller. A history of the internist-1 and quick medical reference (qmr) computer-assisted diagnosis projects, with lessons learned. Yearbook of medical informatics, 19(01):121-136, 2010. [PF96] Will Penny and David Frost. Neural networks in clinical medicine. Medical Decision Making, 16(4):386-398, 1996. [RIZ+17] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv: 1711.05225, 2017. [SA75] Edward H Shortliffe and Stanton G Axline. Computer-based consultations in clinical therapeutics: Explanation and rule acquisition capabilities of the mycin. 1975. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 6', \"Q: Can we use a data-driven approach to figure out what types of data we want to acquire? A: It's easy to bring in new data, but the hard part is deciding whether new data actually contains added value. The data usually just doesn't tell you that you should go out and get a different type of data. If model performance is low, then we'll try to go out and find data with information that we think may boost the performance. Q: How much impact do interventions have based on the predictions made by the model? A: No customer ever pays you for a good positive predictive value; they only care about saving or making money. We show clients how much money they would save for a particular level of improvement, then relate that to the performance of our models. We don't show clients the predictions of our models; we show them the financial impact of our models and whether it was able to make a difference. References [Apg66] Virginia Apgar. The newborn (apgar) scoring system. Pediatr Clin North Am, 13(3):645-50, 1966. [Opt14] Optum. Predictive analytics: Poised to drive population health. [PDS+84] Michael W Pozen, Ralph B D'Agostino, Harry P Selker, Pamela A Sytkowski, and William B Hood Jr. A predictive instrument to improve coronary-care-unit admission practices in acute ischemic heart disease: a prospective multicenter clinical trial. New England Journal of Medicine, 310(20):1273-1278, 1984. [RBS+15] Narges Razavian, Saul Blecker, Ann Marie Schmidt, Aaron Smith-McLallen, Somesh Nigam, and David Sontag. Population-level prediction of type 2 diabetes from claims data and analysis of risk factors. Big Data, 3(4):277-287, 2015. [SRG+10] Suchi Saria, Anand K Rajani, Jeffrey Gould, Daphne Koller, and Anna A Penn. Integration of early physiological responses predicts later illness severity in preterm infants. Science translational medicine, 2(48):48ra65-48ra65, 2010. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 13\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 7: Natural Language Processing (NLP) Instructors: David Sontag, Peter Szolovits 1 Outline This lecture and the next covers the role of Natural Language Processing in machine learning in healthcare. The two lectures in succession first cover methods, which are not based on neural networks representations and then discusses techniques which employ neural network architectures. We begin by first motivating why we care about clinical text. Later, we discuss some conceptually very appealing, but practically infeasible methods that involve analyzing the narrative texts as linguistic entities in a way that a linguistic might approach them. Next, we discuss what is actually often done e.g. a term spotting approach that says that we might not be able to understand everything that goes on in the narratives, but we can identify certain words/phrases that are highly indicative of whether a certain patient has a certain disease, or a symptom or a medical procedure that was done to them. This is the bread and butter of how clinical research is done nowadays. 2 Value of the data in clinical text Let's see an example of a discharge summary from MIMIC dataset. The text has been de-identified in the dataset. We know that in MIMIC dataset, we see astericks in places of names, dates, locations etc. Here those entities have been replaced with synthetics names, dates, locations etc. to make it look like a piece that reads like a real text. We want to take advantage of these clinical notes because they carry important information about what happened to the patient over the course of their stay at the hospital. Mr. Blind is a 79-year-old white male with a history of diabetes mellitus, inferior myocardial infarction, who underwent open repair of his increased diverticulum November 13th at Sephsand- pot Center. The patient developed hematemesis November 15th and was intubated for respiratory distress. He was transferred to the Valtawnprinceel Community Memorial Hospital for endoscopy and esophagoscopy on the 16th of November which showed a 2 cm linear tear of the esophagus at 30 to 32 cm. The patient's hematocrit was stable and he was given no further intervention. The patient attempted a gastrografin swallow on the 21st, but was unable to cooperate with probable aspiration. The patient also had been receiving generous intravenous hydration during the period for which he was NPO for his esophageal tear and intravenous Lasix for a question of pulmonary congestion. On the morning of the 22nd the patient developed tachypnea with a chest X-ray showing a question of congestive heart failure. A medical consult was obtained at the Valtawnprinceel Community Memorial Hospital. The patient was given intravenous Lasix. Note: orange=demographics; blue=patient condition, diseases, etc.; red=procedures, tests; magenta=results of measurements; yellow=time In fact to give you a more quantitative version of this, Professor Solovitz and Dr. Katherine worked on a project in 2010 in which they tried to understand what are the genetic correlates of rheumatoid arthritis (RA). In order to do this, they went to Research Patient Data Repository (RPDR) of Massachusetts General and Brigham Partners Healthcare and tried to find the patients who had been billed for rheumatoid arthritis. Naturally, there were thousands of those patients who had been billed for RA. So, they selected a random subset of those patients and gave their records to dermatologists to find out which of those patients actually had rheumatoid arthritis. They found out that the positive predictive value of having a billing code for RA 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 1\", \"Q: Can we use a data-driven approach to figure out what types of data we want to acquire? A: It's easy to bring in new data, but the hard part is deciding whether new data actually contains added value. The data usually just doesn't tell you that you should go out and get a different type of data. If model performance is low, then we'll try to go out and find data with information that we think may boost the performance. Q: How much impact do interventions have based on the predictions made by the model? A: No customer ever pays you for a good positive predictive value; they only care about saving or making money. We show clients how much money they would save for a particular level of improvement, then relate that to the performance of our models. We don't show clients the predictions of our models; we show them the financial impact of our models and whether it was able to make a difference. References [Apg66] Virginia Apgar. The newborn (apgar) scoring system. Pediatr Clin North Am, 13(3):645-50, 1966. [Opt14] Optum. Predictive analytics: Poised to drive population health. [PDS+84] Michael W Pozen, Ralph B D'Agostino, Harry P Selker, Pamela A Sytkowski, and William B Hood Jr. A predictive instrument to improve coronary-care-unit admission practices in acute ischemic heart disease: a prospective multicenter clinical trial. New England Journal of Medicine, 310(20):1273-1278, 1984. [RBS+15] Narges Razavian, Saul Blecker, Ann Marie Schmidt, Aaron Smith-McLallen, Somesh Nigam, and David Sontag. Population-level prediction of type 2 diabetes from claims data and analysis of risk factors. Big Data, 3(4):277-287, 2015. [SRG+10] Suchi Saria, Anand K Rajani, Jeffrey Gould, Daphne Koller, and Anna A Penn. Integration of early physiological responses predicts later illness severity in preterm infants. Science translational medicine, 2(48):48ra65-48ra65, 2010. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 13\", \"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some goals of NLP in healthcare as discussed in the lecture?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some goals of NLP in healthcare as discussed in the lecture?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 7: Natural Language Processing (NLP) Instructors: David Sontag, Peter Szolovits 1 Outline This lecture and the next covers the role of Natural Language Processing in machine learning in healthcare. The two lectures in succession first cover methods, which are not based on neural networks representations and then discusses techniques which employ neural network architectures. We begin by first motivating why we care about clinical text. Later, we discuss some conceptually very appealing, but practically infeasible methods that involve analyzing the narrative texts as linguistic entities in a way that a linguistic might approach them. Next, we discuss what is actually often done e.g. a term spotting approach that says that we might not be able to understand everything that goes on in the narratives, but we can identify certain words/phrases that are highly indicative of whether a certain patient has a certain disease, or a symptom or a medical procedure that was done to them. This is the bread and butter of how clinical research is done nowadays. 2 Value of the data in clinical text Let's see an example of a discharge summary from MIMIC dataset. The text has been de-identified in the dataset. We know that in MIMIC dataset, we see astericks in places of names, dates, locations etc. Here those entities have been replaced with synthetics names, dates, locations etc. to make it look like a piece that reads like a real text. We want to take advantage of these clinical notes because they carry important information about what happened to the patient over the course of their stay at the hospital. Mr. Blind is a 79-year-old white male with a history of diabetes mellitus, inferior myocardial infarction, who underwent open repair of his increased diverticulum November 13th at Sephsand- pot Center. The patient developed hematemesis November 15th and was intubated for respiratory distress. He was transferred to the Valtawnprinceel Community Memorial Hospital for endoscopy and esophagoscopy on the 16th of November which showed a 2 cm linear tear of the esophagus at 30 to 32 cm. The patient's hematocrit was stable and he was given no further intervention. The patient attempted a gastrografin swallow on the 21st, but was unable to cooperate with probable aspiration. The patient also had been receiving generous intravenous hydration during the period for which he was NPO for his esophageal tear and intravenous Lasix for a question of pulmonary congestion. On the morning of the 22nd the patient developed tachypnea with a chest X-ray showing a question of congestive heart failure. A medical consult was obtained at the Valtawnprinceel Community Memorial Hospital. The patient was given intravenous Lasix. Note: orange=demographics; blue=patient condition, diseases, etc.; red=procedures, tests; magenta=results of measurements; yellow=time In fact to give you a more quantitative version of this, Professor Solovitz and Dr. Katherine worked on a project in 2010 in which they tried to understand what are the genetic correlates of rheumatoid arthritis (RA). In order to do this, they went to Research Patient Data Repository (RPDR) of Massachusetts General and Brigham Partners Healthcare and tried to find the patients who had been billed for rheumatoid arthritis. Naturally, there were thousands of those patients who had been billed for RA. So, they selected a random subset of those patients and gave their records to dermatologists to find out which of those patients actually had rheumatoid arthritis. They found out that the positive predictive value of having a billing code for RA 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 1\", 'example, \"rheumatoid arthritis\" gets codified to 714.0 (ICD-9). Determine whether any word or phrase represents protected health information. For example, de- identify \"Mr. Huntington suffers from Huntington\\'s Disease\" without losing medical information. Determine aspects of each entity such as time, location, certainty etc. Identify relationships between two meaningful phrases in a sentence, for example precedence, causality, indication etc. Identify the sentences or fragments most relevant to answering a specific medical question. For instance, where is the patient\\'s exercise regimen discussed? Summarize large corpus of medical text to provide a meaningful overview. It is important to understand that there are two kinds of tasks. For instance, if you are performing de- identification, you need to look at each word in order to see if it is protective health information. In contrast, the second kind of task requires aggregate judgements where many of the words do not make any difference. For example, one of the challenges the healthcare community working in NLP ran in 2006 gave people medical records and gave them the task of predicting whether the patient is a smoker. In this context, there were obviously words such as \"smoker\", \"tobacco user\" that were helpful in making a prediction; however, even these terms were sometimes misleading as a researcher who was working in tobacco mosaic virus got predicted to be a smoker! Another interesting case said that the patient quit smoking two days ago, which is certainly impossible to correctly predict whether that patient was a smoker or not. Similarly, aggregate judgement in process of cohort selection doesn\\'t require you to know everything about a patient but only whether they fit a certain inclusion criteria. 4 Hyper-simplified linguistics Dr. Thompson, Professor Solovitz\\'s PhD advisor, published an article \"English for the Computer\" in 1966 [4], which discussed a method to process english. It assumed that there was a grammar and any english text you come across is parsed according to this grammar and each parsing rule corresponds to some semantic function and the picture that emerges is shown in Fig. 4. If you have two phrases with some syntactic 3/11/98 IPN (date of) Intern Progress Note, SOB & DOE i the patient\\'s shortness of breath and dyspnea on exertion are decreased, VSS. AF the patient\\'s vital signs are stable and the patient is afebrile, CXR LLL ASD no A a recent new chest xray shows a left lower lobe air space density that is unchanged from the previous radiograph, WBC IIK a recent new white blood cell count is 11,000 cells per cubic milliliter, S/B Cx GPC c/w PC. no the patient\\'s sputum and blood cultures are positive for gram GNR positive cocci-consistent with prieumococcus, no gram negative rods have grown, D/C Cef PPN IV so the plan is to discontinue the cefazolin and then begin penicilin treatment intravenously, Figure 3: Sample terms used in a nursing note. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 4', '6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', ['Baseline NegEx Group 1 Group 2 Group Group 2 sentences due sentences (Le., contences (Le contenced (i.e., containing not containing contences containing not containing AA contences NegEx NegEx NegEX NegEx negation negation negation negation phrases) physion presson) phrases) 0 500 500 1000 500 500 1000 Sensitivity 88.27 0,00 88.27 82,31 0.00 77.84 Specificity 52,69 100.00 85,27 82.50 100.00 94.51 PPV 68.42 - 68:42 84.49 - 84.49 NRV 79,46 96.99 93.01 80.21 96.99 91.73 Figure 5: NegEx Results. 6 Unified Medical Language System (UMLS) In 1985, National Library of Medicine made a huge effort to create UMLS; this was an attempt to take all of the terminologies that various medical societies had developed and unify them into what they termed as \"meta-thesaurus\". They also dedicated huge amount of human and machine resources to identify cases in which two different expressions from different terminologies meant the same thing. For instance, heart attack, myocardial infarction, and acute myocardial infarction mean the same. They used the resources to scour the databases and come up with a mapping of each of these terms to a single concept. This is an enormous help to normalize databases that come from different places and are described differently. It also gives you, in the context of natural language processing, a treasure trove of ways of expressing the same conceptual idea and it gives you ways to expand the kind of expressions that you are looking for. There are about 3.7 million concepts in this meta-thesaurus, each of which is assigned a concept unique identifier (CUI). There are also hierarchies and relationships that are imported from all of these different sources of terminology; though these are a jumbled mess. They also created a semantic network of 54 relations and 127 types. Every CUI is assigned at least one semantic type. Examples of UMLS concepts of various types are shown in Fig. 6. The types are hierarchically organized: an example is shown in Fig. 7 There are also tools that deal with some simplistic linguistic problems. For example, \"lead\", \"leads\", and \"leading\" are the same concept. So, there are Lexical Variation Generation (LVG) tools that help you normalize this sort of problem. Similarly, there is a normalization function that helps you normalize sentences into lower-case alphabetized version of the text, e.g. \"Mr. Huntington was admitted to Huntington Memorial Hospital for acute chest pain in March\" is normalized to \"acute admit be chest hospital huntington huntington march memorial mr pain\". Then, text can translated into other potential linguistic meanings of that text. There is also an online tool available through UMLS Terminology Services, where you can type ayagia select c from mrsty group by aty select From azoonao e 2010 araty a on order by c desc) where and c.GtT-IPF\\' and c.ISPAST= and c.LAT=TEN and tai= T0471 tui aty e cal ALT 1062 Therapestic or Preventive Procedure 260914 2033 Finding 233579 C0000744 Abetalipoproteinemia T200 Clinical Drug 172069 C0000174 Gastrin secretion obnormality NOS T109 Organic Chemical 157501 C0000386 Spontaneous abortion T121 Pharmacologic Substance 124644 C0000809 Abortion, Habitual 7116 Amino Acid, Peptide, or Protein 117508 C0000814 Missed abortion TOOM Invertebrate 111044 C0000821 Threatened abortion TOOD Bacterium 110065 C0000022 Abortion, Tube) T002 Plant 95017 C0000823 Abortion, Veterinary 2047 Disesse or Syndrome 29370 C0000832 Abruptio Placentac 7023 Body Part. Organ. or Organ Componént 73402 00000000 Acanthamoeba Keratitis 2201 Clinical Astribute 69998 00000099 Acantbosis Nigricana 7123 BioLogically Active Substance 55741 00001080 Achondroplasia T074 Medical Devion 51708 C0001083 Achromis parasitica 7020 Gene or Genone 49960 C0001125 Acidosis, Lactic Figure 6: Wealth of UMLS Concepts of Various Types. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 6', \"6.S897/HST.956 Machine Learning for Healthcare Lecture 7: Natural Language Processing (NLP) Instructors: David Sontag, Peter Szolovits 1 Outline This lecture and the next covers the role of Natural Language Processing in machine learning in healthcare. The two lectures in succession first cover methods, which are not based on neural networks representations and then discusses techniques which employ neural network architectures. We begin by first motivating why we care about clinical text. Later, we discuss some conceptually very appealing, but practically infeasible methods that involve analyzing the narrative texts as linguistic entities in a way that a linguistic might approach them. Next, we discuss what is actually often done e.g. a term spotting approach that says that we might not be able to understand everything that goes on in the narratives, but we can identify certain words/phrases that are highly indicative of whether a certain patient has a certain disease, or a symptom or a medical procedure that was done to them. This is the bread and butter of how clinical research is done nowadays. 2 Value of the data in clinical text Let's see an example of a discharge summary from MIMIC dataset. The text has been de-identified in the dataset. We know that in MIMIC dataset, we see astericks in places of names, dates, locations etc. Here those entities have been replaced with synthetics names, dates, locations etc. to make it look like a piece that reads like a real text. We want to take advantage of these clinical notes because they carry important information about what happened to the patient over the course of their stay at the hospital. Mr. Blind is a 79-year-old white male with a history of diabetes mellitus, inferior myocardial infarction, who underwent open repair of his increased diverticulum November 13th at Sephsand- pot Center. The patient developed hematemesis November 15th and was intubated for respiratory distress. He was transferred to the Valtawnprinceel Community Memorial Hospital for endoscopy and esophagoscopy on the 16th of November which showed a 2 cm linear tear of the esophagus at 30 to 32 cm. The patient's hematocrit was stable and he was given no further intervention. The patient attempted a gastrografin swallow on the 21st, but was unable to cooperate with probable aspiration. The patient also had been receiving generous intravenous hydration during the period for which he was NPO for his esophageal tear and intravenous Lasix for a question of pulmonary congestion. On the morning of the 22nd the patient developed tachypnea with a chest X-ray showing a question of congestive heart failure. A medical consult was obtained at the Valtawnprinceel Community Memorial Hospital. The patient was given intravenous Lasix. Note: orange=demographics; blue=patient condition, diseases, etc.; red=procedures, tests; magenta=results of measurements; yellow=time In fact to give you a more quantitative version of this, Professor Solovitz and Dr. Katherine worked on a project in 2010 in which they tried to understand what are the genetic correlates of rheumatoid arthritis (RA). In order to do this, they went to Research Patient Data Repository (RPDR) of Massachusetts General and Brigham Partners Healthcare and tried to find the patients who had been billed for rheumatoid arthritis. Naturally, there were thousands of those patients who had been billed for RA. So, they selected a random subset of those patients and gave their records to dermatologists to find out which of those patients actually had rheumatoid arthritis. They found out that the positive predictive value of having a billing code for RA 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 1\", 'Biologic Function Physiologic Pathologic Function Function Organism Organ or Cell Molecular Cell or Disease or Experimental Function Tissue Function Function Molecular Syndrome model Function Dysfunction of Disease Mental Genetic Mental or Neoplastic Process Function Behavioral Process Dysfunction Courtesy of National Library of Medicine. Image is in the public domain. Figure 7: Hierarchy of UMLS Semantic Network Types and Relations. something to get the concept, semantic type etc. In the next lecture, Professor Solovitz will discuss the advanced machine learning approaches for natural language processing, some of which are based on neural network representations. References [1] Zeng QT, Goryachev S, Weiss S, Sordo M, Murphy SN, Lazarus R. Extracting principal diagnosis, co- morbidity and smoking status for asthma research: evaluation of a natural language processing system. BMC Med Inform Decis Mak 2006;6:30. [2] Liao, K. P., Cai, T., Gainer, V., Goryachev, S., Zeng-Treitler, Q., Raychaudhuri, S., Szolovits, P., Churchill, S., Murphy, S., Kohane, I., Karlson, E., Plenge, R. (2010). Electronic medical records for discovery research in rheumatoid arthritis. Arthritis Care & Research, 62(8), 1120-1127. http://doi.org/10.1002/acr.20184 [3] Carroll, R. J., Thompson, W. K., Eyler, A. E., Mandelin, A. M., Cai, T., Zink, R. M., et al. (2012). Portability of an algorithm to identify rheumatoid arthritis in electronic health records. Journal of the American Medical Informatics Association, 19(e1), e162-9. http://doi.org/10.1136/amiajnl-2011-000583 [4] Frederick B. Thompson, \"English for the Computer.\" Proceedings of the Fall Joint Computer Conference (1966) pp. 349-356 [5] Walker, D. E., Hobbs, J. R., 1981. Natural Language Access to Medical Text*. (pp. 269-273). Presented at the Proc Annu Symp Comput Appl Med Care. [6] de Heaulme M, Tainturier C, Thomas D. [Computer treatment of medical reports: example of the \"Remde\" system (author\\'s transl)]. Nouv Presse Med. 1979 Oct 22;8(40):3223-6. French. PubMed PMID: 534182 [7] Chapman WW, Bridewell W, Hanbury P, Cooper GF, Buchanan BG. A simple algorithm for identifying negated findings and diseases in discharge summaries. J Biomed Inform. 2001 Oct;34(5):301-10. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 7'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the role of term spotting and negation handling in clinical NLP?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the role of term spotting and negation handling in clinical NLP?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the role of term spotting and negation handling in clinical NLP?', ['Phrase1 Phrase2 Mapping to marring Meaning1 Semantic relationship Meaning2 Figure 4: Proposed relationship between syntax and semantics. relationship between them, then each phrase can be mapped to their meanings and the semantic relationship between those two meanings is determined by the syntactic relationship in the language. Dr. Thompson built computer systems that tried to follow this method and these systems were able to help researchers who worked in areas such as anthropology, where you don\\'t have codified data and a lot of the information is in the form of narrative text. In 1980, Stanford Research Institute built a system called (\"DIAMOND/DIAGRAM\", which intended to help people interact with computer systems when they didn\\'t know command language. So, the people expressed something in english, which got translated to some semantic representation and that was used by the computer. This idea was applied by Walker and Hobbs to natural language access to medical text and they built a system that essentially translated english into some formal representation and process it [5]. The original \"DIAMOND/DIAGRAM\" system had a very rigid syntax and relied on adaptation of humans. The most radical version of this by the name \"French Remede system\" was implemented and tested in a medieval hospital in Paris, where an artificial language was developed to take notes about cardiac patients instead of writing them in French [6]. However, it was quickly discarded as doctors reported that the language was not expressive enough. 5 Term spotting and handling negation, uncertainty Traditionally, term-spotting is done by hand-crafting a list of all the terms that might appear in the note that could be indicative of some condition by a medical practitioner and then the notes are searched through for those terms by the researcher. More sophisticated techniques would use algorithms such as NegEx, which is a negation expression detector, that gets rid of things which not true. This led to more sophisticated machine learning algorithms which aimed to automatically augment the hand-crafted list to create a more indicative list of terms. For negation, Chapman described a simple algorithm to identify negated findings [7], which found all the UMLS (discussed in next section) terms in each sentence of discharge summary and then searched for two kind of patterns. First pattern looked for a negation phrase such as \"no signs of\", \"ruled out unlikely\", \"absence of\" \"not demonstrated\", \"denies\", \"no sign of\", etc. followed within 5 words by UMLS terms. The second pattern looked for post modifiers such as \"declined\", \"unlikely\" etc. Furthermore, they hacked up a bunch of exceptions such as \"gram negative\", \"no further\", \"not able to be\", \"not certain if\" This algorithm, despite being incredibly simple, does reasonably well as shown in Fig. 5. Comparing with the baseline which looks for negation phrases which are immediately followed by a UMLS term, NegEx significantly improves the specificity from 52.69% to 82.50%. Generalization is done by taking advantage of related terms, for instance hypo- and hyper-. You could also employ associative reasoning; for example, if you see a lot of symptoms in the clinical text of a particular condition, then the disease is likely to be present as well. The recursive machine learning problem is how best to identify things associated with the term, which is known as \"phenotyping\". 6.S897/HST.956 Machine Learning for Healthcare - Lec7 5', \"6.S897/HST.956 Machine Learning for Healthcare Lecture 7: Natural Language Processing (NLP) Instructors: David Sontag, Peter Szolovits 1 Outline This lecture and the next covers the role of Natural Language Processing in machine learning in healthcare. The two lectures in succession first cover methods, which are not based on neural networks representations and then discusses techniques which employ neural network architectures. We begin by first motivating why we care about clinical text. Later, we discuss some conceptually very appealing, but practically infeasible methods that involve analyzing the narrative texts as linguistic entities in a way that a linguistic might approach them. Next, we discuss what is actually often done e.g. a term spotting approach that says that we might not be able to understand everything that goes on in the narratives, but we can identify certain words/phrases that are highly indicative of whether a certain patient has a certain disease, or a symptom or a medical procedure that was done to them. This is the bread and butter of how clinical research is done nowadays. 2 Value of the data in clinical text Let's see an example of a discharge summary from MIMIC dataset. The text has been de-identified in the dataset. We know that in MIMIC dataset, we see astericks in places of names, dates, locations etc. Here those entities have been replaced with synthetics names, dates, locations etc. to make it look like a piece that reads like a real text. We want to take advantage of these clinical notes because they carry important information about what happened to the patient over the course of their stay at the hospital. Mr. Blind is a 79-year-old white male with a history of diabetes mellitus, inferior myocardial infarction, who underwent open repair of his increased diverticulum November 13th at Sephsand- pot Center. The patient developed hematemesis November 15th and was intubated for respiratory distress. He was transferred to the Valtawnprinceel Community Memorial Hospital for endoscopy and esophagoscopy on the 16th of November which showed a 2 cm linear tear of the esophagus at 30 to 32 cm. The patient's hematocrit was stable and he was given no further intervention. The patient attempted a gastrografin swallow on the 21st, but was unable to cooperate with probable aspiration. The patient also had been receiving generous intravenous hydration during the period for which he was NPO for his esophageal tear and intravenous Lasix for a question of pulmonary congestion. On the morning of the 22nd the patient developed tachypnea with a chest X-ray showing a question of congestive heart failure. A medical consult was obtained at the Valtawnprinceel Community Memorial Hospital. The patient was given intravenous Lasix. Note: orange=demographics; blue=patient condition, diseases, etc.; red=procedures, tests; magenta=results of measurements; yellow=time In fact to give you a more quantitative version of this, Professor Solovitz and Dr. Katherine worked on a project in 2010 in which they tried to understand what are the genetic correlates of rheumatoid arthritis (RA). In order to do this, they went to Research Patient Data Repository (RPDR) of Massachusetts General and Brigham Partners Healthcare and tried to find the patients who had been billed for rheumatoid arthritis. Naturally, there were thousands of those patients who had been billed for RA. So, they selected a random subset of those patients and gave their records to dermatologists to find out which of those patients actually had rheumatoid arthritis. They found out that the positive predictive value of having a billing code for RA 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 1\", 'Baseline NegEx Group 1 Group 2 Group Group 2 sentences due sentences (Le., contences (Le contenced (i.e., containing not containing contences containing not containing AA contences NegEx NegEx NegEX NegEx negation negation negation negation phrases) physion presson) phrases) 0 500 500 1000 500 500 1000 Sensitivity 88.27 0,00 88.27 82,31 0.00 77.84 Specificity 52,69 100.00 85,27 82.50 100.00 94.51 PPV 68.42 - 68:42 84.49 - 84.49 NRV 79,46 96.99 93.01 80.21 96.99 91.73 Figure 5: NegEx Results. 6 Unified Medical Language System (UMLS) In 1985, National Library of Medicine made a huge effort to create UMLS; this was an attempt to take all of the terminologies that various medical societies had developed and unify them into what they termed as \"meta-thesaurus\". They also dedicated huge amount of human and machine resources to identify cases in which two different expressions from different terminologies meant the same thing. For instance, heart attack, myocardial infarction, and acute myocardial infarction mean the same. They used the resources to scour the databases and come up with a mapping of each of these terms to a single concept. This is an enormous help to normalize databases that come from different places and are described differently. It also gives you, in the context of natural language processing, a treasure trove of ways of expressing the same conceptual idea and it gives you ways to expand the kind of expressions that you are looking for. There are about 3.7 million concepts in this meta-thesaurus, each of which is assigned a concept unique identifier (CUI). There are also hierarchies and relationships that are imported from all of these different sources of terminology; though these are a jumbled mess. They also created a semantic network of 54 relations and 127 types. Every CUI is assigned at least one semantic type. Examples of UMLS concepts of various types are shown in Fig. 6. The types are hierarchically organized: an example is shown in Fig. 7 There are also tools that deal with some simplistic linguistic problems. For example, \"lead\", \"leads\", and \"leading\" are the same concept. So, there are Lexical Variation Generation (LVG) tools that help you normalize this sort of problem. Similarly, there is a normalization function that helps you normalize sentences into lower-case alphabetized version of the text, e.g. \"Mr. Huntington was admitted to Huntington Memorial Hospital for acute chest pain in March\" is normalized to \"acute admit be chest hospital huntington huntington march memorial mr pain\". Then, text can translated into other potential linguistic meanings of that text. There is also an online tool available through UMLS Terminology Services, where you can type ayagia select c from mrsty group by aty select From azoonao e 2010 araty a on order by c desc) where and c.GtT-IPF\\' and c.ISPAST= and c.LAT=TEN and tai= T0471 tui aty e cal ALT 1062 Therapestic or Preventive Procedure 260914 2033 Finding 233579 C0000744 Abetalipoproteinemia T200 Clinical Drug 172069 C0000174 Gastrin secretion obnormality NOS T109 Organic Chemical 157501 C0000386 Spontaneous abortion T121 Pharmacologic Substance 124644 C0000809 Abortion, Habitual 7116 Amino Acid, Peptide, or Protein 117508 C0000814 Missed abortion TOOM Invertebrate 111044 C0000821 Threatened abortion TOOD Bacterium 110065 C0000022 Abortion, Tube) T002 Plant 95017 C0000823 Abortion, Veterinary 2047 Disesse or Syndrome 29370 C0000832 Abruptio Placentac 7023 Body Part. Organ. or Organ Componént 73402 00000000 Acanthamoeba Keratitis 2201 Clinical Astribute 69998 00000099 Acantbosis Nigricana 7123 BioLogically Active Substance 55741 00001080 Achondroplasia T074 Medical Devion 51708 C0001083 Achromis parasitica 7020 Gene or Genone 49960 C0001125 Acidosis, Lactic Figure 6: Wealth of UMLS Concepts of Various Types. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 6'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is risk stratification and why is it important in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is risk stratification and why is it important in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is risk stratification and why is it important in healthcare?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\", '3 Interview with Leonard D\\'Avolio 3.1 Introduction Leonard D\\'Avolio is an Assistant Professor at Harvard Medical School and the CEO and founder of Cyft. He spent the last 15 years \"trying to help healthcare learn from its data in new ways\" for governments, academia, researchers, publishing papers and nonprofits. Things D\\'Avolio worked on included Working with the Department of Veterans Affairs to build out their genomic science infrastructure and recruiting and enrolling millions of veterans to donate blood. Working at Ariadne Labs in improving neonatal care in India. 3.2 Interview Q: What is risk stratification to you? Risk stratification depends entirely on the problem. Risk could be: Running out of medical supply in an operating room The Apgar score A patient going from pre-diabetic to diabetic An older person falling down in their home Risk startification is a set of wonderful tools with which skilled craftsmen can go ahead to solve specific problems. Q: What are some of the areas that Cyft is applying today? What we do is essentially performance improvement; more specifically, the performance in keeping peo- ple out of the hospital. The most logical application for these technologies is to help do preventative things, but only between 8-12% of healthcare is financially incentivized for that. As a company, you focus on where there\\'s a financial incentive. I wanted to build a company where the financial incentives aligned with keeping people healthy. We focus on older populations where it is important to understand who care managers should approach because their risk levels are rising. The traditional approach of risk stratification identifies people that are already at their most acute. We try to help care management organizations find people that are rising risks and bring a more granular approach to healthcare. The power of these technologies is to move away from one-size-fits-all. Examples of what Cyft does includes: Tackling rising risk of an inpatient psychiatric admission Predicting which older people are likely to fall down Finding which children with Type 1 diabetes should be scheduled an appointment now rather than every 3 months The theme of the above examples is helping organizations move away from rather generic decisions towards things that are more actionable. Q: What areas have you worked on the longest? 6.S897/HST.956 Machine Learning for Healthcare - Lec4 10', \"2 Case Study: Early Detection of Type 2 Diabetes 2.1 Background We now consider a case study: risk stratification for Type 2 diabetes. This problem is extremely important, as an estimated 25% of individuals with diabetes in the United States are still undiagnosed, and the number is similar in other countries worldwide. If we are able to discover undiagnosed individuals who currently have diabetes, or identify people who are at high risk of developing diabetes in the future, we can provide interventions that prevent their condition from worsening, such as weight loss programs or first line diabetic treatments. In this section, we discuss the problem of identifying the population of individuals at high-risk of diabetes using machine learning algorithms. Traditional approaches to this problem include point-based metrics similar to the APGAR score. The following image shows a sample questionnaire for evaluating diabetes risk in Finland, which produces a single score quantifying an individual's likelihood of developing diabetes. Finniah Diabetes Association TYPE 2 DIABETES RISK ASSESSMENT FORM Orde add - - point 5. Item yes #### Salar for High blood I us register bent 9a 2g , INTERT bision glucsse a health than M lgw 2g. 5p Ban d. family with 1s - More than fa 30 x gaidparent aunt, under or fen cause the de par parent, bother gitter did 50 paint Sential in DATE est Total Ruit Score the Lower in 100 daily at least 20 - 2-11 who leisure Highly deing N25 daily activity() 12-14 attenuted 1 as © Finnish Diabetes Association. All rights 0-25 1 reserved. This content is excluded from after our Creative Commons license. For more Night Very lp two for than 20 Not information, see https://ocw.mit.edu/ every help/faq-fair-use/ Figure 5: Questionnaire for Diabetes Risk Assessment Unfortunately, these simpler methods have not had much impact and have not been widely used. Automation of the risk stratification process would allow us to avoid these types of manual questionnaires and lead to wider adoption. Instead of evaluating risk for every individual separately, an alternative option is to use machine learning models - trained on data from a health insurance company or other sources - that automatically identify the subpopulation at high risk of developing diabetes out of millions of individuals. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 5\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the difference between traditional scoring systems and ML-based risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', [\"1.4 Old VS. New 1.4.1 Traditional Approaches APGAR SCORING SYSTEM Points 0 Points 1 Point 2 Points totaled Activity Arma and legs Active Absent (muscle tone) flexed movement Pulse Absent Belins 100 lipm Over 100 Ligan Active motion Grimace Flaccid Some flexion of innecer, cough (reflex irritability) Extremities pndl away Appearance Blue. pale Body pinku Completely (skin color) Extremities blue pink Respiration Absent Slow, irregular Vigorous oy Severely depressed 0-3 Moderately depressed 4-6 Excellent condition 7-10 © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 2: Chart of the Apgar scoring system used to predict infant morbidity. Traditional approaches to risk stratification are based on scoring systems. The Apgar score, shown in Fig- ure 2, is one such system [Apg66]. It is based on different criteria, with each answer having a specific point value. After answering, one adds up the points to obtain the risk-level score. There are hundreds of such scoring rules that are carefully derived through studies and are widely used in today's healthcare system. 1.4.2 Machine Learning-based Approaches Now, most of industry is moving towards machine learning based methods that can work with a much higher dimensional set of features and solve a number of key challenges of these early approaches. Machine learning based approaches can: Fit more easily into clinical workflows. Scores from traditional approaches are often done manually. One has to figure out the corresponding inputs, SO it is often not used as frequently. Be much quicker to derive. Traditional scoring systems have a very long research and development process that led to their adoption. With machine learning based approaches, given enough data or access to data, one can predict narrow outcomes or conditions that may occur infrequently. Lead to higher accuracy. However, these new ML approaches also introduce new dangers. This will be discussed more in future lectures. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 3\", \"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\", \"2 Case Study: Early Detection of Type 2 Diabetes 2.1 Background We now consider a case study: risk stratification for Type 2 diabetes. This problem is extremely important, as an estimated 25% of individuals with diabetes in the United States are still undiagnosed, and the number is similar in other countries worldwide. If we are able to discover undiagnosed individuals who currently have diabetes, or identify people who are at high risk of developing diabetes in the future, we can provide interventions that prevent their condition from worsening, such as weight loss programs or first line diabetic treatments. In this section, we discuss the problem of identifying the population of individuals at high-risk of diabetes using machine learning algorithms. Traditional approaches to this problem include point-based metrics similar to the APGAR score. The following image shows a sample questionnaire for evaluating diabetes risk in Finland, which produces a single score quantifying an individual's likelihood of developing diabetes. Finniah Diabetes Association TYPE 2 DIABETES RISK ASSESSMENT FORM Orde add - - point 5. Item yes #### Salar for High blood I us register bent 9a 2g , INTERT bision glucsse a health than M lgw 2g. 5p Ban d. family with 1s - More than fa 30 x gaidparent aunt, under or fen cause the de par parent, bother gitter did 50 paint Sential in DATE est Total Ruit Score the Lower in 100 daily at least 20 - 2-11 who leisure Highly deing N25 daily activity() 12-14 attenuted 1 as © Finnish Diabetes Association. All rights 0-25 1 reserved. This content is excluded from after our Creative Commons license. For more Night Very lp two for than 20 Not information, see https://ocw.mit.edu/ every help/faq-fair-use/ Figure 5: Questionnaire for Diabetes Risk Assessment Unfortunately, these simpler methods have not had much impact and have not been widely used. Automation of the risk stratification process would allow us to avoid these types of manual questionnaires and lead to wider adoption. Instead of evaluating risk for every individual separately, an alternative option is to use machine learning models - trained on data from a health insurance company or other sources - that automatically identify the subpopulation at high risk of developing diabetes out of millions of individuals. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 5\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How is label leakage managed in diabetes prediction models?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How is label leakage managed in diabetes prediction models?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How is label leakage managed in diabetes prediction models?', ['a patient\\'s likelihood of developing diabetes at some time period in the \"future\" (after 1/1/2009). Three different prediction tasks were considered, using different gaps between the data collection and prediction windows, shown in Figure 8: Prediction Window 2000-2011 Construction 2009 2010 2011 2012 2013 Firmith Prediction Window 2010 Construction 2012 2009 2010 2011 2012 2013 Frature Prediction Window 2114 Construction 2012 2009 2010 2011 2012 2013 Figure 8: Prediction Tasks In each case, we exclude patients who develop diabetes before the start of the prediction window. For in- stance, in the task with the 1-year gap, we exclude any patients diagnosed with diabetes prior to 1/1/2010. One reason for including this gap is label leakage. In certain situations, it is possible that a doctor is very certain that a patient has diabetes, even though this has not been explicitly coded in a way that our algorithms can detect. The doctor may already be doing interventions based on this \"pre-diagnosis\". The models will pick up on these signals and predict that this patient is very likely to develop diabetes. However, such a prediction is not very interesting, as the doctor has already identified the patient as being at high-risk for diabetes and is carrying out appropriate interventions. Instead, our models should be able to identify patients at high risk that the doctor may not expect. Another issue is data censoring. For example, a patient may have only enrolled with an insurer in 2012, SO they will have no data prior to 2009, and our models will not be able to construct any features for these individuals. There are two types of censoring that are handled: Left Censoring: Patient data absent prior to some point in time Right Censoring: Patient data absent after some point in time For patients with left-censoring, the models attempt to construct as many features as possible; patients with less data simple have sparser feature vectors. Right-censored patients are dropped from the dataset if data in the full relevant prediction window is unavailable. This simple exclusion criteria can be problematic in some cases. For instance, a patient may have switched insurers as a result of their diabetes diagnosis at some point in the prediction window, leaving them with no data after that time. Thus, we may actually be excluding patients who would benefit from our model\\'s predictions and biasing the model\\'s results. In the next lecture, we will discuss alternative approaches for handling right-censoring. For the rest of this section, we focus on the prediction task corresponding to the 1-year gap. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 7', \"Top History of Disease Odds Ratio 4,17 Impaired Fasting Glucose (Code 790.21) (3.87 4.49) 4.07 Abnormal Glucose NEC (790.29) (3,76 4,41) 3.28 Hypertension (401) (3,17 3.39) 2.98 Constructive Sleep Aprica (327,23) (2.78.320) 2.88 Obesity (278) (2.75 3.02) 2.49 Abnormal Blood Chemistry (790.6) (2.36 2.62) 2.45 Hyperlipidemia (272,4) (2.37 2.53) 2.09 Shodness Of Breath (788.05) (1.99.2.19) 185 Esophageal Reflux (530.81) (1178 1.03) Figure 9: Most Predictive Disease Features The criteria used to evaluate risk stratification models are slightly different from standard diagnosis criteria. One common metric is the model's positive predictive value (PPV). In this case study, this metric corresponds to the proportion of predicted high-risk patients who actually went on to develop diabetes in the prediction window. The results for these particular models are shown in Figure 10, compared with a simpler model that did not perform as well. Traditional risk factors Full model 0.17 0.15 0.1 0.07 0.06 0.06 Top 100 Predictions Top 1000 Predictions Top 10000 Predictions Diabetes 1-year gap Figure 10: Positive Predictive Value (PPV) of Models for Different Groups We evaluate this metric at different levels: for the top 100, top 1000, and top 10000 most risky patients. We can observe that 15% of the top 100 and 10% of the 10000 riskiest patients go on to develop diabetes. By performing these separate analyses, one could target different interventions for patients at different risk levels. Cheap interventions (i.e, an eye checkup for diabetic retinopathy) could be recommended for the top 10,000 riskiest patients. On the other hand, a more expensive intervention could not be implemented at such a large scale, and it may only be recommended for the 100 riskiest patients. 6.S897/HST.956 Machine Learning for Healthcare - Lec4-9\", \"Q: Can we use a data-driven approach to figure out what types of data we want to acquire? A: It's easy to bring in new data, but the hard part is deciding whether new data actually contains added value. The data usually just doesn't tell you that you should go out and get a different type of data. If model performance is low, then we'll try to go out and find data with information that we think may boost the performance. Q: How much impact do interventions have based on the predictions made by the model? A: No customer ever pays you for a good positive predictive value; they only care about saving or making money. We show clients how much money they would save for a particular level of improvement, then relate that to the performance of our models. We don't show clients the predictions of our models; we show them the financial impact of our models and whether it was able to make a difference. References [Apg66] Virginia Apgar. The newborn (apgar) scoring system. Pediatr Clin North Am, 13(3):645-50, 1966. [Opt14] Optum. Predictive analytics: Poised to drive population health. [PDS+84] Michael W Pozen, Ralph B D'Agostino, Harry P Selker, Pamela A Sytkowski, and William B Hood Jr. A predictive instrument to improve coronary-care-unit admission practices in acute ischemic heart disease: a prospective multicenter clinical trial. New England Journal of Medicine, 310(20):1273-1278, 1984. [RBS+15] Narges Razavian, Saul Blecker, Ann Marie Schmidt, Aaron Smith-McLallen, Somesh Nigam, and David Sontag. Population-level prediction of type 2 diabetes from claims data and analysis of risk factors. Big Data, 3(4):277-287, 2015. [SRG+10] Suchi Saria, Anand K Rajani, Jeffrey Gould, Daphne Koller, and Anna A Penn. Integration of early physiological responses predicts later illness severity in preterm infants. Science translational medicine, 2(48):48ra65-48ra65, 2010. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 13\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What types of data are used in risk stratification for diabetes?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What types of data are used in risk stratification for diabetes?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What types of data are used in risk stratification for diabetes?', [\"2 Case Study: Early Detection of Type 2 Diabetes 2.1 Background We now consider a case study: risk stratification for Type 2 diabetes. This problem is extremely important, as an estimated 25% of individuals with diabetes in the United States are still undiagnosed, and the number is similar in other countries worldwide. If we are able to discover undiagnosed individuals who currently have diabetes, or identify people who are at high risk of developing diabetes in the future, we can provide interventions that prevent their condition from worsening, such as weight loss programs or first line diabetic treatments. In this section, we discuss the problem of identifying the population of individuals at high-risk of diabetes using machine learning algorithms. Traditional approaches to this problem include point-based metrics similar to the APGAR score. The following image shows a sample questionnaire for evaluating diabetes risk in Finland, which produces a single score quantifying an individual's likelihood of developing diabetes. Finniah Diabetes Association TYPE 2 DIABETES RISK ASSESSMENT FORM Orde add - - point 5. Item yes #### Salar for High blood I us register bent 9a 2g , INTERT bision glucsse a health than M lgw 2g. 5p Ban d. family with 1s - More than fa 30 x gaidparent aunt, under or fen cause the de par parent, bother gitter did 50 paint Sential in DATE est Total Ruit Score the Lower in 100 daily at least 20 - 2-11 who leisure Highly deing N25 daily activity() 12-14 attenuted 1 as © Finnish Diabetes Association. All rights 0-25 1 reserved. This content is excluded from after our Creative Commons license. For more Night Very lp two for than 20 Not information, see https://ocw.mit.edu/ every help/faq-fair-use/ Figure 5: Questionnaire for Diabetes Risk Assessment Unfortunately, these simpler methods have not had much impact and have not been widely used. Automation of the risk stratification process would allow us to avoid these types of manual questionnaires and lead to wider adoption. Instead of evaluating risk for every individual separately, an alternative option is to use machine learning models - trained on data from a health insurance company or other sources - that automatically identify the subpopulation at high risk of developing diabetes out of millions of individuals. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 5\", \"Top History of Disease Odds Ratio 4,17 Impaired Fasting Glucose (Code 790.21) (3.87 4.49) 4.07 Abnormal Glucose NEC (790.29) (3,76 4,41) 3.28 Hypertension (401) (3,17 3.39) 2.98 Constructive Sleep Aprica (327,23) (2.78.320) 2.88 Obesity (278) (2.75 3.02) 2.49 Abnormal Blood Chemistry (790.6) (2.36 2.62) 2.45 Hyperlipidemia (272,4) (2.37 2.53) 2.09 Shodness Of Breath (788.05) (1.99.2.19) 185 Esophageal Reflux (530.81) (1178 1.03) Figure 9: Most Predictive Disease Features The criteria used to evaluate risk stratification models are slightly different from standard diagnosis criteria. One common metric is the model's positive predictive value (PPV). In this case study, this metric corresponds to the proportion of predicted high-risk patients who actually went on to develop diabetes in the prediction window. The results for these particular models are shown in Figure 10, compared with a simpler model that did not perform as well. Traditional risk factors Full model 0.17 0.15 0.1 0.07 0.06 0.06 Top 100 Predictions Top 1000 Predictions Top 10000 Predictions Diabetes 1-year gap Figure 10: Positive Predictive Value (PPV) of Models for Different Groups We evaluate this metric at different levels: for the top 100, top 1000, and top 10000 most risky patients. We can observe that 15% of the top 100 and 10% of the 10000 riskiest patients go on to develop diabetes. By performing these separate analyses, one could target different interventions for patients at different risk levels. Cheap interventions (i.e, an eye checkup for diabetic retinopathy) could be recommended for the top 10,000 riskiest patients. On the other hand, a more expensive intervention could not be implemented at such a large scale, and it may only be recommended for the 100 riskiest patients. 6.S897/HST.956 Machine Learning for Healthcare - Lec4-9\", \"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Why is L1 regularization used in logistic regression for risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Why is L1 regularization used in logistic regression for risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'Why is L1 regularization used in logistic regression for risk stratification?', ['2.4 Model Overview Logistic regression with L1 regularization is used for this task. L1 regularization is useful because it encour- ages sparsity in the feature weights of the trained model, which has multiple benefits: 1. Prevents overfitting in settings with a good risk model containing a small number of features. 2. Improves interpretability. Can potentially enumerate all non-zero features to better understand how the model makes predictions. 3. Improves translatability. If a model has only a small number of features, it is more likely that data needed for the models can be found at many hospitals, allowing the same model to be used more widely. The cost function for such a model is of the form: where l is any loss function, W are the weights of the model, and 11/w/1 is the L1-norm of the weight vector. 2.5 Features Features were designed to account for the large amount of missing data in the records for most patients. In- stead of choosing features in a way that would potentially require the imputation of many values, the models use several binary features indicating whether a particular observation was ever made for an individual in their records. For instance, there are features for each type of specialist a patient could have visited. The correspond- ing feature value is \"1\" if the patient ever visited a particular type of specialist and \"0\" otherwise. Similar features are constructed for the most common medications (\"1\" if a person has ever taken, \"0\" otherwise). A slightly different approach is used for featurizing lab test results. In addition to features indicating whether a patient ever took a particular lab test, there are features for each of the following: Is lab test result high/low/normal? Is result increasing/decreasing? Is result fluctuating? If a patient had never been given a particular lab test, all the corresponding feature values would be 0. As constructed here, all these features are very simple. One could potentially use recurrent neural networks or other models to automatically learn features about the time series data present in lab test results. We will discuss more complex feature construction techniques in future lectures. Each of these features are then computed for different time windows: the last 6 months, the last 24 months, and all of a patient\\'s past history. In the end, a patient\\'s feature vector consists of approximately 42,000 elements. 2.6 Model Evaluation We first examine some of the features that were determined to be most predictive in the trained model. The top feature is found to be a diagnosis of \"Impaired Fasting Glucose\". While one may think that such a diagnosis would indicate that a patient has already been diagnosed as diabetic, these could also correspond to pre-diabetic patients in the dataset who are not guaranteed to develop diabetes. Other top features are shown in Figure 9. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 8', \"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\", \"Top History of Disease Odds Ratio 4,17 Impaired Fasting Glucose (Code 790.21) (3.87 4.49) 4.07 Abnormal Glucose NEC (790.29) (3,76 4,41) 3.28 Hypertension (401) (3,17 3.39) 2.98 Constructive Sleep Aprica (327,23) (2.78.320) 2.88 Obesity (278) (2.75 3.02) 2.49 Abnormal Blood Chemistry (790.6) (2.36 2.62) 2.45 Hyperlipidemia (272,4) (2.37 2.53) 2.09 Shodness Of Breath (788.05) (1.99.2.19) 185 Esophageal Reflux (530.81) (1178 1.03) Figure 9: Most Predictive Disease Features The criteria used to evaluate risk stratification models are slightly different from standard diagnosis criteria. One common metric is the model's positive predictive value (PPV). In this case study, this metric corresponds to the proportion of predicted high-risk patients who actually went on to develop diabetes in the prediction window. The results for these particular models are shown in Figure 10, compared with a simpler model that did not perform as well. Traditional risk factors Full model 0.17 0.15 0.1 0.07 0.06 0.06 Top 100 Predictions Top 1000 Predictions Top 10000 Predictions Diabetes 1-year gap Figure 10: Positive Predictive Value (PPV) of Models for Different Groups We evaluate this metric at different levels: for the top 100, top 1000, and top 10000 most risky patients. We can observe that 15% of the top 100 and 10% of the 10000 riskiest patients go on to develop diabetes. By performing these separate analyses, one could target different interventions for patients at different risk levels. Cheap interventions (i.e, an eye checkup for diabetic retinopathy) could be recommended for the top 10,000 riskiest patients. On the other hand, a more expensive intervention could not be implemented at such a large scale, and it may only be recommended for the 100 riskiest patients. 6.S897/HST.956 Machine Learning for Healthcare - Lec4-9\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is MYCIN and why was it never used in practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is MYCIN and why was it never used in practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What is MYCIN and why was it never used in practice?', ['6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1', 'to those challenges, patient data is particularly sensitive, SO de-identification is necessary and negotiating data sharing agreements is time-consuming. Due to the complexity of the healthcare system, there is often missing data and different training data VS testing data distributions. Production EHR systems might be difficult to work with, as each commercial system is slightly different. 5 Overview of course syllabus The goals for this class are to provide intuition for healthcare data and machine learning algorithms along with understanding of the subtleties in applying these methods to the real world and challenges for future research. References [Blu19] Robert Blum. RX Project Notes. https://www.bobblum.com/ESSAYS/COMPSCI/rx-project. html, 2019. [Online; accessed 05-February-2019 [Mil10] RA Miller. A history of the internist-1 and quick medical reference (qmr) computer-assisted diagnosis projects, with lessons learned. Yearbook of medical informatics, 19(01):121-136, 2010. [PF96] Will Penny and David Frost. Neural networks in clinical medicine. Medical Decision Making, 16(4):386-398, 1996. [RIZ+17] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv: 1711.05225, 2017. [SA75] Edward H Shortliffe and Stanton G Axline. Computer-based consultations in clinical therapeutics: Explanation and rule acquisition capabilities of the mycin. 1975. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 6', 'Baseline NegEx Group 1 Group 2 Group Group 2 sentences due sentences (Le., contences (Le contenced (i.e., containing not containing contences containing not containing AA contences NegEx NegEx NegEX NegEx negation negation negation negation phrases) physion presson) phrases) 0 500 500 1000 500 500 1000 Sensitivity 88.27 0,00 88.27 82,31 0.00 77.84 Specificity 52,69 100.00 85,27 82.50 100.00 94.51 PPV 68.42 - 68:42 84.49 - 84.49 NRV 79,46 96.99 93.01 80.21 96.99 91.73 Figure 5: NegEx Results. 6 Unified Medical Language System (UMLS) In 1985, National Library of Medicine made a huge effort to create UMLS; this was an attempt to take all of the terminologies that various medical societies had developed and unify them into what they termed as \"meta-thesaurus\". They also dedicated huge amount of human and machine resources to identify cases in which two different expressions from different terminologies meant the same thing. For instance, heart attack, myocardial infarction, and acute myocardial infarction mean the same. They used the resources to scour the databases and come up with a mapping of each of these terms to a single concept. This is an enormous help to normalize databases that come from different places and are described differently. It also gives you, in the context of natural language processing, a treasure trove of ways of expressing the same conceptual idea and it gives you ways to expand the kind of expressions that you are looking for. There are about 3.7 million concepts in this meta-thesaurus, each of which is assigned a concept unique identifier (CUI). There are also hierarchies and relationships that are imported from all of these different sources of terminology; though these are a jumbled mess. They also created a semantic network of 54 relations and 127 types. Every CUI is assigned at least one semantic type. Examples of UMLS concepts of various types are shown in Fig. 6. The types are hierarchically organized: an example is shown in Fig. 7 There are also tools that deal with some simplistic linguistic problems. For example, \"lead\", \"leads\", and \"leading\" are the same concept. So, there are Lexical Variation Generation (LVG) tools that help you normalize this sort of problem. Similarly, there is a normalization function that helps you normalize sentences into lower-case alphabetized version of the text, e.g. \"Mr. Huntington was admitted to Huntington Memorial Hospital for acute chest pain in March\" is normalized to \"acute admit be chest hospital huntington huntington march memorial mr pain\". Then, text can translated into other potential linguistic meanings of that text. There is also an online tool available through UMLS Terminology Services, where you can type ayagia select c from mrsty group by aty select From azoonao e 2010 araty a on order by c desc) where and c.GtT-IPF\\' and c.ISPAST= and c.LAT=TEN and tai= T0471 tui aty e cal ALT 1062 Therapestic or Preventive Procedure 260914 2033 Finding 233579 C0000744 Abetalipoproteinemia T200 Clinical Drug 172069 C0000174 Gastrin secretion obnormality NOS T109 Organic Chemical 157501 C0000386 Spontaneous abortion T121 Pharmacologic Substance 124644 C0000809 Abortion, Habitual 7116 Amino Acid, Peptide, or Protein 117508 C0000814 Missed abortion TOOM Invertebrate 111044 C0000821 Threatened abortion TOOD Bacterium 110065 C0000022 Abortion, Tube) T002 Plant 95017 C0000823 Abortion, Veterinary 2047 Disesse or Syndrome 29370 C0000832 Abruptio Placentac 7023 Body Part. Organ. or Organ Componént 73402 00000000 Acanthamoeba Keratitis 2201 Clinical Astribute 69998 00000099 Acantbosis Nigricana 7123 BioLogically Active Substance 55741 00001080 Achondroplasia T074 Medical Devion 51708 C0001083 Achromis parasitica 7020 Gene or Genone 49960 C0001125 Acidosis, Lactic Figure 6: Wealth of UMLS Concepts of Various Types. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 6'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some reasons why AI in healthcare is more promising today compared to the past?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', ['KNOWLEDGE FROM MEDICAL LITERATURE SUBSET OF DATABASE KNOWLEDGE BASE STATISTICAL PACKAGE DISCOVERY MODULE STUDY MODULE HYPOTHESIS MEDICAL ENTIRE RESEARCHER DATABASE © Robert Blum. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 1: The RX Cycle 2 Why apply machine learning to healthcare today? From the previous examples, it is clear that researchers have tried to develop computational tools for health- care with relatively little success for 40+ years. Many have found new hope for AI in healthcare because of recent widespread EHR adoption, publicly available datasets, standardization of medical codes, and break- throughs in machine learning. 2.1 EHR Adoption In the last decade, health records transitioned from mostly on paper to mostly electronic. The shift to EHR has been swift, increasing by 9x since 2008, growing from 9.4% of hospitals to nearly 84% See Figure 3 for the adoption trend from 2008 to 2015. This highlights a theme for the rest of the course: that new policy can open the door to innovation. 2.2 Data New medical datasets are now publicly available. Mimic, the only publicly available EHR dataset, was created out of MIT, consisting of intensive care unit patient records. From the MIMIC Physiotnet website, \"MIMIC is an openly available dataset developed by the MIT Lab for Computational Physiology, comprising de-identified health data associated with 40,000 critical care patients. It includes demographics, vital signs, laboratory tests, medications, and more.\" Chexpert, a large publicly available image dataset, was created in collaboration between Stanford and MIT [RIZ+17]. From the Chexpert website, \"CheXpert is a large dataset of chest X-rays and competition for automated chest x-ray interpretation, which features uncertainty labels and radiologist-labeled reference standard evaluation sets.\" The Truven Marketscan data is not a publicly available dataset, but it\\'s available in this class and it\\'s useful because it has \"data on nearly 230 million unique patients since 1995.\" Here\\'s a link to the Marketscan website. Additionally new streams of data that are relevant to health have become available to researchers. Sources of new diverse data streams include: wearable devices, phones, social media, proteomics, and genomics. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 2', '6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1', \"© source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Funura Regulation The stakeholders: (Gov't Employer's Gov't Individuals) Insurance Payment Coverage Reguration Taxes or Came and Premiums Bill Care/Hearth Services imavidun Patients (Consumer) Doctors) Direct Payment Figure 4: The healthcare system is comprised of several important pieces 3.1.2 Propagating best practices As medical knowledge becomes more specialized, it becomes important to find ways to share best practices. Professor Sontag believes this could be particularly useful in academic medical centers to aid in the training of new doctors and in less populated areas where doctors might need to cover a broader set of conditions. 3.2 Efficient healthcare workflows Machine learning can make many healthcare workflows more efficient. Image processing techniques for chest x-rays and EKGs could help reduce the number of specialist consults. On the administrative side, machine learning can be automate documentation and billing processes. Wearable devices allow for continuous moni- toring, potentially allowing for better management of chronic diseases. With more data, it would be possible to better understand chronic disease progression. Liquid biopsy could potentially lead to earlier diagnoses. 3.3 Facilitating discovery In addition to healthcare management, there are opportunities for data-driven methods to aid in discovery. Machine learning methods could help to identify disease subtypes, search for optimal molecular structures for binding sites, and facilitate new clinical trial designs. The promises of precision medicine become feasible when data is aggregated and analyzed efficiently at scale. 4 What is unique about machine learning for healthcare? Healthcare is different from other machine learning applications because the gravity of life and death decision- making. The algorithms need to be more robust than other common ML applications such as search or object recognition. There need to be deliberate checks and balances to the ML deployment with considerations for both fairness and accountability. Many questions in healthcare do not neatly align with the current advances in machine learning. Many healthcare problems are concerned with semi-supervised or unsupervised learning. Often in healthcare, it is important to identify causal relationships. In addition to the theoretical challenges, implementing data-driven systems has additional challenges in healthcare. It is already a challenge to integrate new technologies into industrial workflows. In addition 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 5\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How can machine learning transform emergency departments?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How can machine learning transform emergency departments?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'How can machine learning transform emergency departments?', [\"Figure 1: Percent of non-Federal acute care hospitals with adoption of at least a Basic EHR with notes system and possession of a certified EHR: 2008-2015 96% Certified EHR 85.2%* 96.9% 94%* 75.5%* 83.8%* 71.9% Basic EHR 59.4% 44,4%* 27.6% 15.6% 12.2% 9.4% 2008 2009 2010 2011 2012 2013 2014 2015 NOTE: Basic DIR adoption requires the EHR system to have a set of EHR functions defined in Table AL A certified EHR is EHR technology that meets the technological capability, functionality, and security requirements adopted by the Department of Health and Human Services. Possession means that the hospital has a legal agreement with the DHR vendor, but is not equivalent to adoption, *Significantly different from previous your (p=0.05). SOURCE: ONC/American Hospital Association (AMA). AHA Annual Survey Information Technology Supplement Courtesy of Health and Human Services. Image is in the public domain. Figure 3: The adoption of EHR by hospitals from 2008-2015. 3 Examples of machine learning applied to healthcare There are opportunities to transform every aspect of the healthcare system. Figure 4 shows some of the key components of the healthcare system and how they interact. In the United States, we have separated payors and providers along with government programs like Medicare and Medicaid, but the UK's National Health Service differs as a more integrated system across payors and providers. Understanding these systems, we can find opportunities to turn the right knobs to make an impact. 3.1 Imagining the emergency department of the future Professor Sontag has been working with Beth Israel Deaconess Medical Center to use technology in their Emergency Department. The ER is an interesting setting because it faces extreme constraints on a daily basis, these include: limited resources, time-sensitive needs, and critical life or death decisions. The following are some concrete examples of AI applications that aim to improve healthcare in both the short and long term. One of the themes of this course will be to highlight the high-value subtle interventions that AI can offer in the healthcare setting. 3.1.1 Behind-the-scenes reasoning about the patients conditions One of the most valuable resources in healthcare is time. Clinicians have many constraints on their time, making data collection less frequent and accurate. If features about patients can be automatically extracted from electronic medical records, then clinicians can spend more time treating patients. Extracting these features would allow for better triage, diagnosis, earlier detection of adverse events, and would likely prevent medical errors. Professor Sontag proposes a system that could predict the clincians needs, providing them with a list of treatment option lists. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 4\", '6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1', 'Time Risk factors Hemming and deviate from hawing regarding Death optimal values lifestyle changes and disability blood pressure LDL/VLDL cholesterol Treatment may be weight (grudgingly) blood sugar initiated Symptoms develop anti-hypertensives cholesterol-lowering dyspnea Therapeutic anti-diabetics angina Responsiveness $$$ Figure 4: A rough timeline on patients with cardiovascular disease. (a) Expressive - captures complex underlying processes (molecular, cellular, imaging ...) (b) Multidimensional - Can\\'t readily be \"gamed\" 3. Pipeline should be ameliorated with therapy (c.f. genetic risk) The role for the fully automated pipeline for echocardiogram interpretation would be at the \"low risk - high reward\" portion of the current spectrum. See Figure 5 6.3 Focus of machine learning in cardiac diseases We can use machine learning to: 1. enable much greater of volumes of data to be interpreted, SO that we reduce costs of acquisition and interpretation, as well as augment interpretations of simple data. 2. augment surveillance within a hospital system, e.g. patient identification for therapies 3. perform triage, i.e. automating ECG interpretation in urgent situations in the ambulance/ER To illustrate the need of machine learning to perform rapid triage, we provide an example. In the early 2000\\'s, it was recognized that any delay in angioplasty and stenting would result in irreversible damage to the heart. Thus, the solution was to replace a cardiologist reviewing the ECG with a rapid triage system by ambulance personnel or ED physicians for quicker turnover. However, this resulted in an increase in false positives. Thus, there is still a need for a fast pipeline that has high quality. 6.4 Zhang, Deo, et al. approach to Automated Approach for Echo interpreta- tion An echo study is typically a collection of up to 70 videos of the heart taken over multiple cardiac cycles and focusing on different viewpoints. The heart is visualized from ¿10 different views, and still images are typi- cally included to enable manual measurements. ¿7,000,000 echo studies are performed annually in Medicare population alone, and there are likely (an estimate by Deo) of about 100,000,000\\'s of archived echo studies. Zhang et al. built a pipeline using 14k raw echo studies and traditional computer vision algorithms for view classification and segmentation into 5 views to perform cardiac structural and functional analysis. This is an automated and low cost approach to echo interpretation. See Figure 6. 6.S897/HST.956 Machine Learning for Healthcare - Lec10 7'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some challenges unique to machine learning in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some challenges unique to machine learning in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some challenges unique to machine learning in healthcare?', ['6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1', \"© source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Funura Regulation The stakeholders: (Gov't Employer's Gov't Individuals) Insurance Payment Coverage Reguration Taxes or Came and Premiums Bill Care/Hearth Services imavidun Patients (Consumer) Doctors) Direct Payment Figure 4: The healthcare system is comprised of several important pieces 3.1.2 Propagating best practices As medical knowledge becomes more specialized, it becomes important to find ways to share best practices. Professor Sontag believes this could be particularly useful in academic medical centers to aid in the training of new doctors and in less populated areas where doctors might need to cover a broader set of conditions. 3.2 Efficient healthcare workflows Machine learning can make many healthcare workflows more efficient. Image processing techniques for chest x-rays and EKGs could help reduce the number of specialist consults. On the administrative side, machine learning can be automate documentation and billing processes. Wearable devices allow for continuous moni- toring, potentially allowing for better management of chronic diseases. With more data, it would be possible to better understand chronic disease progression. Liquid biopsy could potentially lead to earlier diagnoses. 3.3 Facilitating discovery In addition to healthcare management, there are opportunities for data-driven methods to aid in discovery. Machine learning methods could help to identify disease subtypes, search for optimal molecular structures for binding sites, and facilitate new clinical trial designs. The promises of precision medicine become feasible when data is aggregated and analyzed efficiently at scale. 4 What is unique about machine learning for healthcare? Healthcare is different from other machine learning applications because the gravity of life and death decision- making. The algorithms need to be more robust than other common ML applications such as search or object recognition. There need to be deliberate checks and balances to the ML deployment with considerations for both fairness and accountability. Many questions in healthcare do not neatly align with the current advances in machine learning. Many healthcare problems are concerned with semi-supervised or unsupervised learning. Often in healthcare, it is important to identify causal relationships. In addition to the theoretical challenges, implementing data-driven systems has additional challenges in healthcare. It is already a challenge to integrate new technologies into industrial workflows. In addition 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 5\", 'to those challenges, patient data is particularly sensitive, SO de-identification is necessary and negotiating data sharing agreements is time-consuming. Due to the complexity of the healthcare system, there is often missing data and different training data VS testing data distributions. Production EHR systems might be difficult to work with, as each commercial system is slightly different. 5 Overview of course syllabus The goals for this class are to provide intuition for healthcare data and machine learning algorithms along with understanding of the subtleties in applying these methods to the real world and challenges for future research. References [Blu19] Robert Blum. RX Project Notes. https://www.bobblum.com/ESSAYS/COMPSCI/rx-project. html, 2019. [Online; accessed 05-February-2019 [Mil10] RA Miller. A history of the internist-1 and quick medical reference (qmr) computer-assisted diagnosis projects, with lessons learned. Yearbook of medical informatics, 19(01):121-136, 2010. [PF96] Will Penny and David Frost. Neural networks in clinical medicine. Medical Decision Making, 16(4):386-398, 1996. [RIZ+17] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv: 1711.05225, 2017. [SA75] Edward H Shortliffe and Stanton G Axline. Computer-based consultations in clinical therapeutics: Explanation and rule acquisition capabilities of the mycin. 1975. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 6'])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some examples of publicly available healthcare datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some examples of publicly available healthcare datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8686EFFD0>, 'What are some examples of publicly available healthcare datasets?', ['KNOWLEDGE FROM MEDICAL LITERATURE SUBSET OF DATABASE KNOWLEDGE BASE STATISTICAL PACKAGE DISCOVERY MODULE STUDY MODULE HYPOTHESIS MEDICAL ENTIRE RESEARCHER DATABASE © Robert Blum. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 1: The RX Cycle 2 Why apply machine learning to healthcare today? From the previous examples, it is clear that researchers have tried to develop computational tools for health- care with relatively little success for 40+ years. Many have found new hope for AI in healthcare because of recent widespread EHR adoption, publicly available datasets, standardization of medical codes, and break- throughs in machine learning. 2.1 EHR Adoption In the last decade, health records transitioned from mostly on paper to mostly electronic. The shift to EHR has been swift, increasing by 9x since 2008, growing from 9.4% of hospitals to nearly 84% See Figure 3 for the adoption trend from 2008 to 2015. This highlights a theme for the rest of the course: that new policy can open the door to innovation. 2.2 Data New medical datasets are now publicly available. Mimic, the only publicly available EHR dataset, was created out of MIT, consisting of intensive care unit patient records. From the MIMIC Physiotnet website, \"MIMIC is an openly available dataset developed by the MIT Lab for Computational Physiology, comprising de-identified health data associated with 40,000 critical care patients. It includes demographics, vital signs, laboratory tests, medications, and more.\" Chexpert, a large publicly available image dataset, was created in collaboration between Stanford and MIT [RIZ+17]. From the Chexpert website, \"CheXpert is a large dataset of chest X-rays and competition for automated chest x-ray interpretation, which features uncertainty labels and radiologist-labeled reference standard evaluation sets.\" The Truven Marketscan data is not a publicly available dataset, but it\\'s available in this class and it\\'s useful because it has \"data on nearly 230 million unique patients since 1995.\" Here\\'s a link to the Marketscan website. Additionally new streams of data that are relevant to health have become available to researchers. Sources of new diverse data streams include: wearable devices, phones, social media, proteomics, and genomics. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 2', 'to those challenges, patient data is particularly sensitive, SO de-identification is necessary and negotiating data sharing agreements is time-consuming. Due to the complexity of the healthcare system, there is often missing data and different training data VS testing data distributions. Production EHR systems might be difficult to work with, as each commercial system is slightly different. 5 Overview of course syllabus The goals for this class are to provide intuition for healthcare data and machine learning algorithms along with understanding of the subtleties in applying these methods to the real world and challenges for future research. References [Blu19] Robert Blum. RX Project Notes. https://www.bobblum.com/ESSAYS/COMPSCI/rx-project. html, 2019. [Online; accessed 05-February-2019 [Mil10] RA Miller. A history of the internist-1 and quick medical reference (qmr) computer-assisted diagnosis projects, with lessons learned. Yearbook of medical informatics, 19(01):121-136, 2010. [PF96] Will Penny and David Frost. Neural networks in clinical medicine. Medical Decision Making, 16(4):386-398, 1996. [RIZ+17] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv: 1711.05225, 2017. [SA75] Edward H Shortliffe and Stanton G Axline. Computer-based consultations in clinical therapeutics: Explanation and rule acquisition capabilities of the mycin. 1975. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 6', '2.2 Data This case study used administrative data from a health insurance company containing information about a patient population in Philadelphia. The types of data found in this dataset are summarized in the following diagram: Medication Eligibility Record: NBC code (drug Member ID named Age/gender Days ml apply -ID of subscriber Quantity Company code -Service Provider n Date of no Patient: time Medical Claims: Lab Tests: ACD9 diagnosis codes -LOINC code (urine or CPT code (procedure) blood test name) Specialty Results (actual values) Location of service -Lab ID -Date of Service Range high/low-Date Figure 6: Overview of Data Types The top diagnoses and administered lab tests in this dataset are shown in the tables below. Many of the most frequent lab tests come from the CBC panel, a common set of tests carried out during annual physicals and checkups. Note that the end of the lab test table contains the hemoglobin A1C test, used to measure blood glucose levels and track the status of diabetes patients. Type 2 Diabetes is also one of the most common diagnoses among the patient cohort. Lab test Lab test Lab test Disease count 2160-OCreatining 1284737 770-8 Neutrophil/200 2085-9 Cholesterol in HDL 1155666 4011 Benign hypertension 447017 1094-0 Urea netogen 1282344 tookocytes 952089 718-7 Memoglobie 1157726 1280813 731-Citymphocytes 943918 2724 Hyperlipidemia NEC/NOS 382030 2823-3 Fotatulum 4544-3 Hematocnt 1147893 2345-7 Cluruse 1299897 704-7 Basophin 863448 4019 Hypertension NOS 372477 9830-1 1742-6 Alanine 7112 Eminophis 935710 25000 DMII wo cmp nt st uncnts 339522 Cholesterol total/Cholester iminotranste 1187809 our HOL 1037730 5505-5 Monocytes/100 2720 Pure hypercholesterolem 232671 943754 1920-3 Aspartate 33914-3 Glemerular 2722 Mixed hyperlipidemia 180015 aminotranst 1187965 706-2 Basophis/100 filtration rate/1.33x 2885-2 Protein 561309 kukocyter 863435 V7231 Routine gyn examination 178709 1277338 M.predicted 1751-7 Albumin 1274166 751-8 Neutrophils 943233 2449 Hypothyroidism NOS 169829 285-9 trythrocyte mrah 2093-1 Cholesterol 1268269 corpuscular hemoglobin 1070832 742-7 Manocytes 942978 78079 Malaise and fatigue NEC 149797 2571-8 Trighyceride 1257751 713-5 Eosinophile/100 5690-2 Leukecytes 1062980 V0481 Vaccin for influenza 147858 13457-7 Cholesteral LD 1241208 leukocytes 932929 789-8 Ecythrocytes 1062445 7242 Lumbagn 137345 1016-3 Thyrotropin 891807 17861 & Calcium 1165370 787-2 Erythrocyte mean 4548-4 Hemoglobin V7612 Screen mammogram NEC 129445 2951-2 Sodium 1167675 corpuscular volume 1053665 Alc/Hemoglobin.com 527052 V700 Routine medical exam 127848 Figure 7: Most Frequent Diagnoses and Administered Lab Tests in Patient Cohort 2.3 Machine Learning Formulation This problem is treated as a binary classification problem: predicting whether or not a patient will develop diabetes. Data is collected for each patient before January 1, 2009, and the classification models predict 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 6'])\n"
     ]
    }
   ],
   "source": [
    "for content_type in [\"Video\", \"PDF\"]:\n",
    "    print(f\"\\nEvaluating {content_type} content\")\n",
    "    table_name = f\"{course_name}_{content_type.lower()}\"\n",
    "    retriever = ContentRetriever(snow_session, table_name)\n",
    "    tru_app = TruCustomApp(\n",
    "        retriever,\n",
    "        app_name=f\"{content_type} Retriever\",\n",
    "        app_version=\"base\",\n",
    "        feedbacks=feedbacks,\n",
    "    )\n",
    "\n",
    "    with tru_app as recording:\n",
    "        for question in eval_questions:\n",
    "            response = retriever.search(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does metadata filtering help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decorating <function ContentRetrieverWithFilter.search at 0x000001E86AE60860>\n",
      "decorating <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0>\n",
      "adding method <class '__main__.ContentRetrieverWithFilter'> search __main__\n",
      "adding method <class '__main__.ContentRetrieverWithFilter'> retrieve __main__\n"
     ]
    }
   ],
   "source": [
    "class ContentRetrieverWithFilter(ContentRetriever):\n",
    "    @instrument\n",
    "    def search(self, query: str, lecture_name: str) -> str:\n",
    "        context = self.retrieve(query, lecture_name)\n",
    "        answer = self.complete(query, context)\n",
    "        return answer\n",
    "\n",
    "    @instrument\n",
    "    def retrieve(self, query: str, lecture_name: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Retrieve documents from cortex search service.\n",
    "        \"\"\"\n",
    "        filter_query = {\"@eq\": {\"lecture_name\": lecture_name}}\n",
    "        documents = self.service.search(query, columns=[\"text\"], limit=3, filter=filter_query)\n",
    "        return [doc[\"text\"] for doc in documents.results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Video content\n",
      "instrumenting <class '__main__.ContentRetrieverWithFilter'> for base <class '__main__.ContentRetrieverWithFilter'>\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting search\n",
      "instrumenting <class '__main__.ContentRetrieverWithFilter'> for base <class '__main__.ContentRetriever'>\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting search\n",
      "skipping base <class 'object'> because of class\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the primary function of the heart in the circulatory system?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the primary function of the heart in the circulatory system?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the primary function of the heart in the circulatory system?', [\"So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps about 5 liters of blood a minute, and with exercise, that can go up 5 to 7 fold or so with with sort of conditioned athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about 3 seconds, you are likely to to to get light headed or pass out. So you have to maintain a sort of this rhythmic beat in your heart, and and you can kinda compute what that would be in somewhere around 2,000,000,000 beats in a in a typical lifetime. So I'm gonna show a lot of pictures and videos throughout this, so it's probably worthwhile just to take a pause a little bit and talk about what the what the anatomy of the heart is. So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or or the superior vena cava.\", \"So every time people try to get funding for for coronary heart disease, they try to talk up just how important it is. So this is still, you know, we have some battles with with the oncology people, but this is still the leading cause of of death in the world. And and then people are like, oh, you're just you're just you're just emphasizing the developed world. There's, you know, lots of lots of communicable diseases that matter much more. So even if you look at those and you sort of look at the bottom here, this still if this is sort of all causes of death age adjusted, cardiovascular disease is still sort of number 1 amongst that. So so certainly it remains important, and and sort of increasingly so in some of the developing world also. So, it's important to think a little bit about what the heart does because this is gonna guide at least the way that diseases have been classified. So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ.\", \"So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or or the superior vena cava. This is draining from the brain, this is draining from the lower body, and then enters into a chamber called the right atrium. It moves through something called the tricuspid valve into what's called the right ventricle. So right ventricle has got some muscle to it. It pumps into the lungs. There, the blood picks up oxygen, so that's why it's sort of shown as being red here. The the oxygenated blood comes through the left atrium and then into the left ventricle through something called the mitral valve. We'll show you some pictures of the mitral valve later on. And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last last class on the electrical system.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the two circulations the heart conducts in series?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the two circulations the heart conducts in series?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the two circulations the heart conducts in series?', [\"And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last last class on the electrical system. So the sinoatrial node is up here in the right atrium, and then conduction sort of goes through. So the p wave on an EKG is is represents the conduction through there. You get through the Savi node where there's a delay, which is the PR interval, and then you get spreading through the ventricles, which is the QRS complex, and then repolarization is the t wave. So that's that's sort of the electrical system. And, of course, these things have to kind of work intimately together. Every sort of like, the every single basic kind of cardiac physiology will show this this diagram called the Wigner's diagram, which really just shows the sort of the interconnectedness of the electrical system. So there's the EKG up there. These are the heart sounds that that a provider would listen to with a stethoscope, and this is capturing the flow of sort of the changes in in pressure in the heart and in the aorta. So heart fills during a period of time called diastole, The mitral valve closes, the ventricle contracts, the pressure increases.\", \"So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or or the superior vena cava. This is draining from the brain, this is draining from the lower body, and then enters into a chamber called the right atrium. It moves through something called the tricuspid valve into what's called the right ventricle. So right ventricle has got some muscle to it. It pumps into the lungs. There, the blood picks up oxygen, so that's why it's sort of shown as being red here. The the oxygenated blood comes through the left atrium and then into the left ventricle through something called the mitral valve. We'll show you some pictures of the mitral valve later on. And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last last class on the electrical system.\", \"So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps about 5 liters of blood a minute, and with exercise, that can go up 5 to 7 fold or so with with sort of conditioned athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about 3 seconds, you are likely to to to get light headed or pass out. So you have to maintain a sort of this rhythmic beat in your heart, and and you can kinda compute what that would be in somewhere around 2,000,000,000 beats in a in a typical lifetime. So I'm gonna show a lot of pictures and videos throughout this, so it's probably worthwhile just to take a pause a little bit and talk about what the what the anatomy of the heart is. So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or or the superior vena cava.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', [\"Echocardiography, which involves sound waves, is ultimately more used for quantifying structure and function, can pick up heart failure, valvular disease, high blood pressure in the lungs. So so that's another modality. MRI, which is just not used all that much in this country, is very expensive but does largely the same things. And you can imagine even though it's beautiful, people have not had an easy time and able to justify why it's any better than this slightly cheaper modality. And then you have angiography, which can either be by CAT scan or by x-ray, and that visualizes the flow of blood through the heart and looks for blockages, which are going to be stented, ballooned up and stented. And then you have these kind of noninvasive technologies like PET and SPECT that use radionuclatides, like technetium, rubidium, and they look for abnormalities in blood flow to detect whether noninvasively there's some patch of the heart that isn't getting enough blood. If you get one of these and it's abnormal, often you go over there. You can take a trip to the movies, as my old teachers used to say, and then you may get, you may find yourself with an angioplasty or stent or a bypass.\", \"And then you have these kind of noninvasive technologies like PET and SPECT that use radionuclatides, like technetium, rubidium, and they look for abnormalities in blood flow to detect whether noninvasively there's some patch of the heart that isn't getting enough blood. If you get one of these and it's abnormal, often you go over there. You can take a trip to the movies, as my old teachers used to say, and then you may get, you may find yourself with an angioplasty or stent or a bypass. So one of the sort of sad things about cardiology is we don't define our diseases by biology. We define our diseases often related to whether the anatomy or the physiology is abnormal or or normal, usually based on some of these images or some of these numbers. Okay. So so we have to make decisions, and we often use these very same things too to be able to make some decisions. So we have to decide whether we wanna put a defibrillator. And if to do so, you often need to to get a echocardiogram to look at the pumping function of the heart. If you wanna decide on whether somebody needs angioplasty, you have to get an angiogram. If you wanna decide to get a valve replacement, you need an echo. But but, some of these other ones actually don't involve any imaging, and this is sort of one of the challenges that I'm gonna talk about is that is that all of the sort of the future, if you can imagine building brand new risk models, new classification models, you're stuck with the data that's out there.\", \"And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself. And so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you want to have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately doesn't deal well with with the moving aspect. So coronary angiography has very, very fast frame rates. So that's x-ray, and that's sort of very fast. Echocardiography can be quite fast. MRI and CT are not quite as good, and so there's some degradation of the image. As a result, people do something called gating, where they'll take the electrocardiogram, the ECG, and try to line up different portions of different heartbeats and say, well, you know, we'll take this image from here, we'll line it up with this one from there, this one from there. I'm going to talk a little bit about that from about registration, but ultimately that's a problem that people have to deal with.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What challenge does cardiac motion pose to high-quality imaging scans?', [\"And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself. And so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you want to have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately doesn't deal well with with the moving aspect. So coronary angiography has very, very fast frame rates. So that's x-ray, and that's sort of very fast. Echocardiography can be quite fast. MRI and CT are not quite as good, and so there's some degradation of the image. As a result, people do something called gating, where they'll take the electrocardiogram, the ECG, and try to line up different portions of different heartbeats and say, well, you know, we'll take this image from here, we'll line it up with this one from there, this one from there. I'm going to talk a little bit about that from about registration, but ultimately that's a problem that people have to deal with.\", \"So you have the raw imaging data, but all the clinical stuff is somewhere else. So you have to sometimes link that, and so you need to get access there. And so just to give you a little bit of an idea of scale, so we're about to get all of the ECGs from Brigham and Women's, which is about 30,000,000, stored kind of historically. And this is all related to cost. So positron emission tomography, you can get about 8,000 or so, and we're one of the busiest centers for that. You know, echocardiograms are in the 300,000 to 500,000 ranges archived, so that gets a little bit more interesting. Okay. So what a DICOM header looks like. You have some sort of, identifiers, and then you have some information there, attributes of the images, patient name, date of birth, frame rate, these kind of things are there, and there's some variability. So it's never never quite easy. Okay. So, these different modalities have some different benefits to them, and this is why they're used for for one disease or the other. And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself.\", \"This is a not just a problem for us, but a problem for many people in this field. So so we need to be a little bit more adventurous in terms of trying some of these other methods. We did try a little bit of of that and didn't find huge huge gains, but I think ultimately there still needs to be a little bit more work there. Okay. So last thing I'm going to talk about before getting into to to my work is really this idea of image registration. So I talked about how there are sometimes some techniques that have limitations either in terms of spatial resolution or temporal resolution. So this is a PET scan here, this sort of reddish glow here. And in the background, we have a CAT scan of the of the heart. And so clearly this is a poorly registered image where you have this the PET scan kind of floating out here, but it really should be lined up here, and so you have something that's registered better there. Also mentioned this problem about gating. So ultimately, if you have a a image taken from different parts mature problem in the computer vision world. We haven't done anything in this space, but ultimately it has sort of been around for decades.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is a significant benefit of applying machine learning to cardiac imaging?', [\"So welcome, everyone. Today is the first of what will be a series of 4 guest lectures throughout the semester. There will be 2 guest lectures the week from starting the week from today, and then there'll be another one towards the end of the semester. And what Pete and I decided to do is to bring in people who know a lot more than us about some area of expertise. And today's instance is going to be about, about cardiovascular medicine, in particular, about how to use imaging and machine learning on images in that context. And for today's lecture, we're we're, very excited to have, professor Rahul Deo to speak. Rahul's name kept on showing up as I did research over the last couple of years. First, I my group was starting to get interested in echocardiography, and we said, oh, here's an interesting paper to read on it. We read it, and then we wrote another paper on doing subtyping of of ejection fraction as a type of heart failure, and we read it.\", \"Many of the starting things we're doing are kind of already picking up what everybody else here is already doing, but at the same time so it it's it's it's it's okay from that standpoint, but it really has to make its way. And that means that we have to have some mature understanding of what makes its way into practice, where the resistance will be. So the the lecture will be kind of peppered throughout with some kind of opinions and comments in that, and hopefully that will be useful. So just a quick outline. Just gonna introduce cardiac structure and function. Probably not part of the the sort of the regular undergraduate and graduate training here at MIT. Talk a little bit about what the major sort of cardiac diagnostics are and how they're used. And and all of this is really to help guide the the sort of the thought and the decision making about how we would ever automate and and bring this into sort of how to bring machine learning artificial intelligence to actual clinical practice. Because you need to give enough background so you realize what the sort of the the challenges are. And then the question probably everybody has is where's the data? How how would how would one get access to some of this stuff to be able to potentially do work in this area? And then I'm gonna sort of venture a little bit into computer vision and just talk about some of the the topics that that at least I've been thinking about that are relevant to to what we're doing.\", \"Like, in those days, the the slices were rather far Uh-huh. And so they would hallucinate what the structure looked like. Yeah. And, of course, that has the benefit of giving you a better model, but it also has the risk that it's hallucinated data. Have you guys tried doing that with some of the Yeah. That that's a great point. So oh, so okay. So the question was so in you know, cardiac imaging has a very long history. And so there was a period of time where there's these kind of active modelers around morphologies of the heart. And so people have these sort of models around what the heart should look like from many, many, many studies, and they were using that back in the time when you had these relatively coarse, multislice scanners for a CT. They would reconstruct the 3 d image of the heart based on sort of some preexisting geometric model of what the heart should look like. And there's, of course, a benefit to that for some risk in the sense that somebody may be very different in the space that's missing, and you may be and so the question is whether those kind of priors can be introduced in some way.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', [\"Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks, specifically in cancer and also, obviously, risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 2009 to 2016. This started off with about 280,000 cancers. And once we kinda filtered for at least 1 year follow-up, we ended up with this, you know, final setting where we had, 220,000 mammograms for training, and about 26,000 for development and testing. And the way we had our outcomes to say, you know, is this a positive mammogram or not? We didn't look at what cancers were caught by the radiologist. We'll say, you know, what was cancer that was fine in any means within a year? And where we looked, we looked through the radiology, HR, and the partners kind of 5 hospital registry. And they were really trying to say if a cancer if any way we can tell a cancer occurred, let's mark it as such, regardless of whether it was caught on MRI or some kind of later stage. And so the thing we're trying to do here is just mimic, you know, the real world of whether we not trying to catch cancer.\", \"Okay. Great. Well, thank you for the great setup. So for this section, I'm gonna talk about some of our work in interpreting mammograms for cancer. Specifically, it's gonna go into cancer detection and triaging mammograms. Next, we'll talk about kind of our technical approach to breast cancer risk. And then finally, close-up in the many many different ways to mess up and the way things can go wrong and how does a poor clinical implementation. So let's kind of look more closely at the numbers of the actual breast cancer screening workflow. So as Kanye already said, you might, you know, see something like a 1,000 patients, all of them take mammograms, and of that 1,000, on average, maybe a 100 be called back for additional imaging. Of that 100, something like 20 will get biopsied and end up with maybe 5 or 6 diagnoses of breast cancer. So one very clear thing you see about, you know, problems when you look at this funnel is that way over 99% of people that you see in a given day are cancer free, so your actual incidence is very low. And so there's kind of a natural question that can come up, what can you do in terms of modeling if you have, you know, an even okay cancer detection model to raise the incidence of this population but automatically reading a portion of the population is healthy?\", \"And in that, the actual can't show the confer might be 50 by 50 pixels. So intuitively, your signal to noise ratio is very different. Whereas, in ImageNet, my dog is like the entire image. She's huge, in real life and in that photo. And the image itself is much smaller. So not only do you have much smaller images, but you're kind of like the relative size of the object in there is much larger. To kind of further compounded difficulty, the pattern that you're looking for inside the mammogram is really context dependent. So if you saw that pattern somewhere else in the breast, it's not it doesn't indicate the same thing, and so you really care about where in this kind of global context this comes out. And if you kind of take the mammogram at different times with different compressions, you have this kind of non rigid morphing of the image that's much more difficult to model, whereas that's a more or less context independent dog. You see that kind of frame kind of anywhere you know it's a dog, and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just, like, the number of cancers we have, it's gonna be the cancer might be less than 1% of the mammogram and about 0.7% of your images have cancers.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the four categories of breast tissue density used in medical practice?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the four categories of breast tissue density used in medical practice?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are the four categories of breast tissue density used in medical practice?', [\"So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively, and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about?\", \"So if you can tell from an image that is gonna be healthy for a long time, you're really trying to model what's the likelihood of this breast developing cancer in the future. Now, modeling breast cancer risk, as Connie already said, is not a new problem. It's been a quite researched one in the community, and the more classical approach that we're gonna look at, other kind of global health factors, the person's age, their family history, whether or not they've had menopause, and kind of any other or these kind of factor we can try to say our markers of their health to try to predict whether or not those persons at risk of developing breast cancer. People have thought that the image contained something before. The way they've thought about this is through this kind of subjective breast density marker, and the improvements seen across this are kind of marginal from 61 to 63. And as before, the kind of sketch we're gonna go through is data collection, modeling, and analysis. In data collection, we followed a very similar template. We sought for the consecutive mammograms from 2009 to 2012. We took outcomes from the EHR, once again, and the partner's registry. We didn't do exclusions based on race or anything of that sort or implants, but we did exclude negatives for follow-up.\", \"So, for example but the kind of key core takeaway here is that the there was no noticeable gap in terms of by age group. We repeated this analysis by race and we saw, the same trend again. The performance kind of ranged generally around 82, and in places where the gap was bigger, the just confidence interval was bigger accordingly, due to smaller sample sizes because MGH is 80% white. We saw the exact same trend by density. The outline here is very dense breasts, but there's only like a 100 of those on test sets, so like this confidence level actually goes from like 60 to 90. So, as far as we know, for the other 3 categories, it is very much tighter confidence interval and very similar, once again, around 82. Okay. So we have a decent idea that this model seems at least with a population MGH, actually serve the relevant populations, you know, that exist as far as we know so far. The next question is, how does this how does a model assessment relate to the radiology assessment? So to look at that, we looked at on the test side, if you look at the radiology, true positives, false positives, true negatives, false negatives, where do they fall within the model distribution of, like, percentile risk?\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', [\"So, it shows that they're kind of picking up on different things and where they disagree gives us both areas to improve and some ancillary benefits because now we can reduce false positives. This directly leads into simulating the impact. So one of the things we did, we said, okay, if people retrospectively on the test set as a simulation before we truly plug it in, if people didn't re blow the triage threshold, so we can't catch anymore, catch it this way, but we can reduce false positives, what would have happened? So at the top, we have the original performance. So this is looking a 100% of mammogram, sensitivity was 90.6 with specificity of 93, And in the simulation, the sensitivity dropped, not significantly to 90.1, but significantly improved to 93.7 while looking at 80% or 81% of the mammograms. So this is like promising preliminary data, but to reevaluate this and go forward, our next step see if I oh, I'm gonna get to that in a second. Our next step is really do clinical implementation, to really figure out, because there's like a core assumption here was that people read it the same way. But if you have this higher incidence, what does that mean? Can you focus more on the people that are more suspicious, and is the right way to do this just a single threshold to not read, or have a double ender with the same, these are much more likely to have cancer.\", \"Okay. Great. Well, thank you for the great setup. So for this section, I'm gonna talk about some of our work in interpreting mammograms for cancer. Specifically, it's gonna go into cancer detection and triaging mammograms. Next, we'll talk about kind of our technical approach to breast cancer risk. And then finally, close-up in the many many different ways to mess up and the way things can go wrong and how does a poor clinical implementation. So let's kind of look more closely at the numbers of the actual breast cancer screening workflow. So as Kanye already said, you might, you know, see something like a 1,000 patients, all of them take mammograms, and of that 1,000, on average, maybe a 100 be called back for additional imaging. Of that 100, something like 20 will get biopsied and end up with maybe 5 or 6 diagnoses of breast cancer. So one very clear thing you see about, you know, problems when you look at this funnel is that way over 99% of people that you see in a given day are cancer free, so your actual incidence is very low. And so there's kind of a natural question that can come up, what can you do in terms of modeling if you have, you know, an even okay cancer detection model to raise the incidence of this population but automatically reading a portion of the population is healthy?\", \"So, something like, let's say, some of the lower dimensions can summarize like, is this a dense breast or kind of some of the other pattern information that might tell you what what kind of breast this is, whereas any one of them can tell you this, this looks like a cancer given its local context. So, do you have some level of summarization both because of the channel wise maximum of the end and because each point through the many many convolutions of different strides gives you some of that summary effect. Okay. Great. I'm gonna jump forward. So we talked about how to make this learn. It's actually not that tricky if you just do it carefully and tune. Now, let's talk about how to use this model to actually deliver on this triage idea. So to summarize my choices again, image analysis is gonna make your life a happier time. Use bigger batch sizes, and the architecture choice doesn't really matter if it's convolutional. And the overall setup that we do through this work and across many other projects, we're training independently per image. Now, this is a harder task, because you don't actually have the focal you're not taking any other view, you're not taking prior mammograms, but this is for kind of more harder reasons than not.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', [\"You see that kind of frame kind of anywhere you know it's a dog, and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just, like, the number of cancers we have, it's gonna be the cancer might be less than 1% of the mammogram and about 0.7% of your images have cancers. Even in this data set, which is from 2000 to 2016 NGH, a massive imaging center, in total, across all of that, we all still have, like, less than 2,000 cancers. And this is super tiny compared to, like, regular object classification data sets. And this is, you know, looking at over a 1,000,000 images if you look at all the four views of the exams. And at the same time, it's also too big. So, even if I down sample these images, I can only really fit 3 of them for a single GPU, and so this kind of limits the batch size I can work with. And whereas the kind of comparable, if I took just the regular ImageNet size, I could fit batch sizes of 128, easily happy days, and do all this parallelization stuff, and it's just much easier to play with. And finally, the actual data set itself is quite large, and so you have to do some, there's no uses to deal with in terms of, like, just setting up your server infrastructure to handle these massive data sets, while still being able to train efficiently.\", \"So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively, and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about?\", \"But in general, our, like, a true deeper derecognizing, what it says, it still eludes us and isn't something I can give too much conclusions about, unfortunately. Okay. So that's generalization, and if you don't get this right, kind of nothing works for a very long time. So just if you're gonna start a project in the space, try this. Next, another important decision that if you don't do kind of breaks, is your optimization and architecture choice. So as I said before, kind of a core problem in stability here is this idea that our signal to noise ratio is really low. And so, a very common approach throughout a lot of the prior work and things I actually have tried myself before is to say, okay, let's just break down this problem. We can train at a patch level first. We're gonna take just subsets of the mammogram, maybe this little bounding box, have it annotated for radiology findings, like benign masses or calcification, things of that sort. We're gonna pre train on that task that has this kind of pixel level prediction. And then once we're done with that, we're gonna just fine tune that initialize model across the entire image. So you kinda have this, like, 2 stage training procedure.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', [\"So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts. So in terms of looking at high risk cohorts, our best model plays about 30% of all the cancers in the population in the top 10%, and 3% of all the cancers in the bottom 10%, compared to 185 to the prior state of the art. And so, what this enables you to do if you're gonna say that, you know, this 10% should actually qualify for MRI, you can start fighting this problem of majority of people that get cancer don't have MRI and the majority of people that get it don't need it. It's all about is your risk model actually placed the right people into the right buckets. Now, we saw that this trend of outperforming the prior state of the art held across races, and one of the things that was kind of astonishing was that, though Thai cuisine performed by white women, which makes sense because it was developed only using white women in the UK, it was worse than random in our data set of African American women. And so, this kind of, emphasizes the importance of this kind of analysis to make sure that the kind of data set that you have is reflective of the population you're trying to serve, and actually doing the analysis, accordingly.\", \"Our kind of goals for the analysis as before, we wanna see, does this model actually serve the whole the whole population? Is it gonna be discriminative across race, menopause, status, and family history? And how does this relate to kind of classical portions of risk, and are we actually doing any better? And so just diving directly into that, assuming there's no questions. Good. Just kinda remind you, this is the kind of the setting. One thing I forgot to mention, that's why I had the slide here to remind me, is that we excluded cancers from the 1st year from the test set, so there's truly a negative screening population. So the way we we kind of disentangle cancer detection from cancer risk. Okay. Cool. So Tyre Cusick is the kind of prior state of the art model. It's a model based out of the UK. They're developed by someone named Sir Cusick, who's knighted over this work. It's very commonly used. So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts.\", \"So, for example but the kind of key core takeaway here is that the there was no noticeable gap in terms of by age group. We repeated this analysis by race and we saw, the same trend again. The performance kind of ranged generally around 82, and in places where the gap was bigger, the just confidence interval was bigger accordingly, due to smaller sample sizes because MGH is 80% white. We saw the exact same trend by density. The outline here is very dense breasts, but there's only like a 100 of those on test sets, so like this confidence level actually goes from like 60 to 90. So, as far as we know, for the other 3 categories, it is very much tighter confidence interval and very similar, once again, around 82. Okay. So we have a decent idea that this model seems at least with a population MGH, actually serve the relevant populations, you know, that exist as far as we know so far. The next question is, how does this how does a model assessment relate to the radiology assessment? So to look at that, we looked at on the test side, if you look at the radiology, true positives, false positives, true negatives, false negatives, where do they fall within the model distribution of, like, percentile risk?\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the primary challenge with using billing codes for clinical research?', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the primary challenge with using billing codes for clinical research?', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the primary challenge with using billing codes for clinical research?', [\"What and and there's a systematic reason, because those billing codes were not created in order to specify what's wrong with the patient. They were created in order to tell an insurance company or Medicare or somebody how much of a payment is deserved by the doctors taking care of them. And so what this means is that, for example, if I clutch my chest and go, and an ambulance rushes me over to Mass General, And they do a whole bunch of tests, and they decide that I'm not having a heart attack. The correct billing code for that visit is myocardial infarction, because, of course, the work that they had to do in order to figure out that I'm not having a heart attack is the same as the work they would have had to do to figure out that I was having a heart attack. And so, the billing codes, we've talked about this a little bit before, but they're a very imperfect representation of reality. So we said, well, okay. What if we insisted that, you have 3 billing codes for rheumatoid arthritis rather than just one?\", \"The the I think the biggest challenge right now is the mapping. So ICD 9, you know, is now doesn't map directly to ICD 10 or back because there are diseases that we didn't know when they developed ICD 9 that exist in ICD 10. In ICT 10, they talk about diseases in ways that weren't described in ICD 9. So when you're trying to harmonize the data, and this is actively something we're dealing with right now at the VA, how do you now count the ICD codes? How do you consider that someone has an ICD code for RA? So those are all things that are being developed now. CMS, Center For Medicaid and Medicare, again, this is for billing purposes, has come up with a mapping system that many of us are using now given what we have. And by the way, the the committee that is designing ICD 11 Yeah. Has been very active for years. And so there's another one coming down down the pike. Although from what I understood you posit that?\", \"And so we went to the research patient data repository of Mass General and and the Brigham Partners Healthcare. And we said, okay. Who are the patients who have been billed for a rheumatoid arthritis visit? And there are many thousands of those people. Okay? And then we selected a random set of, I think, 400 of those patients. We gave them to rheumatologists, and we said, which of these people actually have rheumatoid arthritis? K. So these were based on billing codes. So what would you guess is the, positive predictive value of having a billing code for rheumatoid arthritis in this data set? I mean, how many people think it's more than 50%? Okay. That would be nice, but it's not. How many people think it's more than 25%?\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', [\"So what we did is to say, well, if you train a data set that tries to tell you whether somebody really has rheumatoid arthritis or not based on just codified data. So codified data is things like lab values and prescriptions and demographics and stuff that is in tabular form. Then we were getting a positive predictive value of about 88%. And we said, well, how how well could we do by instead of looking at that codified data, looking at the narrative text in nursing notes, doctors' notes, discharge summaries, various other sources, could we do as well or better? And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%.\", \"And the natural language queries were also extracted in different ways, because Vanderbilt, for example, already had a tool in place where they would try to translate any text in their notes into UMLS concepts, which we'll talk about again in a little while. So my expectation when I heard about this study is that this would be a disaster, okay, that it would simply not work, because there are local effects, local factors, local ways that people have of describing patients that I thought would be very different between Nashville, Chicago, and Boston. And much to my surprise, what they found was that, in fact, it kind of worked. So the model performance, even taking into account that the way the data was extracted out of the notes and the clinical systems was different, was fairly similar. Now one thing that is worrisome is that the PPV of our algorithm on our data, the way we calculated PPV they calculated PPV in this study came in lower than the way we had done it when we when we found it.\", \"And the, predictors actually are an interesting mix of ones based on natural language processing and ones that are codified. So, for example, you have rheumatoid arthritis. If if a note says the patient has rheumatoid arthritis, that's pretty good evidence that they do. If somebody has characterized this being seropositive, that's, again, good evidence. And then, erosions and so on. But there are also codified things, like if you see that the rheumatoid factor in a lab test was negative, then actually, what? I don't know why that's oh, no. That counts against. Okay. And then various exclusions. So these were the things selected by our regularized logistic regression algorithm. And I showed you the results before. So we were able to get a positive predictive value of about 0.94.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some goals of NLP in healthcare as discussed in the lecture?', [\"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations. But I'm not sure where the the boundary is going to fall. I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview.\", \"And this is probably not meant to be readable by anybody except the person who wrote it or maybe their immediate friends and colleagues. So this is a real issue and one that we don't have a very good solution for yet. Now what do you use NLP for? Well, I had mentioned that one of the things we want to do is to codify things that appear in a note. So if it says rheumatoid arthritis, we want to say, well, that's equivalent to a particular ICD 9 code. We might want to use natural language processing for de identification of data. I mentioned that before. You know, Mimic, the only way that that Roger Marks' group got permission to release that data and make it available for people like you to use is by persuading the IRB that we had done a good enough job of getting rid of the all the identifying information in all of those records so that it's probably not technically impossible, but it's very difficult to figure out, who the the patients actually were in that cohort, in in that database.\", \"So one of the things that we didn't know when we first started out was how many gold standard labels did we need, and how many features did we need, and which of those features would be important. So by features, I mean ICD codes, the diagnosis code, medications, and all that list of NLP terms that might be related to the condition. And so now we have ways to try to whittle down that list before we even use those gold standard labels. And so may let me think about so this is NLP. The focus here is on NLP. So there are couple ways we're doing this. So one rate limiting step was getting the clinicians to come up with a list of terms that are important for a certain condition. You can imagine if you get 5 doctors in a room to try to agree on a list, takes forever. And so we tried to get that out of the way. So one thing we started doing was we took, just common things that are freely available on the Web, Wikipedia, Medline, the Merck Manual, that have medical information. And we actually now process those articles, look for medical terms, pull those out, map them to concepts, and that becomes that term list now that goes into so now instead of if you think about in the old days, we came up with a list.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', [\"And so the recursive machine learning problem is how best to identify the things associated with the term. And this is generally known as phenotyping. Now, how many of you have used the UMLS? Just a few. So in 1985 or 'eighty 4, the newly appointed director of the National Library of Medicine, which is one of the NIH institutes, decided to make a big investment in creating this unified medical language system, which was an attempt to take all of the terminologies that various medical professional societies had developed and unify them into a single, what they called a metathesaurus. So it's not really a thesaurus, because it's not completely well integrated, but it does include all of this terminology.\", \"So one of the things that we didn't know when we first started out was how many gold standard labels did we need, and how many features did we need, and which of those features would be important. So by features, I mean ICD codes, the diagnosis code, medications, and all that list of NLP terms that might be related to the condition. And so now we have ways to try to whittle down that list before we even use those gold standard labels. And so may let me think about so this is NLP. The focus here is on NLP. So there are couple ways we're doing this. So one rate limiting step was getting the clinicians to come up with a list of terms that are important for a certain condition. You can imagine if you get 5 doctors in a room to try to agree on a list, takes forever. And so we tried to get that out of the way. So one thing we started doing was we took, just common things that are freely available on the Web, Wikipedia, Medline, the Merck Manual, that have medical information. And we actually now process those articles, look for medical terms, pull those out, map them to concepts, and that becomes that term list now that goes into so now instead of if you think about in the old days, we came up with a list.\", \"And then as people did this, they said, well, there must be more sophisticated ways of doing this. And so a whole industry developed of people saying that not only should we use the terms that we got originally from the doctors who were interested in doing these queries, but we can define a machine learning problem, which is how do we learn the set of terms that we should actually use that will give us better results than just the terms we started with? And so I'm gonna talk about a little bit of of that approach. First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the role of term spotting and negation handling in clinical NLP?', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the role of term spotting and negation handling in clinical NLP?', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the role of term spotting and negation handling in clinical NLP?', [\"And then as people did this, they said, well, there must be more sophisticated ways of doing this. And so a whole industry developed of people saying that not only should we use the terms that we got originally from the doctors who were interested in doing these queries, but we can define a machine learning problem, which is how do we learn the set of terms that we should actually use that will give us better results than just the terms we started with? And so I'm gonna talk about a little bit of of that approach. First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary.\", \"First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary. So I'll talk a little bit about that. But basically, it's a dictionary lookup. You look up in this very large database of medical terms and translate them into some kind of expression that represents what that term means. And then you find 2 kinds of patterns. One pattern is a negation phrase followed within 5 words by one of these UMLS terms, and the other is a UMLS term followed within 5 words by a negation phrase, different set of negation phrases. So if you see no sign of something, that means it's not present. Or if you see ruled out unlikely something, then it's not present.\", \"I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview. So roughly, the outline of these two lectures is that I want to talk a little bit about why we care about clinical text. And then I'm going to talk about some conceptually very appealing, but practically not very feasible methods that involve analyzing these narrative texts as linguistic entities, as linguistic objects, in the way that a linguist might approach them. And then we're going to talk about what is very often done, which is a kind of term spotting approach that says, well, we may not be able to understand exactly everything that that goes on in the narratives, but we can identify certain words and certain phrases that are very highly indicative that the patient has a certain disease, a certain symptom, that some particular thing was done to them.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is risk stratification and why is it important in healthcare?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is risk stratification and why is it important in healthcare?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is risk stratification and why is it important in healthcare?', [\"Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring. Now, risk stratification is quite different from diagnosis. Diagnosis often has very, very stringent criteria on performance. If you do a misdiagnosis of something, that can have very severe consequences in terms of patients being treated for conditions that they didn't need to be treated for and patients dying because they were were not diagnosed in time. Now risk stratification, you think of as a little bit more fuzzy in nature. We wanna do our best job of trying to push patients into each of these categories, high dose, low risk, and so on.\", \"Although today's lecture is going to be a little bit more high level, next Thursday's lecture is where we're going to really start to get into mathematical details about how one should tackle machine learning problems with sensor data. And then the following lecture after that is going to be on physiological data. And that lecture will also be much more technical in nature compared to the first couple of weeks of the course. So what is risk stratification? At a high level, you should think about risk stratification as a way of taking in a patient population and separating out all of your patients into 1 of 2 or more categories. Patients with high risk, patients with low risk, and maybe patients somewhere in the middle. Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring.\", \"But every single project that I've been a part of has been an effort to bring in data that has always been there, but we haven't been able to to learn from until now. And whether that's, you know, at the VA building out their genomic, science infrastructure and recruiting and enrolling a million veterans to to to donate their blood and their EMR or at Ariadne Labs over out of Harvard School of Public Health in the Brigham, improving childbirth in India. It it's all about how can we get a little bit better over and over again to make health care, you know, better place for folks. So so tell me, what is risk stratification from your perspective? Right? Defining that, I found to be one of the most difficult parts of today's lecture. Well, thank you for challenging me with it. So So it's a rather generic term, and I think it depends entirely on the problem you're trying to solve. And every time I I go at this, you really have to ground yourself in the problem that you're trying to solve. Risk could be running out of a medical supply, in an operating room. Risk could be an APGAR score. Risk could be, from pre diabetic to diabetic. Risk could be an older person falling down in their home.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', [\"And each one of those steps takes a lot of time. Now with these machine learning based approaches, it raises the possibility of a research assistant sitting in a hospital or in a computer science department saying, oh, I think it would be really useful to derive a score for this problem. You apply your machine learning algorithm. And even if it's a condition or an outcome, which occurs very infrequently, if you have access to a large enough data set, you'll be able to get enough samples in order to actually predict that somewhat very narrow outcome. And so as a result, it really opens the door to rethinking about the way that risk stratification can be can be used. But as a result, there are also new dangers that are introduced. And we'll talk about some of those in today's lecture, and we'll continue to talk about those in next Thursday's lecture. So these models are being widely commercialized.\", \"Well, the traditional approaches to risk stratification are based on scoring systems. So I mentioned to you a few minutes ago the APGAR scoring system. It's shown here. You're going to say for each of these different criteria, activity, pulse, grimace, appearance, respiration, You look at the baby and you say, well, activity is absent or maybe their active movement. Appearance might be pale or blue, which would get 0 points, or completely pink, which gets 2 points. And for each one of these answers, you add up the corresponding points. So you get a total number of points. And you look over here and you say, okay. Well, baby is at risk, at severe risk. If they have 7 to 10 points, then then the baby is low risk. And there are hundreds of such scoring rules which have been very carefully derived through studies not dissimilar to the one that you read for today's readings and which are actually widely used in the health care system today.\", \"So one has to think to do the score. One has to figure out what the corresponding inputs are. And as a result of that, often they're not used as frequently as they should be. 2nd, the new machine learning approaches can get higher accuracy, potentially, due to their ability to use many more features than the traditional approaches. And finally, they can be much quicker to drive. So all of the traditional scoring systems had a very long research and development process that lead that led to their adoption. First, you gather the data, then you build the models, then you sanity check the models, then you do an evaluation in 1 hospital, then you do a prospective evaluation in many hospitals. And each one of those steps takes a lot of time. Now with these machine learning based approaches, it raises the possibility of a research assistant sitting in a hospital or in a computer science department saying, oh, I think it would be really useful to derive a score for this problem.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How is label leakage managed in diabetes prediction models?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How is label leakage managed in diabetes prediction models?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How is label leakage managed in diabetes prediction models?', [\"So for example, for this prediction task, we're going to exclude patients who have developed type 2 diabetes between 2,009 and 2,011. And we're only going to count as positives patients who get newly diagnosed with type 2 diabetes between 2,011 and 2,013. And one of the reasons why you might want to include a gap in the model is because often there's label leakage. So if you look at the very top setup, often what happens is that a clinician might have a really good idea that the patient might be diabetic, but it's not yet coded in a way which our algorithms can pick up. And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list.\", \"And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list. We're gonna say this patient is someone you should be going after. But that's really not an interesting patient to be going after because the clinicians are probably already doing interventions that are relevant for that patient. Rather, we want to find the patients where the diabetes might be more unexpected. And so this is one of the subtleties that really arises when you try to use retrospective clinical data to derive your labels to use within machine learning for risk stratification. So in the result result I'll tell you about, I'm going to use a 1 year gap. Another problem is that the data is highly censored. So, what I mean by censoring is that we often don't have full visibility into the the the data for patients. For example, patients might have only come into the health insurance in 2013.\", \"And so that, then, would be a sign of obesity. So I talked about how the criteria which we use to evaluate risk stratification models are a little bit different from the criteria used to evaluate diagnosis models. Here, I'll tell you, one of the measures that we often use, and it's called positive predictive value. So what we'll do is we'll look at after you've learned your model, look at the top 100 predictions, top 1,000 predictions, top 10,000 predictions, and look to see what fraction of those patients went on to actually develop type 2 diabetes. And, of course, this is done using held out data. Now the reason why you might be interested in different levels is because you might want to target different interventions depending on on the risk and cost. For example, a very low cost intervention, one of the ones that that we did was sending a text message to patients who have who who are who are suspected to have high risk of developing type 2 diabetes.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What types of data are used in risk stratification for diabetes?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What types of data are used in risk stratification for diabetes?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What types of data are used in risk stratification for diabetes?', [\"And so that, then, would be a sign of obesity. So I talked about how the criteria which we use to evaluate risk stratification models are a little bit different from the criteria used to evaluate diagnosis models. Here, I'll tell you, one of the measures that we often use, and it's called positive predictive value. So what we'll do is we'll look at after you've learned your model, look at the top 100 predictions, top 1,000 predictions, top 10,000 predictions, and look to see what fraction of those patients went on to actually develop type 2 diabetes. And, of course, this is done using held out data. Now the reason why you might be interested in different levels is because you might want to target different interventions depending on on the risk and cost. For example, a very low cost intervention, one of the ones that that we did was sending a text message to patients who have who who are who are suspected to have high risk of developing type 2 diabetes.\", \"Creatinine, potassium, glucose, liver enzymes are all the most popular lab tests. And that's not surprising because often, there is a panel called the CBC panel, which is what you would get in your annual physical. And that has many of these top laboratory test results. But then, as you look down into the tail, there are many other laboratory test results that are more specialized in nature. For example, hemoglobin a 1 c is used to track roughly 3 month average of blood glucose and is used to understand a patient's diabetes status. So that's just to give you a sense of what is the data behind the scenes. Now let's think about how do we really derive how do we tackle how do we formulate this risk stratification problem as a machine learning problem? Well, today, I'll give you one example of how to formulate it as a machine learning problem. But in in Tuesday's lecture, I'll tell you several other ways. Here, we're going to think about a reduction to binary classification. And we're going to ask we're gonna go back in time.\", \"But as I mentioned, these scores haven't had the impact that we had hoped that they might have. And and the reason really is because they haven't been actually used nearly as much as they should be. So what we will be thinking through is can we change the way in which risk stratification is done rather than it having to be something which is manually done when you think to do it, we can make it now population wide. We could, for example, take data that's already available from a health insurance company, use machine learning. Maybe we don't have access to all of those features I showed you earlier. Like, maybe we don't know the patient's weight, but we'll we'll use machine learning on the data that we do have to try to find other surrogates of those things we don't have, which might predict diabetes risk. And then we can apply it automatically behind the scenes for millions of different patients and find the high risk population and perform interventions for those patients. And by the way, the work that I'm telling you about today is work that really came out of my lab's research in the last few years.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Why is L1 regularization used in logistic regression for risk stratification?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Why is L1 regularization used in logistic regression for risk stratification?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'Why is L1 regularization used in logistic regression for risk stratification?', [\"1st, it can help prevent overfitting in settings where there exists a very good risk model that uses a small number of features. And to point out, that's not a crazy idea that there might exist a risk model that uses a small number of features. Right? Because remember, think back to that Apgar score or the FINRISK, which was used to predict diabetes in in Finland. Each of those had only 5 to 20 questions. And based on the answers to those 5 to 20 questions, one could get a pretty good idea of what the risk is of that patient. Right? So the fact that there might be a small number of features that are that are together sufficient is actually a very reasonable prior. And it's one reason why l one regularization is actually very well suited to these types of risk stratification problems on this type of data. The second reason is one of interpretability. If one wants to then ask, well, what are the features that actually were used by this model to make predictions? When you find only 20 or a few hundred features, you can enumerate all of them and look to see what they are, and that way understand what is going on into the predictions that are that are made.\", \"Then, we've excluded that patient from the population, and we might be really biasing the results of the model by now taking away a whole set of the of the population where this model would have been really important to apply. So thinking about how you really do this inclusion exclusion, how that changes the generalizability of the model you get is something that should be at the top of your mind. So the the machine learning algorithm used in in that paper which you've read is l one regularized logistic regression. One of the reasons for using l one regularized logistic regression is because it provides a way to use a high dimensional feature set. But at the same time, it allows one to do feature selection. So I'll go more into detail on that in just a moment. I imagine most of you have sorry. All of you should be familiar with the idea of formulating machine learning as an optimization problem, where you have some loss function and you have some regularization term. W, in this case, is the weights of your linear model, which we're trying to learn.\", \"Well, the solution the optimal solution is going to be, in essence, the closest point along the circle, which gets as close as possible to the middle of that level set. So over here, the closest point is over is that one. And you'll see that this point has a non zero w 1 and w 2. Over here, the closest point is over here. Right? Notice that that has a zero value of w 1 and a non zero value of w 2. Thus, it's found a sparser solution than this one. So this is just to give you some intuition about why using l one regularization results in sparse solutions to your optimization problem. And that can be beneficial for 2 purposes. 1st, it can help prevent overfitting in settings where there exists a very good risk model that uses a small number of features. And to point out, that's not a crazy idea that there might exist a risk model that uses a small number of features.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is MYCIN and why was it never used in practice?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is MYCIN and why was it never used in practice?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What is MYCIN and why was it never used in practice?', [\"And this knowledge base, which was probabilistic in nature because it captured the idea that some symptoms would only occur with some probability for for disease, took over 15 person years to elicit from a large medical team. Right? So it was a lot of effort. And even in, you know, going forward to today's time, there have been few similar efforts at a scale as as as impressive as this one. But, again, what happened? These algorithms are not being used anywhere today in our clinical workflows. And the challenges that have prevented them from being used today are numerous. But, but I used a word in my in my explanation which should really hint at it. I used the word clinical workflow. And this, I think, is one of the biggest challenges, which is that the algorithms were designed to solve narrow problems. They weren't necessarily even the most important problems because clinicians generally do a very good job at diagnosis. And there was a big gap between the input that they expected and the current clinical workflow. So imagine that you have now a mainframe computer.\", \"The computer responds, my understanding is the name of the patient is Joe. Respiratory tract is one of the symptoms the patient had. Then the clinician writes, a couple of days before the admission, he had malaise, which is general tiredness. The computer responds, please give me a date of admission. The clinician responds, March 12, 1979, and the computer again confirms that it's understood appropriately. And this is the preface to the later diagnostic stages. So the ideas of how AI can really impact medicine have been around a long time, yet these algorithms, which have been shown to be very effective, even going back to the 19 seventies, didn't translate into clinical care. A second example, oh, so equally impressive in its nature, was work from the 19 eighties at at in Pittsburgh, developing what's known as the Internist 1 or Quick Medical Reference System. This was now used not for infectious diseases, but for primary care. Here, one might ask, how can we try to do diagnosis at a much larger scale where patients might come in with 1 of 100 of different diseases and could report thousands of different symptoms, each one giving you some view, noisy view, into what might be going on with patients' health.\", \"Moreover, despite the fact that it took a lot of effort to use it when outside of existing clinical workflows, these systems were also really difficult to maintain. So I talked about how this was elicited from 15 person years of work. There was no machine learning here. It was called artificial intelligence because one tries to reason in an artificial way like humans might, But there was no learning from data in this. And so what that means is if you then go to a new place let's say this was developed in Pittsburgh, and now you go to Los Angeles or to Beijing or to to London and you wanna apply the same algorithms, you suddenly have to re derive parts of this model from scratch. For example, the prior probability of the diseases are going to be very different depending on where you are in the world. Now, you might wanna go to a different domain outside of primary care. And, again, one has to spend a huge amount of effort to derive such models. As new medicine as new medicine discoveries are made, one has to again update these models. And this has been a huge blocker to deployment. I'll move forward to one more example now from the 19 also from the 19 eighties.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', [\"And I'll point out a few examples of that in the rest of today's lecture. So all of this coming together, the data availability, the advances in other fields of machine learning, and the huge amount of financial potential financial gain in health care and the potential social impact it could have has not gone unnoticed. And there's a huge amount of industry interest in this field. These are just some examples from, from names I think many of you are familiar with, like DeepMind Health and IBM Watson, to start up companies like Bay Labs and PathAI, which is here in Boston, all of which are really trying to build the next generation of tools for health care now based on machine learning algorithms. There's been quite a 1,000,000,000 of dollars of funding in in the recent quarters towards digital health efforts with hundreds of different start ups that are focused specifically on using artificial intelligence in health care.\", \"They might be 60 neurons, then 7, then 6, for example, in terms of each of the layers of of the of the neural network. By the way, that that sort of makes sense given the type of data that was fed into it. So none of this is new in terms of the goals. So what's changed? Why do I think that despite that the fact that we've had what could arguably be called a failure for the last 30 or 40 years, that we might actually have some chance of succeeding now? And the big differentiator, what I'll call now the opportunity, is data. So whereas in the past, much of the work in artificial intelligence in medicine was not data driven, it was based on trying to elicit as much domain knowledge as one can from clinical domain experts, in some cases, gathering a little bit of data. Today, we have an amazing opportunity because of the prevalence of electronic medical records, both in United States and elsewhere. Now here in the United States, for example, the story wasn't that way even back in 2,008, when the adoption of electronic medical records was under 10% across the US.\", \"The the answer is that it's there's a huge amount of difference, and there are a lot of subtleties to doing machine learning right here. And we'll talk about that throughout the whole entire semester. So to begin, this isn't a new field. Artificial intelligence in medicine goes back to the 19 seventies or sometime even in the sixties. One of the earliest examples of trying to use artificial intelligence for diagnosis was this Mison system developed at Stanford where the goal was try to identify bacteria that might might cause infection and then to try to guide what would be the appropriate therapy for that bacteria. Now it was found that this algorithm, this machine learning, this simple AI algorithm, was able to propose a good therapy in 69% of cases, which at the time was better than the best or very good infectious disease experts.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How can machine learning transform emergency departments?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How can machine learning transform emergency departments?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'How can machine learning transform emergency departments?', [\"In a few lectures, I'll talk to you about techniques from the eighties nineties, which were based on trying to signal processing, trying to detect where are the peaks of this signal, look at the distance between peaks. And more recently, because of the large wealth of data that's available, we've been using convolutional neural network based approaches to try to understand this data and predict from it. Yet another example from the ER really has to do with not how do we care for the patient today, but how do we get better data, which will then result in taking better care of the patient tomorrow. And so one example of that, which which my group deployed at Beth Israel Deaconess, and it's still running there in the emergency department, has to do with getting higher quality chief complaints. The chief complaint is the, it's usually a very short 2 or 3 word quantity, like, left knee pain, rectal pain, right right upper quadrant, RUQ, abdominal pain. And it's just a very quick summary of why did the patient come into the ER today.\", \"Which is, again, an important question when it comes to deploying algorithms here. So I'll I'll run through a couple of very high level examples, driven from from my own work, focused on the provider space, and then I'll bump up to talk a bit more broadly. So for the last 7 or 8 years, I've been doing a lot of work in collaboration with Beth Israel Deaconess Medical Center across the river with their emergency department. And the emergency department is a really interesting clinical setting because you have a very short period of time from when a patient comes into the hospital to diagnose what's going on with them, to initiate therapy, and then to decide what to do next. Do you keep them in the hospital? Do you send them home? If you for each one of those things, what should the most immediate actions be? And at least here in the US, we're always understaffed. So we've got limited resources and very critical decisions to make. So this is one example of a setting where algorithms that are running behind the scenes could potentially really help with some of the challenges I mentioned earlier.\", \"And here's one example where it says, the ED dashboard, the emergency department dashboard, decision support algorithms have determined this patient may be eligible for the atrial cellulitis pathway. Cellulitis is often caused by infections. Please choose from one of the options. Enroll in the pathway, decline. And if you decline, you must include a comment for the reviewers. Now, if you clicked on enroll in the pathway, at that moment, machine learning disappears. Rather, there's a standardized process. It's an algorithm, but it's a deterministic algorithm for how patients with cellulitis should be properly managed, diagnosed, and treated. That algorithm comes from best practices, comes from clinicians coming together, analyzing past data, understanding what would be good ways to treat patients of this type, and then formalizing that in a document. The challenge is that there might be 100 or even 1000 of these best practices.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some challenges unique to machine learning in healthcare?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some challenges unique to machine learning in healthcare?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some challenges unique to machine learning in healthcare?', [\"I'll just stick to your independence. We hope. So what's unique about machine learning health care? I gave you already some hints at this. So first, health care is ultimately, unfortunately, about life or death decisions. Right? So we need robust algorithms that don't screw up. A prime example of this, which I'll tell you a little bit more about, in towards the end of the semester, is, from a major software error that occurred something like, 20, 30 years ago, in a, in an x-ray type device where an overwhelming amount of radiation was exposed to a patient just because of a software overflow problem, a bug. And, of course, that resulted in a number of patients dying. So that was a software error from decades ago where there was no machine learning in the loop.\", \"Now more broadly, this is a young field. So for example, there just recently, just about 3 years ago, was created the first conference on machine learning in health care by that name. And new publication venues are being created every single day by Nature, Landsat, and and also machine learning journals for publishing research on machine learning healthcare. Because of some of the issues we talked about, like access to data and not very good benchmarks, reproducibility has been a major challenge. And this is, again, something that the field is only now starting to really grapple with. And so as part of this course, also many of you are going to be are currently PhD students or will soon be PhD students. We're going to think through what are some of the challenges for the research field. What are some of the open problems that you might wanna work on either during your PhD or during your future career?\", \"Another challenge is about the difficulty in deploying machine learning algorithms due to the challenge of integration. So you build a good algorithm. You wanna deploy it at your favorite hospital. But guess what? That hospital has Epic or Cerner or or Athena or some other commercial electronic medical record system, and that electronic medical record system is not built for your algorithm to plug into. So there's a big gap, big, large amount of difficulty to to getting your algorithms into production systems, which which we'll talk about as well during the semester. So the goals that Pete and I have for you are as follows. We want you to get intuition for working with health care data. And so the next two lectures after today are going to focus on what health care is really like and what is the health care data that's created by the practice of health care like. We want you to get intuition for how to formalize machine learning challenges as health care problems.\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some examples of publicly available healthcare datasets?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some examples of publicly available healthcare datasets?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8692C2750>, 'What are some examples of publicly available healthcare datasets?', [\"And, of course, also medications that are being prescribed as as it goes. And so this is a wealth of data that now one could use to try to study at least study in a very narrow setting of intensive care unit how machine learning could be used in that in that location. And I don't wanna underemphasize the importance of this database, both through this course and to the broader field. This is really the only publicly available electronic medical record dataset of any reasonable size in the whole world. And it was created here at MIT. And we'll be using it extensively in our homework assignments as a result. There are other datasets that aren't publicly available, but which have been gathered by by industry. And one prime example is the Truven MarketScan database, which is which was created by a company called Truven, which was later acquired by IBM, as I'll tell you about more in a few minutes. Now this data, and there are many competing companies that that have similar datasets, is created not from electronic medical records, but rather from typically, it's created from insurance claims.\", \"And fingers crossed, it looks like we'll get access to this database for our homework and projects for this semester. Now there are a lot a lot of other initiatives that are that are creating large datasets. A really important example here in the US is President Obama's Precision Medicine Initiative, which has since been renamed to the All of Us Initiative. And this initiative is creating a dataset of 1,000,000 patients drawn in a representative manner from across the United States to capture patients, both poor and rich, patients who are healthy and have chronic disease, with a goal of trying to create a research database where all of us and other people, both inside and outside the US, could do research to make medical discoveries. And this will include data such as data from a baseline health exam where the typical vitals are taken, blood blood is drawn. It'll combine data of the previous tube types I've mentioned, including both data from electronic medical records and health insurance claims. And then a lot of this work is also happening here in Boston.\", \"And then there's a lot of money that passes behind the scenes between insurers and hospitals to corporate companies such as Truven, which collect that data and then resell it for research purposes. And one of the biggest purchasers of data like this is the pharmaceutical industry. So this data, unfortunately, is not usually publicly available, and that's actually a big problem both in US and elsewhere. It's a big obstacle to research in this field that only people who have 1,000,000 of dollars to pay for it really get access to it. It's something that I'm gonna return to throughout the semester. It's, again, something where I think policy can make a big difference. But luckily, here at MIT, the story is gonna be a bit different. So thanks to the MIT IBM Watson AI Lab. MIT has a close relationship with IBM. And fingers crossed, it looks like we'll get access to this database for our homework and projects for this semester. Now there are a lot a lot of other initiatives that are that are creating large datasets.\"])\n",
      "\n",
      "Evaluating PDF content\n",
      "instrumenting <class '__main__.ContentRetrieverWithFilter'> for base <class '__main__.ContentRetrieverWithFilter'>\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting search\n",
      "instrumenting <class '__main__.ContentRetrieverWithFilter'> for base <class '__main__.ContentRetriever'>\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting search\n",
      "skipping base <class 'object'> because of class\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the primary function of the heart in the circulatory system?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the primary function of the heart in the circulatory system?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the primary function of the heart in the circulatory system?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 10: Application of Machine Learning to Cardiac Imaging Instructors: David Sontag, Peter Szolovits 1 Background This lecture was a guest lecture by Rahul Deo, the lead investigator of the One Brave Idea project at Brigham and Women's Hospital. Rahul is also Adjunct Associate Professor at UC San Francisco and a member of the faculty at Harvard Medical School. He talked about how machine learning techniques are being used and can be used further to augment cardiac imaging. 2 Introduction to Cardiac Structure and Function Before considering the applications of machine learning to cardiology, it's important to understand the field of cardiology a bit better. In particular, why should we care about cardiology in the first place? For one, coronary heart disease, or CHD (the hardening of arteries that transport blood to the heart), is the leading cause of death globally. And this is something that holds true for both developing and developed countries alike. Since cardiology is ultimately about biological diseases like CHD, it's a good idea to get a better understanding of the biology of the heart before moving on to look at how machine learning can disrupt the field. 2.1 Cardiac Function The heart's primary function is to pump oxygenated blood throughout our circulatory system. The continual flow of blood is not only critical to deliver oxygen necessary for ATP (energy) production to all our tissues, but also to transport signaling molecules throughout our body and remove waste from cells. As a result, the volume of blood flow is quite large: the heart pumps 5 liters of blood every minute, a number that can grow to as much as 35 liters per minute during intense exercise. One crucial aspect of cardiac function is that the body must maintain extremely rhythmic beating of the heart, a not inconsequential task given that the average human heart generates a total of more than 2 billion heartbeats over a lifetime. 2.2 Structure of the Heart Figure 1 above gives an overview of the structure of the human heart. Blood comes in through the superior vena cava into a chamber called the right atrium, from where it passes into the right ventricle. The right ventricle pumps blood to the lungs, and the newly oxygenated blood then flows via the pulmonary veins to the left atrium. Finally, the left ventricle pumps blood to the rest of the body via the aorta. Thus, the heart essentially conducts 2 circulations in series: a pulmonary circulation to pump deoxygenated blood to the lungs, and a systemic circulation to pump newly oxygenated blood to the rest of the body. In addition, the heart also has 4 different valves (mitral, tricuspid, aortic, pulmonary) that control flow of blood out of the heart's four chambers. 2.3 The Cardiac Cycle As the heart pumps, it cycles between periods of relaxation called diastole, in which the heart is filled with blood, and periods of contraction called systole, in which the heart pumps out blood. This regular mechanical motion is coordinated by synchronized electrical activity, which can be visualized in an electrocardiogram (EKG). A Wiggers Diagram can be used to demonstrate the interconnectedness of these electrical and 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 1\", \"Courtesy of OpenStax. Used under CC BY. Aorta Superior vena cava Left pulmonary artery Right pulmonary artery Left atrium Pulmonary trunk Left pulmonary veins Right pulmonary veins Mitral (bicuspid) valve Right atrium Aortic valve Fossa ovalis Tricuspid valve Pulmonary valve Right ventricle Left ventricle Chordae tendineae Papillary muscle Trabeculae carneae Interventricular septum Epicardium Moderator band Myocardium Inferior vena cava Endocardium Anterior view Figure 1: The major chambers, valves, and blood vessels of the human heart. mechanical systems, allowing one to see how events in an EKG align with the physical state of the heart, as shown in Figure 2. 2.4 Cardiac Diseases Given the complex structure of the heart, cardiac diseases are organized based on abnormalities or failures in the following different functions (with example diseases in parentheses): Contractile Function (heart failure) Coronary Blood Supply (coronary artery disease, myocardial infarction) Circulatory Flow (aortic or mitral stenosis/regurgitation) Heart Rhythm (atrial fibrillation, ventricular tachycardia) 2.5 Wrapup of Cardiac Biology So far, our discussion of the heart has focused on examining it as a muscular organ responsible for pumping blood. However, there is a ton of biology here apart from pumping - in fact, only 31% of of cardiac cells are cardiomyocytes, the muscle cells responsible for the heart's contractions. As a result, cardiac function (and, as a result, cardiac disease) comes from the interaction of a very diverse and large group of cells, ranging from endothelial cells, fibroblasts, leukocytes, and more. 3 Major Types of Cardiac Diagnostics and How They are Used Cardiology is by its nature extremely imaging-centric, making it an expensive field of medical study. There exist a large variety of various imaging techniques that each play critical roles in diagnosis. Here is a brief overview of some of the most important ones: EKG - An extremely cheap technique based on measuring voltage differences in the heart over time. Can be used, for example, to diagnose myocardial infarction. 6.S897/HST.956 Machine Learning for Healthcare - Lec10\", 'Time Risk factors Hemming and deviate from hawing regarding Death optimal values lifestyle changes and disability blood pressure LDL/VLDL cholesterol Treatment may be weight (grudgingly) blood sugar initiated Symptoms develop anti-hypertensives cholesterol-lowering dyspnea Therapeutic anti-diabetics angina Responsiveness $$$ Figure 4: A rough timeline on patients with cardiovascular disease. (a) Expressive - captures complex underlying processes (molecular, cellular, imaging ...) (b) Multidimensional - Can\\'t readily be \"gamed\" 3. Pipeline should be ameliorated with therapy (c.f. genetic risk) The role for the fully automated pipeline for echocardiogram interpretation would be at the \"low risk - high reward\" portion of the current spectrum. See Figure 5 6.3 Focus of machine learning in cardiac diseases We can use machine learning to: 1. enable much greater of volumes of data to be interpreted, SO that we reduce costs of acquisition and interpretation, as well as augment interpretations of simple data. 2. augment surveillance within a hospital system, e.g. patient identification for therapies 3. perform triage, i.e. automating ECG interpretation in urgent situations in the ambulance/ER To illustrate the need of machine learning to perform rapid triage, we provide an example. In the early 2000\\'s, it was recognized that any delay in angioplasty and stenting would result in irreversible damage to the heart. Thus, the solution was to replace a cardiologist reviewing the ECG with a rapid triage system by ambulance personnel or ED physicians for quicker turnover. However, this resulted in an increase in false positives. Thus, there is still a need for a fast pipeline that has high quality. 6.4 Zhang, Deo, et al. approach to Automated Approach for Echo interpreta- tion An echo study is typically a collection of up to 70 videos of the heart taken over multiple cardiac cycles and focusing on different viewpoints. The heart is visualized from ¿10 different views, and still images are typi- cally included to enable manual measurements. ¿7,000,000 echo studies are performed annually in Medicare population alone, and there are likely (an estimate by Deo) of about 100,000,000\\'s of archived echo studies. Zhang et al. built a pipeline using 14k raw echo studies and traditional computer vision algorithms for view classification and segmentation into 5 views to perform cardiac structural and functional analysis. This is an automated and low cost approach to echo interpretation. See Figure 6. 6.S897/HST.956 Machine Learning for Healthcare - Lec10 7'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the two circulations the heart conducts in series?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the two circulations the heart conducts in series?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the two circulations the heart conducts in series?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 10: Application of Machine Learning to Cardiac Imaging Instructors: David Sontag, Peter Szolovits 1 Background This lecture was a guest lecture by Rahul Deo, the lead investigator of the One Brave Idea project at Brigham and Women's Hospital. Rahul is also Adjunct Associate Professor at UC San Francisco and a member of the faculty at Harvard Medical School. He talked about how machine learning techniques are being used and can be used further to augment cardiac imaging. 2 Introduction to Cardiac Structure and Function Before considering the applications of machine learning to cardiology, it's important to understand the field of cardiology a bit better. In particular, why should we care about cardiology in the first place? For one, coronary heart disease, or CHD (the hardening of arteries that transport blood to the heart), is the leading cause of death globally. And this is something that holds true for both developing and developed countries alike. Since cardiology is ultimately about biological diseases like CHD, it's a good idea to get a better understanding of the biology of the heart before moving on to look at how machine learning can disrupt the field. 2.1 Cardiac Function The heart's primary function is to pump oxygenated blood throughout our circulatory system. The continual flow of blood is not only critical to deliver oxygen necessary for ATP (energy) production to all our tissues, but also to transport signaling molecules throughout our body and remove waste from cells. As a result, the volume of blood flow is quite large: the heart pumps 5 liters of blood every minute, a number that can grow to as much as 35 liters per minute during intense exercise. One crucial aspect of cardiac function is that the body must maintain extremely rhythmic beating of the heart, a not inconsequential task given that the average human heart generates a total of more than 2 billion heartbeats over a lifetime. 2.2 Structure of the Heart Figure 1 above gives an overview of the structure of the human heart. Blood comes in through the superior vena cava into a chamber called the right atrium, from where it passes into the right ventricle. The right ventricle pumps blood to the lungs, and the newly oxygenated blood then flows via the pulmonary veins to the left atrium. Finally, the left ventricle pumps blood to the rest of the body via the aorta. Thus, the heart essentially conducts 2 circulations in series: a pulmonary circulation to pump deoxygenated blood to the lungs, and a systemic circulation to pump newly oxygenated blood to the rest of the body. In addition, the heart also has 4 different valves (mitral, tricuspid, aortic, pulmonary) that control flow of blood out of the heart's four chambers. 2.3 The Cardiac Cycle As the heart pumps, it cycles between periods of relaxation called diastole, in which the heart is filled with blood, and periods of contraction called systole, in which the heart pumps out blood. This regular mechanical motion is coordinated by synchronized electrical activity, which can be visualized in an electrocardiogram (EKG). A Wiggers Diagram can be used to demonstrate the interconnectedness of these electrical and 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 1\", \"Courtesy of OpenStax. Used under CC BY. Aorta Superior vena cava Left pulmonary artery Right pulmonary artery Left atrium Pulmonary trunk Left pulmonary veins Right pulmonary veins Mitral (bicuspid) valve Right atrium Aortic valve Fossa ovalis Tricuspid valve Pulmonary valve Right ventricle Left ventricle Chordae tendineae Papillary muscle Trabeculae carneae Interventricular septum Epicardium Moderator band Myocardium Inferior vena cava Endocardium Anterior view Figure 1: The major chambers, valves, and blood vessels of the human heart. mechanical systems, allowing one to see how events in an EKG align with the physical state of the heart, as shown in Figure 2. 2.4 Cardiac Diseases Given the complex structure of the heart, cardiac diseases are organized based on abnormalities or failures in the following different functions (with example diseases in parentheses): Contractile Function (heart failure) Coronary Blood Supply (coronary artery disease, myocardial infarction) Circulatory Flow (aortic or mitral stenosis/regurgitation) Heart Rhythm (atrial fibrillation, ventricular tachycardia) 2.5 Wrapup of Cardiac Biology So far, our discussion of the heart has focused on examining it as a muscular organ responsible for pumping blood. However, there is a ton of biology here apart from pumping - in fact, only 31% of of cardiac cells are cardiomyocytes, the muscle cells responsible for the heart's contractions. As a result, cardiac function (and, as a result, cardiac disease) comes from the interaction of a very diverse and large group of cells, ranging from endothelial cells, fibroblasts, leukocytes, and more. 3 Major Types of Cardiac Diagnostics and How They are Used Cardiology is by its nature extremely imaging-centric, making it an expensive field of medical study. There exist a large variety of various imaging techniques that each play critical roles in diagnosis. Here is a brief overview of some of the most important ones: EKG - An extremely cheap technique based on measuring voltage differences in the heart over time. Can be used, for example, to diagnose myocardial infarction. 6.S897/HST.956 Machine Learning for Healthcare - Lec10\", '© Julian Andrés Betancur Acevedo. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Electrocardiogram Phonocardiogram 1st 2nd 120 Aortic valve Aortic pressure LV pressure LA pressure 80 Aortic valve closes Pressure (mmHg) 40 valve AV valve closes opens 0 130 Ventricular volume (mL) 100 70 Atrio-ventricular valves Open Close Open Aortic and pulmonary valves Close Open Close Phase 2a 2b Left atrium Right atrium Left ventricle Right ventricle Ventricular filling Contraction of atria Isovolumetric Ventricular Isovolumetric Ventricular filling contraction ejection relaxation Ventricular filling Ventricular systole Protodiestole (mid-diastole to end-diastole) (atria in diastole) Figure 2: An example of a Wiggers Diagram. Echocardiography - A more expensive technique that uses ultrasound tech to make measurements. Can be used to get general understanding of cardiac structure and thus diagnose, for example, heart failure, valvular disease, and pulmonary hypertension. MRI - One of the most expensive imaging techniques. More expensive than echocardiography but achieves very similar diagnostic functions, SO it is not used all that much in the US. SPECT/PET - Non-invasive techniques, but also extremely expensive. Can be used, for example, to infer coronary artery disease or diagnose microvascular disease. One interesting characteristic of cardiac diagnostics is that diseases are not defined based on biology, but rather based on measurements that depart from \"normal\" anatomic or phsiological values. This may be due to the limitations in our ability to study or image the human heart, but it\\'s not clear whether this is ultimately for the better or worse. In cardiology, clinical decisions regarding treatments for diagnosed diseases are often, but not always, guided in part by inputs from cardiac imaging. Ultimately, a few different factors affect the role of imaging in cardiology. First, although imaging can lead to data with extremely high information content, decisions regarding treatment are affected in large part by historical studies that follow patients with the disease of interest over long time periods. Secondly, cardiologists are often stuck with the data that is already out there because someone decided it was worth paying for. The available data often controls the risk model and decision analysis you can undertake. Finally, while imaging data can be found for patients with diseases for which the imaging process is seen as an essential part of the commonly accepted management plan, it is much more difficult to obtain imaging data for other diseases or patient populations given the high cost. As a result, doctors are often stuck with the stuff that they already know something about. 6.S897/HST.956 Machine Learning for Healthcare - Lec10'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', ['© Julian Andrés Betancur Acevedo. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Electrocardiogram Phonocardiogram 1st 2nd 120 Aortic valve Aortic pressure LV pressure LA pressure 80 Aortic valve closes Pressure (mmHg) 40 valve AV valve closes opens 0 130 Ventricular volume (mL) 100 70 Atrio-ventricular valves Open Close Open Aortic and pulmonary valves Close Open Close Phase 2a 2b Left atrium Right atrium Left ventricle Right ventricle Ventricular filling Contraction of atria Isovolumetric Ventricular Isovolumetric Ventricular filling contraction ejection relaxation Ventricular filling Ventricular systole Protodiestole (mid-diastole to end-diastole) (atria in diastole) Figure 2: An example of a Wiggers Diagram. Echocardiography - A more expensive technique that uses ultrasound tech to make measurements. Can be used to get general understanding of cardiac structure and thus diagnose, for example, heart failure, valvular disease, and pulmonary hypertension. MRI - One of the most expensive imaging techniques. More expensive than echocardiography but achieves very similar diagnostic functions, SO it is not used all that much in the US. SPECT/PET - Non-invasive techniques, but also extremely expensive. Can be used, for example, to infer coronary artery disease or diagnose microvascular disease. One interesting characteristic of cardiac diagnostics is that diseases are not defined based on biology, but rather based on measurements that depart from \"normal\" anatomic or phsiological values. This may be due to the limitations in our ability to study or image the human heart, but it\\'s not clear whether this is ultimately for the better or worse. In cardiology, clinical decisions regarding treatments for diagnosed diseases are often, but not always, guided in part by inputs from cardiac imaging. Ultimately, a few different factors affect the role of imaging in cardiology. First, although imaging can lead to data with extremely high information content, decisions regarding treatment are affected in large part by historical studies that follow patients with the disease of interest over long time periods. Secondly, cardiologists are often stuck with the data that is already out there because someone decided it was worth paying for. The available data often controls the risk model and decision analysis you can undertake. Finally, while imaging data can be found for patients with diseases for which the imaging process is seen as an essential part of the commonly accepted management plan, it is much more difficult to obtain imaging data for other diseases or patient populations given the high cost. As a result, doctors are often stuck with the stuff that they already know something about. 6.S897/HST.956 Machine Learning for Healthcare - Lec10', \"Courtesy of OpenStax. Used under CC BY. Aorta Superior vena cava Left pulmonary artery Right pulmonary artery Left atrium Pulmonary trunk Left pulmonary veins Right pulmonary veins Mitral (bicuspid) valve Right atrium Aortic valve Fossa ovalis Tricuspid valve Pulmonary valve Right ventricle Left ventricle Chordae tendineae Papillary muscle Trabeculae carneae Interventricular septum Epicardium Moderator band Myocardium Inferior vena cava Endocardium Anterior view Figure 1: The major chambers, valves, and blood vessels of the human heart. mechanical systems, allowing one to see how events in an EKG align with the physical state of the heart, as shown in Figure 2. 2.4 Cardiac Diseases Given the complex structure of the heart, cardiac diseases are organized based on abnormalities or failures in the following different functions (with example diseases in parentheses): Contractile Function (heart failure) Coronary Blood Supply (coronary artery disease, myocardial infarction) Circulatory Flow (aortic or mitral stenosis/regurgitation) Heart Rhythm (atrial fibrillation, ventricular tachycardia) 2.5 Wrapup of Cardiac Biology So far, our discussion of the heart has focused on examining it as a muscular organ responsible for pumping blood. However, there is a ton of biology here apart from pumping - in fact, only 31% of of cardiac cells are cardiomyocytes, the muscle cells responsible for the heart's contractions. As a result, cardiac function (and, as a result, cardiac disease) comes from the interaction of a very diverse and large group of cells, ranging from endothelial cells, fibroblasts, leukocytes, and more. 3 Major Types of Cardiac Diagnostics and How They are Used Cardiology is by its nature extremely imaging-centric, making it an expensive field of medical study. There exist a large variety of various imaging techniques that each play critical roles in diagnosis. Here is a brief overview of some of the most important ones: EKG - An extremely cheap technique based on measuring voltage differences in the heart over time. Can be used, for example, to diagnose myocardial infarction. 6.S897/HST.956 Machine Learning for Healthcare - Lec10\", \"Non-skilled acquisition Skilled sonographer (primary care) Low cost handheld ultrasound Costly full ultrasound system Automated interpretation Expert cardiologist interpretation Early in disease course Late in disease course Decision support regarding initiation Difficult decisions regarding or intensification of therapy surgery Low liability $ High liability $$$ Figure 5: The left side shows the benefits of having an automated pipeline for echocardiogram interpretation in contrast to the right side without it. We see that both niches fulfill high reward, but the left is low risk and the right is high risk. For early stages, it would be beneficial to use the automated pipeline for low liability, low cost, and quick decisions for whether further analysis is needed. For late stages, it would be better to use a more trusted skilled sonographer, more expensive ultrasound equipment, and an expert interpretation. 6.5 Purpose of automated disease detection Several rare diseases (e.g. mitral valve prolapse) would benefit from referral to cardiologist or specialty centers Diagnoses tend to be missed at centers that see them infrequently (e.g. cardiac amyloidosis) Automated disease detection provides another pillar of support for definitive diagnoses 7 Rethinking the future of automated interpretation: lessons Deo's predictions for the future of cardiac imaging: 1. Routine measurements will be made in an automated way 2. Some automated diagnoses may happen at point-of-care, e.g. heart function and fluid accumulation around heart 3. Until image data acquisition is facilitated, the benefits of automated interpretation will be muted 4. Pharmaceutical companies have high motivation to perform high frequency serial imaging to assess whether there are any benefits to medications in clinical trials, and an accurate scalable quantification will be needed for this. 5. Surveillance of daily studies may be useful to enable identification of individuals who may be eligible for clincal trials or newly approved therapies. Deo's uncertainties on automated interpretation: 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 8\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What challenge does cardiac motion pose to high-quality imaging scans?', [\"4 Where's the Data? 4.1 How is Medical Imaging Data Stored DICOM is the major international standard for storing imaging information. Image/video files are stored in a compressed DICOM format, which includes a header that contains info or characteristics about the image. Several free, open access libraries or software exist for compressing/uncompressing DICOM files, viewing the corresponding images, and reading or editing the header. Most imaging data data can be found stored in data archives. 4.2 Gaining Access to Data Ultimately, access to imaging data can be quite limited due to the following reasons: Some images have burned in pixels with patient PII Vendors don't necessarily make it easy for users to download or de-identificate data, perhaps due to their motivation to make it difficult for users to switch vendors Some systems have monetized the data access pipelines, making it almost prohibitively expensive to access imaging data Another obstacle is that labels (like physiological measurements or diagnoses) are, in many cases, stored separately in electronic health record data, forcing researchers to look for data across multiple sources. One clear trend related to imaging data is that, as the cost of the study increases and/or the perceived utility of the data decreases, the availability of data goes down. As an example, an imaging technique like PET that is very expensive has only 8000 studies available at Brigham and Women's Hospital, whereas over 30 million EKGs can be accessed. 4.3 Characteristics of Medical Imaging Data One of the major issues with obtaining high quality cardiac images is that, as the patient breathes, the chest wall and the heart are both continuously moving. Thus, high quality scans need to get enough temporal frequency on their data acquisition SO that the movement of the heart doesn't affect the imaging. Another solution to image corruption resulting from cardiac motion can be found in the technique known as gating, in which the cardiologist lines up corresponding portions of different heartbeats from EKG data with images, allowing him or her to average the images to obtain a lower noise measurement. A summary of the characteristics of various cardiac imaging techniques can be found in Figure 3. 5 Computer Vision Topics Relevant to Cardiac Imaging The major question to ask when trying to apply machine learning techniques to cardiology is: what physician practices can we mimic? Currently, all cardiac measurements, ranging from computing volumes of cardiac chambers to measuring ventricular thickness, are performed manually by hand. Moreover, some disease diagnoses require cardiologists manually classifying images or videos. Fortunately, many current priorities in CV are of great interest to cardiac imaging as a result. 5.1 Image Classification In image classification, the goal is to assign a label to a given image or video. This is a ripe candidate for applying supervised machine learning techniques to cardiology. There are many simple disease recognition tasks in medicine such as identifying lung cancer, pneumonia, or breast cancer, although physicians are 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 4\", '© Julian Andrés Betancur Acevedo. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Electrocardiogram Phonocardiogram 1st 2nd 120 Aortic valve Aortic pressure LV pressure LA pressure 80 Aortic valve closes Pressure (mmHg) 40 valve AV valve closes opens 0 130 Ventricular volume (mL) 100 70 Atrio-ventricular valves Open Close Open Aortic and pulmonary valves Close Open Close Phase 2a 2b Left atrium Right atrium Left ventricle Right ventricle Ventricular filling Contraction of atria Isovolumetric Ventricular Isovolumetric Ventricular filling contraction ejection relaxation Ventricular filling Ventricular systole Protodiestole (mid-diastole to end-diastole) (atria in diastole) Figure 2: An example of a Wiggers Diagram. Echocardiography - A more expensive technique that uses ultrasound tech to make measurements. Can be used to get general understanding of cardiac structure and thus diagnose, for example, heart failure, valvular disease, and pulmonary hypertension. MRI - One of the most expensive imaging techniques. More expensive than echocardiography but achieves very similar diagnostic functions, SO it is not used all that much in the US. SPECT/PET - Non-invasive techniques, but also extremely expensive. Can be used, for example, to infer coronary artery disease or diagnose microvascular disease. One interesting characteristic of cardiac diagnostics is that diseases are not defined based on biology, but rather based on measurements that depart from \"normal\" anatomic or phsiological values. This may be due to the limitations in our ability to study or image the human heart, but it\\'s not clear whether this is ultimately for the better or worse. In cardiology, clinical decisions regarding treatments for diagnosed diseases are often, but not always, guided in part by inputs from cardiac imaging. Ultimately, a few different factors affect the role of imaging in cardiology. First, although imaging can lead to data with extremely high information content, decisions regarding treatment are affected in large part by historical studies that follow patients with the disease of interest over long time periods. Secondly, cardiologists are often stuck with the data that is already out there because someone decided it was worth paying for. The available data often controls the risk model and decision analysis you can undertake. Finally, while imaging data can be found for patients with diseases for which the imaging process is seen as an essential part of the commonly accepted management plan, it is much more difficult to obtain imaging data for other diseases or patient populations given the high cost. As a result, doctors are often stuck with the stuff that they already know something about. 6.S897/HST.956 Machine Learning for Healthcare - Lec10', \"Echo Studies (14035) View Classification View Probability (277) Quality Score Segmentation Disease Detection: for 5 views HCM (495/2244) (791*) PAH (584/2487) Amyloid (179/804) Cardiac Structure: Cardiac Function: Mass and Volume Ejection Fraction (8666) (6407) Longitudinal Strain (526) Figure 6: Zhang, Deo, et al.'s [TZDD18] approach to an automated pipeline for echocardiogram interpre- tation. 1. We should be using automated interpretation to elevate medicine beyond the current practice, but we need larger dataset and more images than what we currently have. 2. Disease classifications are currently crude and finer distinctions can be made between disease states. 3. Survival models are crude and better predictive models should be possible with imaging data and emerging algorithms. 4. Physicians are only interested in classifications or risk models that will change and improve practice, thus evidence is required to justify a shift. 5. There is the question of how more data will be obtained and dispersed for research. 8 Biology There are some goals in biology that can be accomplished to facilitate cardiac machine learning. First, clinical datasets lack the scale and expressivity needed to reflect underlying biological processes. We need a data type that has the dimensionality to capture biological heterogeneity and complexity and yet can still be collected in a very scaleable manner. It is likely that we shouldn't look at expensive sequencing technolo- gies and costly medical imaging to accomplish this. Accomplishing this would help expand the biological phenotypic space. Another thing is that we should focus on studying individual circulating blood cells. Circulating blood cells are causally implicated in coronary heart disease (CHD) pathogensis. These blood cells are also easily 6.S897/HST.956 Machine Learning for Healthcare - Lec10\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 'cardiac_imaging')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 'cardiac_imaging')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is a significant benefit of applying machine learning to cardiac imaging?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 10: Application of Machine Learning to Cardiac Imaging Instructors: David Sontag, Peter Szolovits 1 Background This lecture was a guest lecture by Rahul Deo, the lead investigator of the One Brave Idea project at Brigham and Women's Hospital. Rahul is also Adjunct Associate Professor at UC San Francisco and a member of the faculty at Harvard Medical School. He talked about how machine learning techniques are being used and can be used further to augment cardiac imaging. 2 Introduction to Cardiac Structure and Function Before considering the applications of machine learning to cardiology, it's important to understand the field of cardiology a bit better. In particular, why should we care about cardiology in the first place? For one, coronary heart disease, or CHD (the hardening of arteries that transport blood to the heart), is the leading cause of death globally. And this is something that holds true for both developing and developed countries alike. Since cardiology is ultimately about biological diseases like CHD, it's a good idea to get a better understanding of the biology of the heart before moving on to look at how machine learning can disrupt the field. 2.1 Cardiac Function The heart's primary function is to pump oxygenated blood throughout our circulatory system. The continual flow of blood is not only critical to deliver oxygen necessary for ATP (energy) production to all our tissues, but also to transport signaling molecules throughout our body and remove waste from cells. As a result, the volume of blood flow is quite large: the heart pumps 5 liters of blood every minute, a number that can grow to as much as 35 liters per minute during intense exercise. One crucial aspect of cardiac function is that the body must maintain extremely rhythmic beating of the heart, a not inconsequential task given that the average human heart generates a total of more than 2 billion heartbeats over a lifetime. 2.2 Structure of the Heart Figure 1 above gives an overview of the structure of the human heart. Blood comes in through the superior vena cava into a chamber called the right atrium, from where it passes into the right ventricle. The right ventricle pumps blood to the lungs, and the newly oxygenated blood then flows via the pulmonary veins to the left atrium. Finally, the left ventricle pumps blood to the rest of the body via the aorta. Thus, the heart essentially conducts 2 circulations in series: a pulmonary circulation to pump deoxygenated blood to the lungs, and a systemic circulation to pump newly oxygenated blood to the rest of the body. In addition, the heart also has 4 different valves (mitral, tricuspid, aortic, pulmonary) that control flow of blood out of the heart's four chambers. 2.3 The Cardiac Cycle As the heart pumps, it cycles between periods of relaxation called diastole, in which the heart is filled with blood, and periods of contraction called systole, in which the heart pumps out blood. This regular mechanical motion is coordinated by synchronized electrical activity, which can be visualized in an electrocardiogram (EKG). A Wiggers Diagram can be used to demonstrate the interconnectedness of these electrical and 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 1\", 'Time Risk factors Hemming and deviate from hawing regarding Death optimal values lifestyle changes and disability blood pressure LDL/VLDL cholesterol Treatment may be weight (grudgingly) blood sugar initiated Symptoms develop anti-hypertensives cholesterol-lowering dyspnea Therapeutic anti-diabetics angina Responsiveness $$$ Figure 4: A rough timeline on patients with cardiovascular disease. (a) Expressive - captures complex underlying processes (molecular, cellular, imaging ...) (b) Multidimensional - Can\\'t readily be \"gamed\" 3. Pipeline should be ameliorated with therapy (c.f. genetic risk) The role for the fully automated pipeline for echocardiogram interpretation would be at the \"low risk - high reward\" portion of the current spectrum. See Figure 5 6.3 Focus of machine learning in cardiac diseases We can use machine learning to: 1. enable much greater of volumes of data to be interpreted, SO that we reduce costs of acquisition and interpretation, as well as augment interpretations of simple data. 2. augment surveillance within a hospital system, e.g. patient identification for therapies 3. perform triage, i.e. automating ECG interpretation in urgent situations in the ambulance/ER To illustrate the need of machine learning to perform rapid triage, we provide an example. In the early 2000\\'s, it was recognized that any delay in angioplasty and stenting would result in irreversible damage to the heart. Thus, the solution was to replace a cardiologist reviewing the ECG with a rapid triage system by ambulance personnel or ED physicians for quicker turnover. However, this resulted in an increase in false positives. Thus, there is still a need for a fast pipeline that has high quality. 6.4 Zhang, Deo, et al. approach to Automated Approach for Echo interpreta- tion An echo study is typically a collection of up to 70 videos of the heart taken over multiple cardiac cycles and focusing on different viewpoints. The heart is visualized from ¿10 different views, and still images are typi- cally included to enable manual measurements. ¿7,000,000 echo studies are performed annually in Medicare population alone, and there are likely (an estimate by Deo) of about 100,000,000\\'s of archived echo studies. Zhang et al. built a pipeline using 14k raw echo studies and traditional computer vision algorithms for view classification and segmentation into 5 views to perform cardiac structural and functional analysis. This is an automated and low cost approach to echo interpretation. See Figure 6. 6.S897/HST.956 Machine Learning for Healthcare - Lec10 7', \"4 Where's the Data? 4.1 How is Medical Imaging Data Stored DICOM is the major international standard for storing imaging information. Image/video files are stored in a compressed DICOM format, which includes a header that contains info or characteristics about the image. Several free, open access libraries or software exist for compressing/uncompressing DICOM files, viewing the corresponding images, and reading or editing the header. Most imaging data data can be found stored in data archives. 4.2 Gaining Access to Data Ultimately, access to imaging data can be quite limited due to the following reasons: Some images have burned in pixels with patient PII Vendors don't necessarily make it easy for users to download or de-identificate data, perhaps due to their motivation to make it difficult for users to switch vendors Some systems have monetized the data access pipelines, making it almost prohibitively expensive to access imaging data Another obstacle is that labels (like physiological measurements or diagnoses) are, in many cases, stored separately in electronic health record data, forcing researchers to look for data across multiple sources. One clear trend related to imaging data is that, as the cost of the study increases and/or the perceived utility of the data decreases, the availability of data goes down. As an example, an imaging technique like PET that is very expensive has only 8000 studies available at Brigham and Women's Hospital, whereas over 30 million EKGs can be accessed. 4.3 Characteristics of Medical Imaging Data One of the major issues with obtaining high quality cardiac images is that, as the patient breathes, the chest wall and the heart are both continuously moving. Thus, high quality scans need to get enough temporal frequency on their data acquisition SO that the movement of the heart doesn't affect the imaging. Another solution to image corruption resulting from cardiac motion can be found in the technique known as gating, in which the cardiologist lines up corresponding portions of different heartbeats from EKG data with images, allowing him or her to average the images to obtain a lower noise measurement. A summary of the characteristics of various cardiac imaging techniques can be found in Figure 3. 5 Computer Vision Topics Relevant to Cardiac Imaging The major question to ask when trying to apply machine learning techniques to cardiology is: what physician practices can we mimic? Currently, all cardiac measurements, ranging from computing volumes of cardiac chambers to measuring ventricular thickness, are performed manually by hand. Moreover, some disease diagnoses require cardiologists manually classifying images or videos. Fortunately, many current priorities in CV are of great interest to cardiac imaging as a result. 5.1 Image Classification In image classification, the goal is to assign a label to a given image or video. This is a ripe candidate for applying supervised machine learning techniques to cardiology. There are many simple disease recognition tasks in medicine such as identifying lung cancer, pneumonia, or breast cancer, although physicians are 6.S897/HST.956 Machine Learning for Healthcare - Lec10 - 4\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', ['6.S897/HST.956 Machine Learning for Healthcare Lecture 13: Machine Learning for Mammography Instructors: David Sontag, Peter Szolovits 1 Breast Image Interpretation: Background and Challenges Breast cancer affects over 2 million women of the 3.8 billion women globally, and is estimated to contribute to over 40,000 U.S. deaths and 600,000 worldwide deaths annually. The primary method for breast cancer diagnosis is the interpretation of mammography images, which are breast X-ray images. Mammograms are normally acquired from two different angles: craniocaudal (CC, which is a 2D projection of the axial view), and mediolateral oblique (MLO, which is a 2D projection of the frontal coronal view). Ideally, we would like to use these images for early detection of breast cancer, which would allow for more effective treatments and potential cures. It is particularly important to detect cancerous tissue before the non- metatstatic to metastatic transition, after which a cure is no longer feasible. The two primary challenges with mammographic analysis for this purpose are: Accurate risk assessment tools Effective screening tests Specifically, the three main problems that need to be addressed to resolve these challenges are: No risk assessment models are able to predict individual risk accurately There is significant variability in human interpretation of mammograms Widespread standardization and application of mammography are limited by the dearth of specialial- ists. 1.1 Mammogram interpretation The two questions that radiologists ask when analyzing a mammogram are: How dense is the breast tissue? Is it a normal or abnormal mammogram? In a mammogram (an example of which is given in Figure 1, the white pixels represent the breast tissue and black pixels represent fatty tissue inside the breasts; thus, breasts with higher densities of white pixels have higher breast density. The current standard medical practice is for radiologists to bin the tissue density into four categories: fatty (low density), scattered, heterogeneously dense, and dense. However, since cancerous tumors are also small blobs of white pixels, dense breast tissue can sometimes obscure or make it more difficult to detect anomalous cancerous tissues. The difficulty of finding small cancerous tissue in mammograms is illustrated by the case studies in Figure 2. Because of the 2D nature of traditional mammograms, patients with higher breast densities tend to receive more false negative mammograms, in which cancerous tissue is mistakenly diagnosed as healthy. This is shown in Figure 3, in which a 3D reconstruction of the breast tissue acquired using tomosynthesis (in which optical slices in the axial dimension are taken for 3D tomography) shows that cancerous tissue was missed in the 2D projection due to breast density. Although false negatives are the least frequent type of mammogram, it is particularly devastating because of the consequences it entails for the affected patient, who does not receive the appropriate treatment or care. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 1', \"2.1.2 Challenges of applying DL to mammogram triaging While many aspects of the task of cancer detection based on mammograms are similar to that of natural image classification (ImageNet), there are some key differences that make this task tricky. First of all, the signal-to-noise-ratio (SNR) is much lower in mammograms compared to natural images. In other words, the cancerous tissue and region that is relevant for image classification is much smaller (tends to be around 1% of the image, exemplified in Figure 2) than the size of the relevant object(s) in natural images. The images in mammogram datasets are also much larger than natural images. For instance, mammograms tend to be on the order of 3000 by 2600 pixels, whereas ImageNet images tend to be orders of magnitude smaller. This leads to issues with memory and parallelization - in particular, the batch size is limited, which makes the stochastic gradient updates much noisier, and can impede model learning. Large individual images also just presents memory and storage issues in general; for example, the data set for this particular project was over 12 TB. Image size and low SNR ratio both lead to a separate challenge: if patches are used, this can lead to removal of important context, which can make it difficult to differentiate between cancerous and non-cancerous tissues. Lastly, if patch-based data is used, there is a heavy class imbalance, in that only around 0.7% of the inputs are positive, while the vast majority are negatives. While there are methods for resolving this being actively researched and implemented in the machine learning community, it is still a non-trivial challenge. 2.1.3 Building the model In building the DL model, the first thign considered was initialization of the model. Adam Yala and colleagues decided to use ImageNet pre-trained CNN models (e.g. VGG, ResNet, Wide-ResNet, DenseNet) to initialize the network, and then to mitigate the small batch size issue (talked about in section 2.1.2) that is a result of the large size of the images, they performed several forward and backpropagation steps through the network before updating the weights via gradient descent. In essence, this allows them to use a larger batch size than GPU memory allows, but doing it in series rather than in parallel. For this, they utilized a batch size of 24 (by taking 2 full steps with batch size 3 distributed over 4 GPU's). They found that initializing with ImageNet allowed for learning to occur much quicker (demonstrated in Figure 5) than when initializing the model randomly. One possible explanation for this is that the batch normalization statistics are more stable to begin with when using pre-trained weights from ImageNet. ImageNet-Init Random-Init 10 7.5 Train Loss 5 2.5 0 0 5 10 15 20 25 Figure 5: Loss VS. Epoch with ImageNet initialization and random initialization. ImageNet initialization allows for learning to occur quicker. In selecting a base architecture of the model, they preferred models that were fully convolutional to allow for flexibility in feeding in inputs of varying resolutions; thus, the ResNet-18 model was chosen. This was 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 5\", \"[Image removed due to copyright restrictions.] Figure 1: Mediolateral oblique (MLO) view of a breast mammography with relevant components labeled. [And12] Prior Current Prior Current Figure 2: Two examples of time-evolving mammograms with developing cancerous tissue, indicated by the red circles. The cancerous tissue is small and blends in with the rest of the breast tissue. © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ 1.2 Risk assessment For early detection of breast cancer, it's important for accurate risk assessment tools to be available to interpret mammograms. With more accurate risk forecasting, more action can be taken prior to lymph node localization or metastasis. While false negatives (as described in Section 1.1) are particularly harmful to individuals, false positive mammograms can also have deleterious effects on patients. The side effects of chemotherapy or radiation therapy can be particularly damaging to a patient, especially if they are a false positive. Thus, the preferred method of investigating perceived high-risk patients is through the use of magnetic resonance imaging (MRI), which is an extremely useful but expensive non-invasive imaging tool. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 2\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the four categories of breast tissue density used in medical practice?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the four categories of breast tissue density used in medical practice?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are the four categories of breast tissue density used in medical practice?', ['6.S897/HST.956 Machine Learning for Healthcare Lecture 13: Machine Learning for Mammography Instructors: David Sontag, Peter Szolovits 1 Breast Image Interpretation: Background and Challenges Breast cancer affects over 2 million women of the 3.8 billion women globally, and is estimated to contribute to over 40,000 U.S. deaths and 600,000 worldwide deaths annually. The primary method for breast cancer diagnosis is the interpretation of mammography images, which are breast X-ray images. Mammograms are normally acquired from two different angles: craniocaudal (CC, which is a 2D projection of the axial view), and mediolateral oblique (MLO, which is a 2D projection of the frontal coronal view). Ideally, we would like to use these images for early detection of breast cancer, which would allow for more effective treatments and potential cures. It is particularly important to detect cancerous tissue before the non- metatstatic to metastatic transition, after which a cure is no longer feasible. The two primary challenges with mammographic analysis for this purpose are: Accurate risk assessment tools Effective screening tests Specifically, the three main problems that need to be addressed to resolve these challenges are: No risk assessment models are able to predict individual risk accurately There is significant variability in human interpretation of mammograms Widespread standardization and application of mammography are limited by the dearth of specialial- ists. 1.1 Mammogram interpretation The two questions that radiologists ask when analyzing a mammogram are: How dense is the breast tissue? Is it a normal or abnormal mammogram? In a mammogram (an example of which is given in Figure 1, the white pixels represent the breast tissue and black pixels represent fatty tissue inside the breasts; thus, breasts with higher densities of white pixels have higher breast density. The current standard medical practice is for radiologists to bin the tissue density into four categories: fatty (low density), scattered, heterogeneously dense, and dense. However, since cancerous tumors are also small blobs of white pixels, dense breast tissue can sometimes obscure or make it more difficult to detect anomalous cancerous tissues. The difficulty of finding small cancerous tissue in mammograms is illustrated by the case studies in Figure 2. Because of the 2D nature of traditional mammograms, patients with higher breast densities tend to receive more false negative mammograms, in which cancerous tissue is mistakenly diagnosed as healthy. This is shown in Figure 3, in which a 3D reconstruction of the breast tissue acquired using tomosynthesis (in which optical slices in the axial dimension are taken for 3D tomography) shows that cancerous tissue was missed in the 2D projection due to breast density. Although false negatives are the least frequent type of mammogram, it is particularly devastating because of the consequences it entails for the affected patient, who does not receive the appropriate treatment or care. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 1', '100 75 50 25 © American College of Physicians. All rights reserved. This content is 0 excluded from our Creative Commons license. For Radiologist (n=83) more information, see https://ocw.mit.edu/help/ Extremely dense Heterogeneously dense Scattered fibroglandular elements faq-fair-use/ Almost entirely fat Figure 4: Variation in radiologist assessment of breast density. Radiologists vary in \"dense\" breast tissue classification rates from 6% to 85% [SCO+16] 3. Clinical implementation In this section, we introduce the development of a model for automated mammogram triaging and another model for risk assessment. 2.1 Mammogram triaging The goal of the mammogram triaging model is to improve efficiency by reducing the false positives of cancer triaging (especially since >99% of patients are cancer-free). Given a cancer-free threshold that is set from training and development of the algorithm, the triaging process can be streamlined for radiologists by having them skip analysis of mammograms below the threshold. 2.1.1 Dataset collection Data was collected from mammograms in 5 hospital registries, and patient outcomes from Radiology EHR and Partners. These data were pulled from all available screening mammograms between January 2009 and December 2016 (inclusive), with no exclusions made based on race, age, implants or other features of that nature; however, patients with other cancers in the breast were excluded as well as patients with negative exams that did not have a 1-year followup. After these exclusions, there remained 223,109 distinct mammograms from 66,661 unique patients. Since some patients had multiple data points, the training, developmental (dev), and test sets were split by patient to prevent model memorization of patient inputs. The training set contained 1,472 positive exams (1,453 unique patients) and 210,804 negative exams (56,790 unique patients); the development set contained 167 positive exams (163 unique patients) and 25,832 negative exams (7,019 unique patients); the test set contained 191 positive exams (187 unique patients) and 26,349 negative exams (7,170 unique patients). 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 4', '2D FFDM Tomosynthesis Slice VENETU LECCS Cyst Lobular Carcinoma Figure 3: 2D VS. 3D Tomosynthesis mammograms. The 2D projection obscures the cancerous tissues that the tomosynthesis reveals. Images courtesy of Drs. Di Maggio G Gennaro, Istituto Oncologico Veneto I.R.C.C.S. (Padova, Italia) © Maggio and Gennaro. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ However, classical risk models are quite limited, in that they use some basic patient features (e.g. age, race, breast density, family history) to generate risk assessment, and oftentimes are quite sensitive to certain vari- ables. Additionally, the subjective categorization of tissue density (as described in Section 1.1) is subject to high variance between different radiologists, making that qualitative feature somewhat unreliable in classical risk models. We can see this exemplified in Figure 4. The limitations of current clinical risk assessment procedures are elegantly captured by the fact that 75% of all early MRI screens are performed in women with less than 20% lifetime risk, while only 2% of the women with over 20% lifetime risk receive an early MRI. In this sense, the current risk assessment tools are unable to be effective because they are not correctly screening the at-risk population. 2 Deep learning models for mammogram interpretation The usual process for triaging mammograms can be described by the following steps: 1. Routine screening (1000 patients) 2. Callback for additional imaging (100 patients) 3. Biopsy sample collection (20 patients) 4. Diagnosis / triage (6 patients) To harness deep learning (DL) for mammogram triaging or risk assessment, we follow a standard procedure for clinical deployment and utilization: 1. Dataset collection 2. Modeling 6.S897/HST.956 Machine Learning for Healthcare - Lec13 3'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', ['2D FFDM Tomosynthesis Slice VENETU LECCS Cyst Lobular Carcinoma Figure 3: 2D VS. 3D Tomosynthesis mammograms. The 2D projection obscures the cancerous tissues that the tomosynthesis reveals. Images courtesy of Drs. Di Maggio G Gennaro, Istituto Oncologico Veneto I.R.C.C.S. (Padova, Italia) © Maggio and Gennaro. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ However, classical risk models are quite limited, in that they use some basic patient features (e.g. age, race, breast density, family history) to generate risk assessment, and oftentimes are quite sensitive to certain vari- ables. Additionally, the subjective categorization of tissue density (as described in Section 1.1) is subject to high variance between different radiologists, making that qualitative feature somewhat unreliable in classical risk models. We can see this exemplified in Figure 4. The limitations of current clinical risk assessment procedures are elegantly captured by the fact that 75% of all early MRI screens are performed in women with less than 20% lifetime risk, while only 2% of the women with over 20% lifetime risk receive an early MRI. In this sense, the current risk assessment tools are unable to be effective because they are not correctly screening the at-risk population. 2 Deep learning models for mammogram interpretation The usual process for triaging mammograms can be described by the following steps: 1. Routine screening (1000 patients) 2. Callback for additional imaging (100 patients) 3. Biopsy sample collection (20 patients) 4. Diagnosis / triage (6 patients) To harness deep learning (DL) for mammogram triaging or risk assessment, we follow a standard procedure for clinical deployment and utilization: 1. Dataset collection 2. Modeling 6.S897/HST.956 Machine Learning for Healthcare - Lec13 3', '6.S897/HST.956 Machine Learning for Healthcare Lecture 13: Machine Learning for Mammography Instructors: David Sontag, Peter Szolovits 1 Breast Image Interpretation: Background and Challenges Breast cancer affects over 2 million women of the 3.8 billion women globally, and is estimated to contribute to over 40,000 U.S. deaths and 600,000 worldwide deaths annually. The primary method for breast cancer diagnosis is the interpretation of mammography images, which are breast X-ray images. Mammograms are normally acquired from two different angles: craniocaudal (CC, which is a 2D projection of the axial view), and mediolateral oblique (MLO, which is a 2D projection of the frontal coronal view). Ideally, we would like to use these images for early detection of breast cancer, which would allow for more effective treatments and potential cures. It is particularly important to detect cancerous tissue before the non- metatstatic to metastatic transition, after which a cure is no longer feasible. The two primary challenges with mammographic analysis for this purpose are: Accurate risk assessment tools Effective screening tests Specifically, the three main problems that need to be addressed to resolve these challenges are: No risk assessment models are able to predict individual risk accurately There is significant variability in human interpretation of mammograms Widespread standardization and application of mammography are limited by the dearth of specialial- ists. 1.1 Mammogram interpretation The two questions that radiologists ask when analyzing a mammogram are: How dense is the breast tissue? Is it a normal or abnormal mammogram? In a mammogram (an example of which is given in Figure 1, the white pixels represent the breast tissue and black pixels represent fatty tissue inside the breasts; thus, breasts with higher densities of white pixels have higher breast density. The current standard medical practice is for radiologists to bin the tissue density into four categories: fatty (low density), scattered, heterogeneously dense, and dense. However, since cancerous tumors are also small blobs of white pixels, dense breast tissue can sometimes obscure or make it more difficult to detect anomalous cancerous tissues. The difficulty of finding small cancerous tissue in mammograms is illustrated by the case studies in Figure 2. Because of the 2D nature of traditional mammograms, patients with higher breast densities tend to receive more false negative mammograms, in which cancerous tissue is mistakenly diagnosed as healthy. This is shown in Figure 3, in which a 3D reconstruction of the breast tissue acquired using tomosynthesis (in which optical slices in the axial dimension are taken for 3D tomography) shows that cancerous tissue was missed in the 2D projection due to breast density. Although false negatives are the least frequent type of mammogram, it is particularly devastating because of the consequences it entails for the affected patient, who does not receive the appropriate treatment or care. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 1', 'incomplete version of the data set. Another potential pitfall to automated mammogram interpretation is to interpret performance on reader studies as if they were clinical implementations. Reader studies should not be interpreted this way not only because of the dataset pitfalls mentioned previously, but because oftentimes inconvenient cases are excluded from the data set. For instance, a research study might filter out a dataset by breast size, or race, due to insufficient data points, or some other reason of analysis inconvenience. This will certainly further bias the dataset towards certain demographics and types of mammograms, thus making it non-generalizable and unsuitable for clinical implementation. 3 Future outlook In the past, traditional computer-aided diagnosis (CAD) did not perform well in mammogram interpretation, and was primarily used as a money-driven endeavor. With the development of new imaging modalities such as tomosynthesis (which takes 2D optical sections of the breast to provide a 3D reconstruction), AI technology and hospitals have struggled to keep up. However, combined with ever-increasing amounts of data, recent applications of deep learning towards mammogram triaging and risk assessment have greatly improved upon classical methods, providing a promising outlook of a more efficient and life-saving clinical pipeline. References [And12] Savvas Andronikou. The Breast, pages 359-375. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012. [SCO+16] B.L. Sprague, E.F. Conant, T. Onega, E.F. Beaber, S.D. Herschorn, C.D. Lehman, A.N. Toste- son, R. Lacson, M.D. Schnall, D. Kontos, J.S. Haas, D.L. Weaver, W.E. Barlow, and PROSPR Consortium. Variation in mammographic breast density assessments among radiologists in clinical practice: A multicenter observational study. Ann Intern Med, 165(7):457-464, 2016. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 9'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', [\"2.1.2 Challenges of applying DL to mammogram triaging While many aspects of the task of cancer detection based on mammograms are similar to that of natural image classification (ImageNet), there are some key differences that make this task tricky. First of all, the signal-to-noise-ratio (SNR) is much lower in mammograms compared to natural images. In other words, the cancerous tissue and region that is relevant for image classification is much smaller (tends to be around 1% of the image, exemplified in Figure 2) than the size of the relevant object(s) in natural images. The images in mammogram datasets are also much larger than natural images. For instance, mammograms tend to be on the order of 3000 by 2600 pixels, whereas ImageNet images tend to be orders of magnitude smaller. This leads to issues with memory and parallelization - in particular, the batch size is limited, which makes the stochastic gradient updates much noisier, and can impede model learning. Large individual images also just presents memory and storage issues in general; for example, the data set for this particular project was over 12 TB. Image size and low SNR ratio both lead to a separate challenge: if patches are used, this can lead to removal of important context, which can make it difficult to differentiate between cancerous and non-cancerous tissues. Lastly, if patch-based data is used, there is a heavy class imbalance, in that only around 0.7% of the inputs are positive, while the vast majority are negatives. While there are methods for resolving this being actively researched and implemented in the machine learning community, it is still a non-trivial challenge. 2.1.3 Building the model In building the DL model, the first thign considered was initialization of the model. Adam Yala and colleagues decided to use ImageNet pre-trained CNN models (e.g. VGG, ResNet, Wide-ResNet, DenseNet) to initialize the network, and then to mitigate the small batch size issue (talked about in section 2.1.2) that is a result of the large size of the images, they performed several forward and backpropagation steps through the network before updating the weights via gradient descent. In essence, this allows them to use a larger batch size than GPU memory allows, but doing it in series rather than in parallel. For this, they utilized a batch size of 24 (by taking 2 full steps with batch size 3 distributed over 4 GPU's). They found that initializing with ImageNet allowed for learning to occur much quicker (demonstrated in Figure 5) than when initializing the model randomly. One possible explanation for this is that the batch normalization statistics are more stable to begin with when using pre-trained weights from ImageNet. ImageNet-Init Random-Init 10 7.5 Train Loss 5 2.5 0 0 5 10 15 20 25 Figure 5: Loss VS. Epoch with ImageNet initialization and random initialization. ImageNet initialization allows for learning to occur quicker. In selecting a base architecture of the model, they preferred models that were fully convolutional to allow for flexibility in feeding in inputs of varying resolutions; thus, the ResNet-18 model was chosen. This was 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 5\", 'incomplete version of the data set. Another potential pitfall to automated mammogram interpretation is to interpret performance on reader studies as if they were clinical implementations. Reader studies should not be interpreted this way not only because of the dataset pitfalls mentioned previously, but because oftentimes inconvenient cases are excluded from the data set. For instance, a research study might filter out a dataset by breast size, or race, due to insufficient data points, or some other reason of analysis inconvenience. This will certainly further bias the dataset towards certain demographics and types of mammograms, thus making it non-generalizable and unsuitable for clinical implementation. 3 Future outlook In the past, traditional computer-aided diagnosis (CAD) did not perform well in mammogram interpretation, and was primarily used as a money-driven endeavor. With the development of new imaging modalities such as tomosynthesis (which takes 2D optical sections of the breast to provide a 3D reconstruction), AI technology and hospitals have struggled to keep up. However, combined with ever-increasing amounts of data, recent applications of deep learning towards mammogram triaging and risk assessment have greatly improved upon classical methods, providing a promising outlook of a more efficient and life-saving clinical pipeline. References [And12] Savvas Andronikou. The Breast, pages 359-375. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012. [SCO+16] B.L. Sprague, E.F. Conant, T. Onega, E.F. Beaber, S.D. Herschorn, C.D. Lehman, A.N. Toste- son, R. Lacson, M.D. Schnall, D. Kontos, J.S. Haas, D.L. Weaver, W.E. Barlow, and PROSPR Consortium. Variation in mammographic breast density assessments among radiologists in clinical practice: A multicenter observational study. Ann Intern Med, 165(7):457-464, 2016. 6.S897/HST.956 Machine Learning for Healthcare - Lec13 - 9', 'shown in Figure 9. Thus, we see that harnessing deep learning can have real potential to improve the risk assessment models that are used currently. Tyrer-Cuzick Image DL Image + RF DL 0.68 0.70 0.62 Full Test Set Figure 7: AUC on the test set using various risk models. The deep learning combined with classical features model performed the best. Tyrer-Cuzick Image DL Image + RF DL 0.69 0.71 0.69 0.71 0.62 0.45 White Women African American Women Figure 8: AUC comparison between models on white and African American women sub-populations Tyrer-Cuzick Image + RF DL 0.79 0.73 0.70 0.70 0.71 0.66 0.58 0.59 Figure 9: AUC comparison for various sub-populations, showing that the novel image + features DL model outperforms classical approaches. 2.2.3 Potential pitfalls While deep learning is able to perform particularly well in mammogram interpretation, there are still chal- lenges associated with it before it can achieve widespread clinical implementation. In particular, most data sets collected for mammogram interpretation are enriched, potentially not reflecting the true distribution of the data, and certainly contain biases (e.g. machine-specific collection at a certain hospital). For example, one dataset collected at a hospital in Shanghai had collected all of the cancer-positive data first, before collecting the negatives consecutively. This resulted in a skew dataset when researchers tried to use an 6.S897/HST.956 Machine Learning for Healthcare - Lec13 8'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 'mammography')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 'mammography')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', ['shown in Figure 9. Thus, we see that harnessing deep learning can have real potential to improve the risk assessment models that are used currently. Tyrer-Cuzick Image DL Image + RF DL 0.68 0.70 0.62 Full Test Set Figure 7: AUC on the test set using various risk models. The deep learning combined with classical features model performed the best. Tyrer-Cuzick Image DL Image + RF DL 0.69 0.71 0.69 0.71 0.62 0.45 White Women African American Women Figure 8: AUC comparison between models on white and African American women sub-populations Tyrer-Cuzick Image + RF DL 0.79 0.73 0.70 0.70 0.71 0.66 0.58 0.59 Figure 9: AUC comparison for various sub-populations, showing that the novel image + features DL model outperforms classical approaches. 2.2.3 Potential pitfalls While deep learning is able to perform particularly well in mammogram interpretation, there are still chal- lenges associated with it before it can achieve widespread clinical implementation. In particular, most data sets collected for mammogram interpretation are enriched, potentially not reflecting the true distribution of the data, and certainly contain biases (e.g. machine-specific collection at a certain hospital). For example, one dataset collected at a hospital in Shanghai had collected all of the cancer-positive data first, before collecting the negatives consecutively. This resulted in a skew dataset when researchers tried to use an 6.S897/HST.956 Machine Learning for Healthcare - Lec13 8', \"Radiologist False Positive Assessments by Risk Percentile FP triaged below threshold FP triaged above threshold 200 150 100 50 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 Risk Percentile Figure 6: With the cancer-free triage threshold of just above 0.2 model-predicted risk percentile, the radiologist's false positives colored in blue can be eliminated by the automated triaging done by the model. triage dataset) patients with negative exams which lacked a 5-year followup exam were excluded because the goal was to predict 5-year breast cancer risk. Once again, the train/dev/test sets were split by patient to prevent model memorization. In the end, the train set had 71,689 mammograms (31,806 unique patients), the validation set had 8,554 mammograms (3,804 unique patients), and the test set contained 8,751 mammograms (3,937 unique patients). The test set was constructed with an additional exclusion of excluding exams within one year of a cancer diagnosis. In this manner, the predictive value of the model could be limited to one temporal image per patient. 2.2.2 Results The objectives of this study were to: Is the model discriminative across all populations? How does the DL model relate to classical models? The same considerations for building the DL model from the previous section are used for this one, and the researchers decided to compare the risk assessment performance of (1) the DL model using image only, (2) DL using image and other classical features (e.g. age, race, breast density), and (3) Tyrer-Cuzick (a classical approach). Briefly, the Tyrer-Cuzick model estimates breast cancer risk from various family history, physical statistics, and demographic data. As shown in Figure 7, the hybrid method using DL image + features achieved an AUC of 0.7, whereas the DL image only model achieved an AUC of 0.68, and the traditional feature-based Tyrer-Cuzick achieved an AUC of 0.62. It is particularly interesting to note that the Tyrer-Cuzick model, since it was trained on only white women, performed especially poorly on risk assessment of African-American women, achieving an AUC of 0.45 (the DL + features model achieved 0.71 AUC, as seen in Figure 8). This is worse than a model that is guessing randomly. Additionally, we see that the DL image + features model is discriminative across different populations by performing significantly better than the Tyrer-Cuzick model on various sub-populations, as 6.S897/HST.956 Machine Learning for Healthcare - Lec13 7\", \"especially important in implementing a two-stage training method in which patches from the mammograms were sampled and fed to the network to pre-train the network, and then followed by fine tuning the model using the full-sized images. The researchers found that with the aforementioned serial batch size method, they could resolve the noisy stochastic gradient problem and directly train the model using the full sized images. Finally, in order to calibrate the class balance to the real incidence of either class, Platt's method is used, in which a sigmoid function is learned to scale and shift the probabilities calculated from the model (based on training data) to the true incidence rate. In this manner, the incidence rate of classes in the training data does not skew the distribution of predictions during inference. The model triaged by ranking radiologist true positives by the probability assigned by the model, and then returning the minimum probability of radiologist-identified true positive in the development set. To evaluate the best model, instead of using AUC, the triage ability of the model on the dev set was used. 2.1.4 Results The objectives of the model during analysis were: Is the model discriminative across all populations? Does the model capture radiologist mistakes or do they overlap? Assess the triage on test set The model achieved an AUC of 0.82 (confidence interval: [0.8, 0.85]) on the dev set, with no statistically significant difference in predictive value between varying ages, races, and breast densities. The main goal of the model was to not miss a single cancer the radiologist would have caught, in order to be used as an aid (and not replacement) for medical professionals. Thus, it is important to assess how the performance compared to radiologist assessments. It was determined that the model was able to triage significant portions of radiologist-assigned true positives, false positives, and true negatives that were below the model's triage threshold, both reducing radiologist labor (on the true positives and negatives) and limiting the false positives (by triaging those below the threshold as cancer-free, shown in Figure 6). These results are summarized quantitatively in Table 1, with the model increasing specificity by 0.7% and reducing the % of mammograms read by radiologist by 20%. Setting Sensitivey (95% Specificity (95% Mammograms CI) CI) Read (95% CI) Original Interpreting Radiologist 90.6% (86.7, 94.8) 93.0% (92.7, 93.3) 100% (100, 100) Original Interpreting Radiologist 90.1% (86.1, 94.5) 93.7% (93.0, 94.4) 80.7% (80.0, 81.5) + Triage Table 1: Test set triage simulation results. 2.2 Mammogram risk assessment 2.2.1 Dataset collection and model construction A similar method was followed to build a DL model for mammogram risk assessment. Here, the data set was constructed similarly by using mammogram images from a 5 Hospital Registry and patient outcomes from Radiology EHR and Partners from January 2009 to December 2012 with no exclusions based on race and other factors. Again, patients with other cancers in the breast were excluded, but (different from the 6.S897/HST.956 Machine Learning for Healthcare - Lec13 6\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the primary challenge with using billing codes for clinical research?', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the primary challenge with using billing codes for clinical research?', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the primary challenge with using billing codes for clinical research?', [\"in this dataset turned out to be really low (~ 19%)! There is a systematic reason for this as the billing codes were not created to specify what was actually wrong with the patient; instead the billing codes were meant to tell insurance companies/medicare that how much of the payment is reserved for the doctors taking care of them. So the billing codes are very imperfect versions of reality as the billing codes for a patient who is diagnosed with the disease eventually has the same billing codes as the ones for a patient who doesn't eventually get diagnosed with the same disease as the diagnostic procedure is the same! Next, they insisted that instead of just a single billing code for RA, they selected patients from a pool of patients who had three billing codes for RA. This raised the positive predictive value to about 27%. This was again surprising. The reason for such a low PPV even with 3 billing codes was because you can have multiple billing codes during the same visit e.g. one billing code for x-ray, another billing code for blood test for anti-CCP titre. It is entirely possible that all of this is negative and the patient doesn't even have the disease. These aspects are important to consider in clinical data. In order to understand the relation between genetics and the disease, they required a PPV of more than 95% to get a very pure sample of people with RA to get some meaningful results. 1KDRA EMR n=25,830 RA Mart Classification Predicted OR n=29, 432 algorithm RA Cases million Arti-CCP n=3,602 n=3,585 Training set Validation set n=500 training n-400 High sensitivity High specificity © American College of Rheumatology. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 1: Finding a Cohort of Rheumatoid Arthritis Cases. The methodology followed by Professor Solovitz is shown in Fig. 1. This was done by first taking 4 million patients in EMR and selecting ~ 29,000 patients who had atleast one ICD-9 code for RA, or they had an anti-CCP titre. They selected 500 cases on which they got gold standard readings from rheumatologists and then trained an algorithm to predict whether the patient really had RA or not and that predicted 3, 585 cases out of the 29, 432 had RA. Then, they sampled a validation set of 400 out of those and got those evaluated by rheumatologists to give them gold standard on those! Note that they removed people with ICD-9 codes that fell under the general category of rheumatoid diseases because those people were not appropriate for the data sample they required. They dealt with multiple coding for the same visit by ignoring codes that occurred within a week of each other. They looked for electronic prescriptions of various sorts and lab tests. Counting the number of facts in the database for a patient served as a good proxy for how sick the patient was. For the narrative text, they used a system called HITEx that extracted entities from narrative text [1]. This was done from health care provider notes, radiology reports, pathology reports, discharge summaries, and operative reports. They also used diagnoses notes, medications, laboratory data and radiology findings. This list from the system was augmented with a hand-curated list of alternative ways of saying the same thing to expand the text. They also ensured that they dealt with negation. The model used was logistic regression. It was interesting to see the positive predictors were a mixture of those dependent on codified data and others dependent on NLP. This work built a compelling reason to show there is real value in narrative text. Using codified data (e.g. lab values, demographics) only to predict whether a patient has rheumatoid arthritis lead to a PPV of 88% On the other hand, using natural language processing on clinical text (nursing notes, discharge summaries etc.) gave a PPV of 89%. Not surprisingly, a combination of both codified data and NLP gave a PPV of 94% [2]. Another interesting study tried to replicate the results at Vanderbilt and Northwestern [3]. Even though you couldn't run exactly the same methodology based on the fact that all three had different systems. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 2\", '© American Medical Informatics Association. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Testing set Partners Northwestern Vanderbilt Average Algorithm PPV Sensitivity AUC PPV Sensitivity AUC PPV Sensitivity AUC PPV Sensitivity AUC Published algorithm 88%* 79%* 97%* 87% 60% 92% 95% 57% 95% 90% 65% 95% Retrained with Northwestern 79% 47% 89% 87% 73% 92% 93% 43% 89% 86% 54% 90% Vanderbilt 85% 74% 97% 82% 40% 88% 97% 81% 97% 88% 65% 94% Combined 86% 71% 97% 86% 65% 91% 97% 82% 96% 90% 72% 95% ICD-9 only t 1 RA code 22% 97% N/A 26% 100% N/A 49% 100% N/A 33% 99% N/A 3 RA code 55% 81% N/A 42% 87% N/A 73% 98% N/A 57% 89% N/A 97% Specificity 80% 49% 88% 80% 36% 84% 93% 43% 93% 84% 43% 88% Code count for 97% specificity 53 29 48 43.3 The PPV and sensitivity values reported represent model performance with a specificity set at 97% for logistic regression models. *These results are from a fivefold cross-validation on the Partners training set. The PPV and sensitivity as published in Liao et al was calculated from a separate Partners validation set (PPV 94%, sensitivity 63%). +ICD-9 cut-off used the count of 714.* codes, excluding codes for juvenile RA (714.3*). AUC, area under the receiver operating characteristic curve; ICD-9, International Classification of Diseases, version 9 CM; PPV, positive predictive value; RA, rheumatoid arthritis. (a) Algorithm for RA was portable. A Tested un Partners B Tested on Northwestern Tested on Vanderbill Tranegor Transa on haired on P Combined (57%) Combined 01% Combined (96%) Partners 197% Partner (02%) Patrion (95%) Northwestern (10%) Numbers (12%) (89%) TO Vanderbit (97%) Venderbit (88%) DO Venderbit (97%) as 02 24 es e. La so 9.2 04 0.6 os L9 as ea as 26 2.8 14 Faise poptive raor Faxe rate Fake polors as (b) Receiver Operating Characteristic curves for each test set. The vertical line represents the 97% specificity cut-off used in this study. The test performance at Partners, Northwestern, and Vanderbilt are found in (A), (B), and (C) respectively. Figure 2: Medication, for example, was extracted from their local EMR in different ways. It was expected that this replication might not produce similar results as it varies how people describe patients in different regions. However, surprisingly, the model performance, despite variation in data representation, was fairly similar as shown in Fig. 2a. Plotting the ROC curves for the three cohorts, as shown in Fig. 2b, demonstrated that training on NorthWestern data and testing on Partners and Vanderbilt was not SO great. However, training on Partners and Vanderbilt and testing on Northwestern data turned out to be quite decent. This indicated that there was some generality to the algorithm! Next, Professor Solovitz showed a sample of terms in a nursing note, which demonstrated the terms was unreadable as English because they were highly abbreviated and shortened. This is shown in Fig. 3. This is still an open research question how to deal with this effectively. 3 Goals of NLP The typical goals of NLP are described below: Assign a meaning (or null) to any word or phrase from some taxonomy/ontology/terminology. For 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 3', 'Baseline NegEx Group 1 Group 2 Group Group 2 sentences due sentences (Le., contences (Le contenced (i.e., containing not containing contences containing not containing AA contences NegEx NegEx NegEX NegEx negation negation negation negation phrases) physion presson) phrases) 0 500 500 1000 500 500 1000 Sensitivity 88.27 0,00 88.27 82,31 0.00 77.84 Specificity 52,69 100.00 85,27 82.50 100.00 94.51 PPV 68.42 - 68:42 84.49 - 84.49 NRV 79,46 96.99 93.01 80.21 96.99 91.73 Figure 5: NegEx Results. 6 Unified Medical Language System (UMLS) In 1985, National Library of Medicine made a huge effort to create UMLS; this was an attempt to take all of the terminologies that various medical societies had developed and unify them into what they termed as \"meta-thesaurus\". They also dedicated huge amount of human and machine resources to identify cases in which two different expressions from different terminologies meant the same thing. For instance, heart attack, myocardial infarction, and acute myocardial infarction mean the same. They used the resources to scour the databases and come up with a mapping of each of these terms to a single concept. This is an enormous help to normalize databases that come from different places and are described differently. It also gives you, in the context of natural language processing, a treasure trove of ways of expressing the same conceptual idea and it gives you ways to expand the kind of expressions that you are looking for. There are about 3.7 million concepts in this meta-thesaurus, each of which is assigned a concept unique identifier (CUI). There are also hierarchies and relationships that are imported from all of these different sources of terminology; though these are a jumbled mess. They also created a semantic network of 54 relations and 127 types. Every CUI is assigned at least one semantic type. Examples of UMLS concepts of various types are shown in Fig. 6. The types are hierarchically organized: an example is shown in Fig. 7 There are also tools that deal with some simplistic linguistic problems. For example, \"lead\", \"leads\", and \"leading\" are the same concept. So, there are Lexical Variation Generation (LVG) tools that help you normalize this sort of problem. Similarly, there is a normalization function that helps you normalize sentences into lower-case alphabetized version of the text, e.g. \"Mr. Huntington was admitted to Huntington Memorial Hospital for acute chest pain in March\" is normalized to \"acute admit be chest hospital huntington huntington march memorial mr pain\". Then, text can translated into other potential linguistic meanings of that text. There is also an online tool available through UMLS Terminology Services, where you can type ayagia select c from mrsty group by aty select From azoonao e 2010 araty a on order by c desc) where and c.GtT-IPF\\' and c.ISPAST= and c.LAT=TEN and tai= T0471 tui aty e cal ALT 1062 Therapestic or Preventive Procedure 260914 2033 Finding 233579 C0000744 Abetalipoproteinemia T200 Clinical Drug 172069 C0000174 Gastrin secretion obnormality NOS T109 Organic Chemical 157501 C0000386 Spontaneous abortion T121 Pharmacologic Substance 124644 C0000809 Abortion, Habitual 7116 Amino Acid, Peptide, or Protein 117508 C0000814 Missed abortion TOOM Invertebrate 111044 C0000821 Threatened abortion TOOD Bacterium 110065 C0000022 Abortion, Tube) T002 Plant 95017 C0000823 Abortion, Veterinary 2047 Disesse or Syndrome 29370 C0000832 Abruptio Placentac 7023 Body Part. Organ. or Organ Componént 73402 00000000 Acanthamoeba Keratitis 2201 Clinical Astribute 69998 00000099 Acantbosis Nigricana 7123 BioLogically Active Substance 55741 00001080 Achondroplasia T074 Medical Devion 51708 C0001083 Achromis parasitica 7020 Gene or Genone 49960 C0001125 Acidosis, Lactic Figure 6: Wealth of UMLS Concepts of Various Types. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 6'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 7: Natural Language Processing (NLP) Instructors: David Sontag, Peter Szolovits 1 Outline This lecture and the next covers the role of Natural Language Processing in machine learning in healthcare. The two lectures in succession first cover methods, which are not based on neural networks representations and then discusses techniques which employ neural network architectures. We begin by first motivating why we care about clinical text. Later, we discuss some conceptually very appealing, but practically infeasible methods that involve analyzing the narrative texts as linguistic entities in a way that a linguistic might approach them. Next, we discuss what is actually often done e.g. a term spotting approach that says that we might not be able to understand everything that goes on in the narratives, but we can identify certain words/phrases that are highly indicative of whether a certain patient has a certain disease, or a symptom or a medical procedure that was done to them. This is the bread and butter of how clinical research is done nowadays. 2 Value of the data in clinical text Let's see an example of a discharge summary from MIMIC dataset. The text has been de-identified in the dataset. We know that in MIMIC dataset, we see astericks in places of names, dates, locations etc. Here those entities have been replaced with synthetics names, dates, locations etc. to make it look like a piece that reads like a real text. We want to take advantage of these clinical notes because they carry important information about what happened to the patient over the course of their stay at the hospital. Mr. Blind is a 79-year-old white male with a history of diabetes mellitus, inferior myocardial infarction, who underwent open repair of his increased diverticulum November 13th at Sephsand- pot Center. The patient developed hematemesis November 15th and was intubated for respiratory distress. He was transferred to the Valtawnprinceel Community Memorial Hospital for endoscopy and esophagoscopy on the 16th of November which showed a 2 cm linear tear of the esophagus at 30 to 32 cm. The patient's hematocrit was stable and he was given no further intervention. The patient attempted a gastrografin swallow on the 21st, but was unable to cooperate with probable aspiration. The patient also had been receiving generous intravenous hydration during the period for which he was NPO for his esophageal tear and intravenous Lasix for a question of pulmonary congestion. On the morning of the 22nd the patient developed tachypnea with a chest X-ray showing a question of congestive heart failure. A medical consult was obtained at the Valtawnprinceel Community Memorial Hospital. The patient was given intravenous Lasix. Note: orange=demographics; blue=patient condition, diseases, etc.; red=procedures, tests; magenta=results of measurements; yellow=time In fact to give you a more quantitative version of this, Professor Solovitz and Dr. Katherine worked on a project in 2010 in which they tried to understand what are the genetic correlates of rheumatoid arthritis (RA). In order to do this, they went to Research Patient Data Repository (RPDR) of Massachusetts General and Brigham Partners Healthcare and tried to find the patients who had been billed for rheumatoid arthritis. Naturally, there were thousands of those patients who had been billed for RA. So, they selected a random subset of those patients and gave their records to dermatologists to find out which of those patients actually had rheumatoid arthritis. They found out that the positive predictive value of having a billing code for RA 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 1\", 'example, \"rheumatoid arthritis\" gets codified to 714.0 (ICD-9). Determine whether any word or phrase represents protected health information. For example, de- identify \"Mr. Huntington suffers from Huntington\\'s Disease\" without losing medical information. Determine aspects of each entity such as time, location, certainty etc. Identify relationships between two meaningful phrases in a sentence, for example precedence, causality, indication etc. Identify the sentences or fragments most relevant to answering a specific medical question. For instance, where is the patient\\'s exercise regimen discussed? Summarize large corpus of medical text to provide a meaningful overview. It is important to understand that there are two kinds of tasks. For instance, if you are performing de- identification, you need to look at each word in order to see if it is protective health information. In contrast, the second kind of task requires aggregate judgements where many of the words do not make any difference. For example, one of the challenges the healthcare community working in NLP ran in 2006 gave people medical records and gave them the task of predicting whether the patient is a smoker. In this context, there were obviously words such as \"smoker\", \"tobacco user\" that were helpful in making a prediction; however, even these terms were sometimes misleading as a researcher who was working in tobacco mosaic virus got predicted to be a smoker! Another interesting case said that the patient quit smoking two days ago, which is certainly impossible to correctly predict whether that patient was a smoker or not. Similarly, aggregate judgement in process of cohort selection doesn\\'t require you to know everything about a patient but only whether they fit a certain inclusion criteria. 4 Hyper-simplified linguistics Dr. Thompson, Professor Solovitz\\'s PhD advisor, published an article \"English for the Computer\" in 1966 [4], which discussed a method to process english. It assumed that there was a grammar and any english text you come across is parsed according to this grammar and each parsing rule corresponds to some semantic function and the picture that emerges is shown in Fig. 4. If you have two phrases with some syntactic 3/11/98 IPN (date of) Intern Progress Note, SOB & DOE i the patient\\'s shortness of breath and dyspnea on exertion are decreased, VSS. AF the patient\\'s vital signs are stable and the patient is afebrile, CXR LLL ASD no A a recent new chest xray shows a left lower lobe air space density that is unchanged from the previous radiograph, WBC IIK a recent new white blood cell count is 11,000 cells per cubic milliliter, S/B Cx GPC c/w PC. no the patient\\'s sputum and blood cultures are positive for gram GNR positive cocci-consistent with prieumococcus, no gram negative rods have grown, D/C Cef PPN IV so the plan is to discontinue the cefazolin and then begin penicilin treatment intravenously, Figure 3: Sample terms used in a nursing note. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 4', 'Baseline NegEx Group 1 Group 2 Group Group 2 sentences due sentences (Le., contences (Le contenced (i.e., containing not containing contences containing not containing AA contences NegEx NegEx NegEX NegEx negation negation negation negation phrases) physion presson) phrases) 0 500 500 1000 500 500 1000 Sensitivity 88.27 0,00 88.27 82,31 0.00 77.84 Specificity 52,69 100.00 85,27 82.50 100.00 94.51 PPV 68.42 - 68:42 84.49 - 84.49 NRV 79,46 96.99 93.01 80.21 96.99 91.73 Figure 5: NegEx Results. 6 Unified Medical Language System (UMLS) In 1985, National Library of Medicine made a huge effort to create UMLS; this was an attempt to take all of the terminologies that various medical societies had developed and unify them into what they termed as \"meta-thesaurus\". They also dedicated huge amount of human and machine resources to identify cases in which two different expressions from different terminologies meant the same thing. For instance, heart attack, myocardial infarction, and acute myocardial infarction mean the same. They used the resources to scour the databases and come up with a mapping of each of these terms to a single concept. This is an enormous help to normalize databases that come from different places and are described differently. It also gives you, in the context of natural language processing, a treasure trove of ways of expressing the same conceptual idea and it gives you ways to expand the kind of expressions that you are looking for. There are about 3.7 million concepts in this meta-thesaurus, each of which is assigned a concept unique identifier (CUI). There are also hierarchies and relationships that are imported from all of these different sources of terminology; though these are a jumbled mess. They also created a semantic network of 54 relations and 127 types. Every CUI is assigned at least one semantic type. Examples of UMLS concepts of various types are shown in Fig. 6. The types are hierarchically organized: an example is shown in Fig. 7 There are also tools that deal with some simplistic linguistic problems. For example, \"lead\", \"leads\", and \"leading\" are the same concept. So, there are Lexical Variation Generation (LVG) tools that help you normalize this sort of problem. Similarly, there is a normalization function that helps you normalize sentences into lower-case alphabetized version of the text, e.g. \"Mr. Huntington was admitted to Huntington Memorial Hospital for acute chest pain in March\" is normalized to \"acute admit be chest hospital huntington huntington march memorial mr pain\". Then, text can translated into other potential linguistic meanings of that text. There is also an online tool available through UMLS Terminology Services, where you can type ayagia select c from mrsty group by aty select From azoonao e 2010 araty a on order by c desc) where and c.GtT-IPF\\' and c.ISPAST= and c.LAT=TEN and tai= T0471 tui aty e cal ALT 1062 Therapestic or Preventive Procedure 260914 2033 Finding 233579 C0000744 Abetalipoproteinemia T200 Clinical Drug 172069 C0000174 Gastrin secretion obnormality NOS T109 Organic Chemical 157501 C0000386 Spontaneous abortion T121 Pharmacologic Substance 124644 C0000809 Abortion, Habitual 7116 Amino Acid, Peptide, or Protein 117508 C0000814 Missed abortion TOOM Invertebrate 111044 C0000821 Threatened abortion TOOD Bacterium 110065 C0000022 Abortion, Tube) T002 Plant 95017 C0000823 Abortion, Veterinary 2047 Disesse or Syndrome 29370 C0000832 Abruptio Placentac 7023 Body Part. Organ. or Organ Componént 73402 00000000 Acanthamoeba Keratitis 2201 Clinical Astribute 69998 00000099 Acantbosis Nigricana 7123 BioLogically Active Substance 55741 00001080 Achondroplasia T074 Medical Devion 51708 C0001083 Achromis parasitica 7020 Gene or Genone 49960 C0001125 Acidosis, Lactic Figure 6: Wealth of UMLS Concepts of Various Types. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 6'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some goals of NLP in healthcare as discussed in the lecture?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 7: Natural Language Processing (NLP) Instructors: David Sontag, Peter Szolovits 1 Outline This lecture and the next covers the role of Natural Language Processing in machine learning in healthcare. The two lectures in succession first cover methods, which are not based on neural networks representations and then discusses techniques which employ neural network architectures. We begin by first motivating why we care about clinical text. Later, we discuss some conceptually very appealing, but practically infeasible methods that involve analyzing the narrative texts as linguistic entities in a way that a linguistic might approach them. Next, we discuss what is actually often done e.g. a term spotting approach that says that we might not be able to understand everything that goes on in the narratives, but we can identify certain words/phrases that are highly indicative of whether a certain patient has a certain disease, or a symptom or a medical procedure that was done to them. This is the bread and butter of how clinical research is done nowadays. 2 Value of the data in clinical text Let's see an example of a discharge summary from MIMIC dataset. The text has been de-identified in the dataset. We know that in MIMIC dataset, we see astericks in places of names, dates, locations etc. Here those entities have been replaced with synthetics names, dates, locations etc. to make it look like a piece that reads like a real text. We want to take advantage of these clinical notes because they carry important information about what happened to the patient over the course of their stay at the hospital. Mr. Blind is a 79-year-old white male with a history of diabetes mellitus, inferior myocardial infarction, who underwent open repair of his increased diverticulum November 13th at Sephsand- pot Center. The patient developed hematemesis November 15th and was intubated for respiratory distress. He was transferred to the Valtawnprinceel Community Memorial Hospital for endoscopy and esophagoscopy on the 16th of November which showed a 2 cm linear tear of the esophagus at 30 to 32 cm. The patient's hematocrit was stable and he was given no further intervention. The patient attempted a gastrografin swallow on the 21st, but was unable to cooperate with probable aspiration. The patient also had been receiving generous intravenous hydration during the period for which he was NPO for his esophageal tear and intravenous Lasix for a question of pulmonary congestion. On the morning of the 22nd the patient developed tachypnea with a chest X-ray showing a question of congestive heart failure. A medical consult was obtained at the Valtawnprinceel Community Memorial Hospital. The patient was given intravenous Lasix. Note: orange=demographics; blue=patient condition, diseases, etc.; red=procedures, tests; magenta=results of measurements; yellow=time In fact to give you a more quantitative version of this, Professor Solovitz and Dr. Katherine worked on a project in 2010 in which they tried to understand what are the genetic correlates of rheumatoid arthritis (RA). In order to do this, they went to Research Patient Data Repository (RPDR) of Massachusetts General and Brigham Partners Healthcare and tried to find the patients who had been billed for rheumatoid arthritis. Naturally, there were thousands of those patients who had been billed for RA. So, they selected a random subset of those patients and gave their records to dermatologists to find out which of those patients actually had rheumatoid arthritis. They found out that the positive predictive value of having a billing code for RA 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 1\", 'example, \"rheumatoid arthritis\" gets codified to 714.0 (ICD-9). Determine whether any word or phrase represents protected health information. For example, de- identify \"Mr. Huntington suffers from Huntington\\'s Disease\" without losing medical information. Determine aspects of each entity such as time, location, certainty etc. Identify relationships between two meaningful phrases in a sentence, for example precedence, causality, indication etc. Identify the sentences or fragments most relevant to answering a specific medical question. For instance, where is the patient\\'s exercise regimen discussed? Summarize large corpus of medical text to provide a meaningful overview. It is important to understand that there are two kinds of tasks. For instance, if you are performing de- identification, you need to look at each word in order to see if it is protective health information. In contrast, the second kind of task requires aggregate judgements where many of the words do not make any difference. For example, one of the challenges the healthcare community working in NLP ran in 2006 gave people medical records and gave them the task of predicting whether the patient is a smoker. In this context, there were obviously words such as \"smoker\", \"tobacco user\" that were helpful in making a prediction; however, even these terms were sometimes misleading as a researcher who was working in tobacco mosaic virus got predicted to be a smoker! Another interesting case said that the patient quit smoking two days ago, which is certainly impossible to correctly predict whether that patient was a smoker or not. Similarly, aggregate judgement in process of cohort selection doesn\\'t require you to know everything about a patient but only whether they fit a certain inclusion criteria. 4 Hyper-simplified linguistics Dr. Thompson, Professor Solovitz\\'s PhD advisor, published an article \"English for the Computer\" in 1966 [4], which discussed a method to process english. It assumed that there was a grammar and any english text you come across is parsed according to this grammar and each parsing rule corresponds to some semantic function and the picture that emerges is shown in Fig. 4. If you have two phrases with some syntactic 3/11/98 IPN (date of) Intern Progress Note, SOB & DOE i the patient\\'s shortness of breath and dyspnea on exertion are decreased, VSS. AF the patient\\'s vital signs are stable and the patient is afebrile, CXR LLL ASD no A a recent new chest xray shows a left lower lobe air space density that is unchanged from the previous radiograph, WBC IIK a recent new white blood cell count is 11,000 cells per cubic milliliter, S/B Cx GPC c/w PC. no the patient\\'s sputum and blood cultures are positive for gram GNR positive cocci-consistent with prieumococcus, no gram negative rods have grown, D/C Cef PPN IV so the plan is to discontinue the cefazolin and then begin penicilin treatment intravenously, Figure 3: Sample terms used in a nursing note. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 4', 'Biologic Function Physiologic Pathologic Function Function Organism Organ or Cell Molecular Cell or Disease or Experimental Function Tissue Function Function Molecular Syndrome model Function Dysfunction of Disease Mental Genetic Mental or Neoplastic Process Function Behavioral Process Dysfunction Courtesy of National Library of Medicine. Image is in the public domain. Figure 7: Hierarchy of UMLS Semantic Network Types and Relations. something to get the concept, semantic type etc. In the next lecture, Professor Solovitz will discuss the advanced machine learning approaches for natural language processing, some of which are based on neural network representations. References [1] Zeng QT, Goryachev S, Weiss S, Sordo M, Murphy SN, Lazarus R. Extracting principal diagnosis, co- morbidity and smoking status for asthma research: evaluation of a natural language processing system. BMC Med Inform Decis Mak 2006;6:30. [2] Liao, K. P., Cai, T., Gainer, V., Goryachev, S., Zeng-Treitler, Q., Raychaudhuri, S., Szolovits, P., Churchill, S., Murphy, S., Kohane, I., Karlson, E., Plenge, R. (2010). Electronic medical records for discovery research in rheumatoid arthritis. Arthritis Care & Research, 62(8), 1120-1127. http://doi.org/10.1002/acr.20184 [3] Carroll, R. J., Thompson, W. K., Eyler, A. E., Mandelin, A. M., Cai, T., Zink, R. M., et al. (2012). Portability of an algorithm to identify rheumatoid arthritis in electronic health records. Journal of the American Medical Informatics Association, 19(e1), e162-9. http://doi.org/10.1136/amiajnl-2011-000583 [4] Frederick B. Thompson, \"English for the Computer.\" Proceedings of the Fall Joint Computer Conference (1966) pp. 349-356 [5] Walker, D. E., Hobbs, J. R., 1981. Natural Language Access to Medical Text*. (pp. 269-273). Presented at the Proc Annu Symp Comput Appl Med Care. [6] de Heaulme M, Tainturier C, Thomas D. [Computer treatment of medical reports: example of the \"Remde\" system (author\\'s transl)]. Nouv Presse Med. 1979 Oct 22;8(40):3223-6. French. PubMed PMID: 534182 [7] Chapman WW, Bridewell W, Hanbury P, Cooper GF, Buchanan BG. A simple algorithm for identifying negated findings and diseases in discharge summaries. J Biomed Inform. 2001 Oct;34(5):301-10. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 7'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', ['Baseline NegEx Group 1 Group 2 Group Group 2 sentences due sentences (Le., contences (Le contenced (i.e., containing not containing contences containing not containing AA contences NegEx NegEx NegEX NegEx negation negation negation negation phrases) physion presson) phrases) 0 500 500 1000 500 500 1000 Sensitivity 88.27 0,00 88.27 82,31 0.00 77.84 Specificity 52,69 100.00 85,27 82.50 100.00 94.51 PPV 68.42 - 68:42 84.49 - 84.49 NRV 79,46 96.99 93.01 80.21 96.99 91.73 Figure 5: NegEx Results. 6 Unified Medical Language System (UMLS) In 1985, National Library of Medicine made a huge effort to create UMLS; this was an attempt to take all of the terminologies that various medical societies had developed and unify them into what they termed as \"meta-thesaurus\". They also dedicated huge amount of human and machine resources to identify cases in which two different expressions from different terminologies meant the same thing. For instance, heart attack, myocardial infarction, and acute myocardial infarction mean the same. They used the resources to scour the databases and come up with a mapping of each of these terms to a single concept. This is an enormous help to normalize databases that come from different places and are described differently. It also gives you, in the context of natural language processing, a treasure trove of ways of expressing the same conceptual idea and it gives you ways to expand the kind of expressions that you are looking for. There are about 3.7 million concepts in this meta-thesaurus, each of which is assigned a concept unique identifier (CUI). There are also hierarchies and relationships that are imported from all of these different sources of terminology; though these are a jumbled mess. They also created a semantic network of 54 relations and 127 types. Every CUI is assigned at least one semantic type. Examples of UMLS concepts of various types are shown in Fig. 6. The types are hierarchically organized: an example is shown in Fig. 7 There are also tools that deal with some simplistic linguistic problems. For example, \"lead\", \"leads\", and \"leading\" are the same concept. So, there are Lexical Variation Generation (LVG) tools that help you normalize this sort of problem. Similarly, there is a normalization function that helps you normalize sentences into lower-case alphabetized version of the text, e.g. \"Mr. Huntington was admitted to Huntington Memorial Hospital for acute chest pain in March\" is normalized to \"acute admit be chest hospital huntington huntington march memorial mr pain\". Then, text can translated into other potential linguistic meanings of that text. There is also an online tool available through UMLS Terminology Services, where you can type ayagia select c from mrsty group by aty select From azoonao e 2010 araty a on order by c desc) where and c.GtT-IPF\\' and c.ISPAST= and c.LAT=TEN and tai= T0471 tui aty e cal ALT 1062 Therapestic or Preventive Procedure 260914 2033 Finding 233579 C0000744 Abetalipoproteinemia T200 Clinical Drug 172069 C0000174 Gastrin secretion obnormality NOS T109 Organic Chemical 157501 C0000386 Spontaneous abortion T121 Pharmacologic Substance 124644 C0000809 Abortion, Habitual 7116 Amino Acid, Peptide, or Protein 117508 C0000814 Missed abortion TOOM Invertebrate 111044 C0000821 Threatened abortion TOOD Bacterium 110065 C0000022 Abortion, Tube) T002 Plant 95017 C0000823 Abortion, Veterinary 2047 Disesse or Syndrome 29370 C0000832 Abruptio Placentac 7023 Body Part. Organ. or Organ Componént 73402 00000000 Acanthamoeba Keratitis 2201 Clinical Astribute 69998 00000099 Acantbosis Nigricana 7123 BioLogically Active Substance 55741 00001080 Achondroplasia T074 Medical Devion 51708 C0001083 Achromis parasitica 7020 Gene or Genone 49960 C0001125 Acidosis, Lactic Figure 6: Wealth of UMLS Concepts of Various Types. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 6', \"6.S897/HST.956 Machine Learning for Healthcare Lecture 7: Natural Language Processing (NLP) Instructors: David Sontag, Peter Szolovits 1 Outline This lecture and the next covers the role of Natural Language Processing in machine learning in healthcare. The two lectures in succession first cover methods, which are not based on neural networks representations and then discusses techniques which employ neural network architectures. We begin by first motivating why we care about clinical text. Later, we discuss some conceptually very appealing, but practically infeasible methods that involve analyzing the narrative texts as linguistic entities in a way that a linguistic might approach them. Next, we discuss what is actually often done e.g. a term spotting approach that says that we might not be able to understand everything that goes on in the narratives, but we can identify certain words/phrases that are highly indicative of whether a certain patient has a certain disease, or a symptom or a medical procedure that was done to them. This is the bread and butter of how clinical research is done nowadays. 2 Value of the data in clinical text Let's see an example of a discharge summary from MIMIC dataset. The text has been de-identified in the dataset. We know that in MIMIC dataset, we see astericks in places of names, dates, locations etc. Here those entities have been replaced with synthetics names, dates, locations etc. to make it look like a piece that reads like a real text. We want to take advantage of these clinical notes because they carry important information about what happened to the patient over the course of their stay at the hospital. Mr. Blind is a 79-year-old white male with a history of diabetes mellitus, inferior myocardial infarction, who underwent open repair of his increased diverticulum November 13th at Sephsand- pot Center. The patient developed hematemesis November 15th and was intubated for respiratory distress. He was transferred to the Valtawnprinceel Community Memorial Hospital for endoscopy and esophagoscopy on the 16th of November which showed a 2 cm linear tear of the esophagus at 30 to 32 cm. The patient's hematocrit was stable and he was given no further intervention. The patient attempted a gastrografin swallow on the 21st, but was unable to cooperate with probable aspiration. The patient also had been receiving generous intravenous hydration during the period for which he was NPO for his esophageal tear and intravenous Lasix for a question of pulmonary congestion. On the morning of the 22nd the patient developed tachypnea with a chest X-ray showing a question of congestive heart failure. A medical consult was obtained at the Valtawnprinceel Community Memorial Hospital. The patient was given intravenous Lasix. Note: orange=demographics; blue=patient condition, diseases, etc.; red=procedures, tests; magenta=results of measurements; yellow=time In fact to give you a more quantitative version of this, Professor Solovitz and Dr. Katherine worked on a project in 2010 in which they tried to understand what are the genetic correlates of rheumatoid arthritis (RA). In order to do this, they went to Research Patient Data Repository (RPDR) of Massachusetts General and Brigham Partners Healthcare and tried to find the patients who had been billed for rheumatoid arthritis. Naturally, there were thousands of those patients who had been billed for RA. So, they selected a random subset of those patients and gave their records to dermatologists to find out which of those patients actually had rheumatoid arthritis. They found out that the positive predictive value of having a billing code for RA 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 1\", 'Biologic Function Physiologic Pathologic Function Function Organism Organ or Cell Molecular Cell or Disease or Experimental Function Tissue Function Function Molecular Syndrome model Function Dysfunction of Disease Mental Genetic Mental or Neoplastic Process Function Behavioral Process Dysfunction Courtesy of National Library of Medicine. Image is in the public domain. Figure 7: Hierarchy of UMLS Semantic Network Types and Relations. something to get the concept, semantic type etc. In the next lecture, Professor Solovitz will discuss the advanced machine learning approaches for natural language processing, some of which are based on neural network representations. References [1] Zeng QT, Goryachev S, Weiss S, Sordo M, Murphy SN, Lazarus R. Extracting principal diagnosis, co- morbidity and smoking status for asthma research: evaluation of a natural language processing system. BMC Med Inform Decis Mak 2006;6:30. [2] Liao, K. P., Cai, T., Gainer, V., Goryachev, S., Zeng-Treitler, Q., Raychaudhuri, S., Szolovits, P., Churchill, S., Murphy, S., Kohane, I., Karlson, E., Plenge, R. (2010). Electronic medical records for discovery research in rheumatoid arthritis. Arthritis Care & Research, 62(8), 1120-1127. http://doi.org/10.1002/acr.20184 [3] Carroll, R. J., Thompson, W. K., Eyler, A. E., Mandelin, A. M., Cai, T., Zink, R. M., et al. (2012). Portability of an algorithm to identify rheumatoid arthritis in electronic health records. Journal of the American Medical Informatics Association, 19(e1), e162-9. http://doi.org/10.1136/amiajnl-2011-000583 [4] Frederick B. Thompson, \"English for the Computer.\" Proceedings of the Fall Joint Computer Conference (1966) pp. 349-356 [5] Walker, D. E., Hobbs, J. R., 1981. Natural Language Access to Medical Text*. (pp. 269-273). Presented at the Proc Annu Symp Comput Appl Med Care. [6] de Heaulme M, Tainturier C, Thomas D. [Computer treatment of medical reports: example of the \"Remde\" system (author\\'s transl)]. Nouv Presse Med. 1979 Oct 22;8(40):3223-6. French. PubMed PMID: 534182 [7] Chapman WW, Bridewell W, Hanbury P, Cooper GF, Buchanan BG. A simple algorithm for identifying negated findings and diseases in discharge summaries. J Biomed Inform. 2001 Oct;34(5):301-10. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 7'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the role of term spotting and negation handling in clinical NLP?', 'nlp')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the role of term spotting and negation handling in clinical NLP?', 'nlp')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the role of term spotting and negation handling in clinical NLP?', ['Phrase1 Phrase2 Mapping to marring Meaning1 Semantic relationship Meaning2 Figure 4: Proposed relationship between syntax and semantics. relationship between them, then each phrase can be mapped to their meanings and the semantic relationship between those two meanings is determined by the syntactic relationship in the language. Dr. Thompson built computer systems that tried to follow this method and these systems were able to help researchers who worked in areas such as anthropology, where you don\\'t have codified data and a lot of the information is in the form of narrative text. In 1980, Stanford Research Institute built a system called (\"DIAMOND/DIAGRAM\", which intended to help people interact with computer systems when they didn\\'t know command language. So, the people expressed something in english, which got translated to some semantic representation and that was used by the computer. This idea was applied by Walker and Hobbs to natural language access to medical text and they built a system that essentially translated english into some formal representation and process it [5]. The original \"DIAMOND/DIAGRAM\" system had a very rigid syntax and relied on adaptation of humans. The most radical version of this by the name \"French Remede system\" was implemented and tested in a medieval hospital in Paris, where an artificial language was developed to take notes about cardiac patients instead of writing them in French [6]. However, it was quickly discarded as doctors reported that the language was not expressive enough. 5 Term spotting and handling negation, uncertainty Traditionally, term-spotting is done by hand-crafting a list of all the terms that might appear in the note that could be indicative of some condition by a medical practitioner and then the notes are searched through for those terms by the researcher. More sophisticated techniques would use algorithms such as NegEx, which is a negation expression detector, that gets rid of things which not true. This led to more sophisticated machine learning algorithms which aimed to automatically augment the hand-crafted list to create a more indicative list of terms. For negation, Chapman described a simple algorithm to identify negated findings [7], which found all the UMLS (discussed in next section) terms in each sentence of discharge summary and then searched for two kind of patterns. First pattern looked for a negation phrase such as \"no signs of\", \"ruled out unlikely\", \"absence of\" \"not demonstrated\", \"denies\", \"no sign of\", etc. followed within 5 words by UMLS terms. The second pattern looked for post modifiers such as \"declined\", \"unlikely\" etc. Furthermore, they hacked up a bunch of exceptions such as \"gram negative\", \"no further\", \"not able to be\", \"not certain if\" This algorithm, despite being incredibly simple, does reasonably well as shown in Fig. 5. Comparing with the baseline which looks for negation phrases which are immediately followed by a UMLS term, NegEx significantly improves the specificity from 52.69% to 82.50%. Generalization is done by taking advantage of related terms, for instance hypo- and hyper-. You could also employ associative reasoning; for example, if you see a lot of symptoms in the clinical text of a particular condition, then the disease is likely to be present as well. The recursive machine learning problem is how best to identify things associated with the term, which is known as \"phenotyping\". 6.S897/HST.956 Machine Learning for Healthcare - Lec7 5', \"6.S897/HST.956 Machine Learning for Healthcare Lecture 7: Natural Language Processing (NLP) Instructors: David Sontag, Peter Szolovits 1 Outline This lecture and the next covers the role of Natural Language Processing in machine learning in healthcare. The two lectures in succession first cover methods, which are not based on neural networks representations and then discusses techniques which employ neural network architectures. We begin by first motivating why we care about clinical text. Later, we discuss some conceptually very appealing, but practically infeasible methods that involve analyzing the narrative texts as linguistic entities in a way that a linguistic might approach them. Next, we discuss what is actually often done e.g. a term spotting approach that says that we might not be able to understand everything that goes on in the narratives, but we can identify certain words/phrases that are highly indicative of whether a certain patient has a certain disease, or a symptom or a medical procedure that was done to them. This is the bread and butter of how clinical research is done nowadays. 2 Value of the data in clinical text Let's see an example of a discharge summary from MIMIC dataset. The text has been de-identified in the dataset. We know that in MIMIC dataset, we see astericks in places of names, dates, locations etc. Here those entities have been replaced with synthetics names, dates, locations etc. to make it look like a piece that reads like a real text. We want to take advantage of these clinical notes because they carry important information about what happened to the patient over the course of their stay at the hospital. Mr. Blind is a 79-year-old white male with a history of diabetes mellitus, inferior myocardial infarction, who underwent open repair of his increased diverticulum November 13th at Sephsand- pot Center. The patient developed hematemesis November 15th and was intubated for respiratory distress. He was transferred to the Valtawnprinceel Community Memorial Hospital for endoscopy and esophagoscopy on the 16th of November which showed a 2 cm linear tear of the esophagus at 30 to 32 cm. The patient's hematocrit was stable and he was given no further intervention. The patient attempted a gastrografin swallow on the 21st, but was unable to cooperate with probable aspiration. The patient also had been receiving generous intravenous hydration during the period for which he was NPO for his esophageal tear and intravenous Lasix for a question of pulmonary congestion. On the morning of the 22nd the patient developed tachypnea with a chest X-ray showing a question of congestive heart failure. A medical consult was obtained at the Valtawnprinceel Community Memorial Hospital. The patient was given intravenous Lasix. Note: orange=demographics; blue=patient condition, diseases, etc.; red=procedures, tests; magenta=results of measurements; yellow=time In fact to give you a more quantitative version of this, Professor Solovitz and Dr. Katherine worked on a project in 2010 in which they tried to understand what are the genetic correlates of rheumatoid arthritis (RA). In order to do this, they went to Research Patient Data Repository (RPDR) of Massachusetts General and Brigham Partners Healthcare and tried to find the patients who had been billed for rheumatoid arthritis. Naturally, there were thousands of those patients who had been billed for RA. So, they selected a random subset of those patients and gave their records to dermatologists to find out which of those patients actually had rheumatoid arthritis. They found out that the positive predictive value of having a billing code for RA 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 1\", 'Baseline NegEx Group 1 Group 2 Group Group 2 sentences due sentences (Le., contences (Le contenced (i.e., containing not containing contences containing not containing AA contences NegEx NegEx NegEX NegEx negation negation negation negation phrases) physion presson) phrases) 0 500 500 1000 500 500 1000 Sensitivity 88.27 0,00 88.27 82,31 0.00 77.84 Specificity 52,69 100.00 85,27 82.50 100.00 94.51 PPV 68.42 - 68:42 84.49 - 84.49 NRV 79,46 96.99 93.01 80.21 96.99 91.73 Figure 5: NegEx Results. 6 Unified Medical Language System (UMLS) In 1985, National Library of Medicine made a huge effort to create UMLS; this was an attempt to take all of the terminologies that various medical societies had developed and unify them into what they termed as \"meta-thesaurus\". They also dedicated huge amount of human and machine resources to identify cases in which two different expressions from different terminologies meant the same thing. For instance, heart attack, myocardial infarction, and acute myocardial infarction mean the same. They used the resources to scour the databases and come up with a mapping of each of these terms to a single concept. This is an enormous help to normalize databases that come from different places and are described differently. It also gives you, in the context of natural language processing, a treasure trove of ways of expressing the same conceptual idea and it gives you ways to expand the kind of expressions that you are looking for. There are about 3.7 million concepts in this meta-thesaurus, each of which is assigned a concept unique identifier (CUI). There are also hierarchies and relationships that are imported from all of these different sources of terminology; though these are a jumbled mess. They also created a semantic network of 54 relations and 127 types. Every CUI is assigned at least one semantic type. Examples of UMLS concepts of various types are shown in Fig. 6. The types are hierarchically organized: an example is shown in Fig. 7 There are also tools that deal with some simplistic linguistic problems. For example, \"lead\", \"leads\", and \"leading\" are the same concept. So, there are Lexical Variation Generation (LVG) tools that help you normalize this sort of problem. Similarly, there is a normalization function that helps you normalize sentences into lower-case alphabetized version of the text, e.g. \"Mr. Huntington was admitted to Huntington Memorial Hospital for acute chest pain in March\" is normalized to \"acute admit be chest hospital huntington huntington march memorial mr pain\". Then, text can translated into other potential linguistic meanings of that text. There is also an online tool available through UMLS Terminology Services, where you can type ayagia select c from mrsty group by aty select From azoonao e 2010 araty a on order by c desc) where and c.GtT-IPF\\' and c.ISPAST= and c.LAT=TEN and tai= T0471 tui aty e cal ALT 1062 Therapestic or Preventive Procedure 260914 2033 Finding 233579 C0000744 Abetalipoproteinemia T200 Clinical Drug 172069 C0000174 Gastrin secretion obnormality NOS T109 Organic Chemical 157501 C0000386 Spontaneous abortion T121 Pharmacologic Substance 124644 C0000809 Abortion, Habitual 7116 Amino Acid, Peptide, or Protein 117508 C0000814 Missed abortion TOOM Invertebrate 111044 C0000821 Threatened abortion TOOD Bacterium 110065 C0000022 Abortion, Tube) T002 Plant 95017 C0000823 Abortion, Veterinary 2047 Disesse or Syndrome 29370 C0000832 Abruptio Placentac 7023 Body Part. Organ. or Organ Componént 73402 00000000 Acanthamoeba Keratitis 2201 Clinical Astribute 69998 00000099 Acantbosis Nigricana 7123 BioLogically Active Substance 55741 00001080 Achondroplasia T074 Medical Devion 51708 C0001083 Achromis parasitica 7020 Gene or Genone 49960 C0001125 Acidosis, Lactic Figure 6: Wealth of UMLS Concepts of Various Types. 6.S897/HST.956 Machine Learning for Healthcare - Lec7 - 6'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is risk stratification and why is it important in healthcare?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is risk stratification and why is it important in healthcare?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is risk stratification and why is it important in healthcare?', [\"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\", '3 Interview with Leonard D\\'Avolio 3.1 Introduction Leonard D\\'Avolio is an Assistant Professor at Harvard Medical School and the CEO and founder of Cyft. He spent the last 15 years \"trying to help healthcare learn from its data in new ways\" for governments, academia, researchers, publishing papers and nonprofits. Things D\\'Avolio worked on included Working with the Department of Veterans Affairs to build out their genomic science infrastructure and recruiting and enrolling millions of veterans to donate blood. Working at Ariadne Labs in improving neonatal care in India. 3.2 Interview Q: What is risk stratification to you? Risk stratification depends entirely on the problem. Risk could be: Running out of medical supply in an operating room The Apgar score A patient going from pre-diabetic to diabetic An older person falling down in their home Risk startification is a set of wonderful tools with which skilled craftsmen can go ahead to solve specific problems. Q: What are some of the areas that Cyft is applying today? What we do is essentially performance improvement; more specifically, the performance in keeping peo- ple out of the hospital. The most logical application for these technologies is to help do preventative things, but only between 8-12% of healthcare is financially incentivized for that. As a company, you focus on where there\\'s a financial incentive. I wanted to build a company where the financial incentives aligned with keeping people healthy. We focus on older populations where it is important to understand who care managers should approach because their risk levels are rising. The traditional approach of risk stratification identifies people that are already at their most acute. We try to help care management organizations find people that are rising risks and bring a more granular approach to healthcare. The power of these technologies is to move away from one-size-fits-all. Examples of what Cyft does includes: Tackling rising risk of an inpatient psychiatric admission Predicting which older people are likely to fall down Finding which children with Type 1 diabetes should be scheduled an appointment now rather than every 3 months The theme of the above examples is helping organizations move away from rather generic decisions towards things that are more actionable. Q: What areas have you worked on the longest? 6.S897/HST.956 Machine Learning for Healthcare - Lec4 10', \"2 Case Study: Early Detection of Type 2 Diabetes 2.1 Background We now consider a case study: risk stratification for Type 2 diabetes. This problem is extremely important, as an estimated 25% of individuals with diabetes in the United States are still undiagnosed, and the number is similar in other countries worldwide. If we are able to discover undiagnosed individuals who currently have diabetes, or identify people who are at high risk of developing diabetes in the future, we can provide interventions that prevent their condition from worsening, such as weight loss programs or first line diabetic treatments. In this section, we discuss the problem of identifying the population of individuals at high-risk of diabetes using machine learning algorithms. Traditional approaches to this problem include point-based metrics similar to the APGAR score. The following image shows a sample questionnaire for evaluating diabetes risk in Finland, which produces a single score quantifying an individual's likelihood of developing diabetes. Finniah Diabetes Association TYPE 2 DIABETES RISK ASSESSMENT FORM Orde add - - point 5. Item yes #### Salar for High blood I us register bent 9a 2g , INTERT bision glucsse a health than M lgw 2g. 5p Ban d. family with 1s - More than fa 30 x gaidparent aunt, under or fen cause the de par parent, bother gitter did 50 paint Sential in DATE est Total Ruit Score the Lower in 100 daily at least 20 - 2-11 who leisure Highly deing N25 daily activity() 12-14 attenuted 1 as © Finnish Diabetes Association. All rights 0-25 1 reserved. This content is excluded from after our Creative Commons license. For more Night Very lp two for than 20 Not information, see https://ocw.mit.edu/ every help/faq-fair-use/ Figure 5: Questionnaire for Diabetes Risk Assessment Unfortunately, these simpler methods have not had much impact and have not been widely used. Automation of the risk stratification process would allow us to avoid these types of manual questionnaires and lead to wider adoption. Instead of evaluating risk for every individual separately, an alternative option is to use machine learning models - trained on data from a health insurance company or other sources - that automatically identify the subpopulation at high risk of developing diabetes out of millions of individuals. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 5\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', [\"1.4 Old VS. New 1.4.1 Traditional Approaches APGAR SCORING SYSTEM Points 0 Points 1 Point 2 Points totaled Activity Arma and legs Active Absent (muscle tone) flexed movement Pulse Absent Belins 100 lipm Over 100 Ligan Active motion Grimace Flaccid Some flexion of innecer, cough (reflex irritability) Extremities pndl away Appearance Blue. pale Body pinku Completely (skin color) Extremities blue pink Respiration Absent Slow, irregular Vigorous oy Severely depressed 0-3 Moderately depressed 4-6 Excellent condition 7-10 © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 2: Chart of the Apgar scoring system used to predict infant morbidity. Traditional approaches to risk stratification are based on scoring systems. The Apgar score, shown in Fig- ure 2, is one such system [Apg66]. It is based on different criteria, with each answer having a specific point value. After answering, one adds up the points to obtain the risk-level score. There are hundreds of such scoring rules that are carefully derived through studies and are widely used in today's healthcare system. 1.4.2 Machine Learning-based Approaches Now, most of industry is moving towards machine learning based methods that can work with a much higher dimensional set of features and solve a number of key challenges of these early approaches. Machine learning based approaches can: Fit more easily into clinical workflows. Scores from traditional approaches are often done manually. One has to figure out the corresponding inputs, SO it is often not used as frequently. Be much quicker to derive. Traditional scoring systems have a very long research and development process that led to their adoption. With machine learning based approaches, given enough data or access to data, one can predict narrow outcomes or conditions that may occur infrequently. Lead to higher accuracy. However, these new ML approaches also introduce new dangers. This will be discussed more in future lectures. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 3\", \"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\", \"2 Case Study: Early Detection of Type 2 Diabetes 2.1 Background We now consider a case study: risk stratification for Type 2 diabetes. This problem is extremely important, as an estimated 25% of individuals with diabetes in the United States are still undiagnosed, and the number is similar in other countries worldwide. If we are able to discover undiagnosed individuals who currently have diabetes, or identify people who are at high risk of developing diabetes in the future, we can provide interventions that prevent their condition from worsening, such as weight loss programs or first line diabetic treatments. In this section, we discuss the problem of identifying the population of individuals at high-risk of diabetes using machine learning algorithms. Traditional approaches to this problem include point-based metrics similar to the APGAR score. The following image shows a sample questionnaire for evaluating diabetes risk in Finland, which produces a single score quantifying an individual's likelihood of developing diabetes. Finniah Diabetes Association TYPE 2 DIABETES RISK ASSESSMENT FORM Orde add - - point 5. Item yes #### Salar for High blood I us register bent 9a 2g , INTERT bision glucsse a health than M lgw 2g. 5p Ban d. family with 1s - More than fa 30 x gaidparent aunt, under or fen cause the de par parent, bother gitter did 50 paint Sential in DATE est Total Ruit Score the Lower in 100 daily at least 20 - 2-11 who leisure Highly deing N25 daily activity() 12-14 attenuted 1 as © Finnish Diabetes Association. All rights 0-25 1 reserved. This content is excluded from after our Creative Commons license. For more Night Very lp two for than 20 Not information, see https://ocw.mit.edu/ every help/faq-fair-use/ Figure 5: Questionnaire for Diabetes Risk Assessment Unfortunately, these simpler methods have not had much impact and have not been widely used. Automation of the risk stratification process would allow us to avoid these types of manual questionnaires and lead to wider adoption. Instead of evaluating risk for every individual separately, an alternative option is to use machine learning models - trained on data from a health insurance company or other sources - that automatically identify the subpopulation at high risk of developing diabetes out of millions of individuals. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 5\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How is label leakage managed in diabetes prediction models?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How is label leakage managed in diabetes prediction models?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How is label leakage managed in diabetes prediction models?', ['a patient\\'s likelihood of developing diabetes at some time period in the \"future\" (after 1/1/2009). Three different prediction tasks were considered, using different gaps between the data collection and prediction windows, shown in Figure 8: Prediction Window 2000-2011 Construction 2009 2010 2011 2012 2013 Firmith Prediction Window 2010 Construction 2012 2009 2010 2011 2012 2013 Frature Prediction Window 2114 Construction 2012 2009 2010 2011 2012 2013 Figure 8: Prediction Tasks In each case, we exclude patients who develop diabetes before the start of the prediction window. For in- stance, in the task with the 1-year gap, we exclude any patients diagnosed with diabetes prior to 1/1/2010. One reason for including this gap is label leakage. In certain situations, it is possible that a doctor is very certain that a patient has diabetes, even though this has not been explicitly coded in a way that our algorithms can detect. The doctor may already be doing interventions based on this \"pre-diagnosis\". The models will pick up on these signals and predict that this patient is very likely to develop diabetes. However, such a prediction is not very interesting, as the doctor has already identified the patient as being at high-risk for diabetes and is carrying out appropriate interventions. Instead, our models should be able to identify patients at high risk that the doctor may not expect. Another issue is data censoring. For example, a patient may have only enrolled with an insurer in 2012, SO they will have no data prior to 2009, and our models will not be able to construct any features for these individuals. There are two types of censoring that are handled: Left Censoring: Patient data absent prior to some point in time Right Censoring: Patient data absent after some point in time For patients with left-censoring, the models attempt to construct as many features as possible; patients with less data simple have sparser feature vectors. Right-censored patients are dropped from the dataset if data in the full relevant prediction window is unavailable. This simple exclusion criteria can be problematic in some cases. For instance, a patient may have switched insurers as a result of their diabetes diagnosis at some point in the prediction window, leaving them with no data after that time. Thus, we may actually be excluding patients who would benefit from our model\\'s predictions and biasing the model\\'s results. In the next lecture, we will discuss alternative approaches for handling right-censoring. For the rest of this section, we focus on the prediction task corresponding to the 1-year gap. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 7', \"Top History of Disease Odds Ratio 4,17 Impaired Fasting Glucose (Code 790.21) (3.87 4.49) 4.07 Abnormal Glucose NEC (790.29) (3,76 4,41) 3.28 Hypertension (401) (3,17 3.39) 2.98 Constructive Sleep Aprica (327,23) (2.78.320) 2.88 Obesity (278) (2.75 3.02) 2.49 Abnormal Blood Chemistry (790.6) (2.36 2.62) 2.45 Hyperlipidemia (272,4) (2.37 2.53) 2.09 Shodness Of Breath (788.05) (1.99.2.19) 185 Esophageal Reflux (530.81) (1178 1.03) Figure 9: Most Predictive Disease Features The criteria used to evaluate risk stratification models are slightly different from standard diagnosis criteria. One common metric is the model's positive predictive value (PPV). In this case study, this metric corresponds to the proportion of predicted high-risk patients who actually went on to develop diabetes in the prediction window. The results for these particular models are shown in Figure 10, compared with a simpler model that did not perform as well. Traditional risk factors Full model 0.17 0.15 0.1 0.07 0.06 0.06 Top 100 Predictions Top 1000 Predictions Top 10000 Predictions Diabetes 1-year gap Figure 10: Positive Predictive Value (PPV) of Models for Different Groups We evaluate this metric at different levels: for the top 100, top 1000, and top 10000 most risky patients. We can observe that 15% of the top 100 and 10% of the 10000 riskiest patients go on to develop diabetes. By performing these separate analyses, one could target different interventions for patients at different risk levels. Cheap interventions (i.e, an eye checkup for diabetic retinopathy) could be recommended for the top 10,000 riskiest patients. On the other hand, a more expensive intervention could not be implemented at such a large scale, and it may only be recommended for the 100 riskiest patients. 6.S897/HST.956 Machine Learning for Healthcare - Lec4-9\", \"Q: Can we use a data-driven approach to figure out what types of data we want to acquire? A: It's easy to bring in new data, but the hard part is deciding whether new data actually contains added value. The data usually just doesn't tell you that you should go out and get a different type of data. If model performance is low, then we'll try to go out and find data with information that we think may boost the performance. Q: How much impact do interventions have based on the predictions made by the model? A: No customer ever pays you for a good positive predictive value; they only care about saving or making money. We show clients how much money they would save for a particular level of improvement, then relate that to the performance of our models. We don't show clients the predictions of our models; we show them the financial impact of our models and whether it was able to make a difference. References [Apg66] Virginia Apgar. The newborn (apgar) scoring system. Pediatr Clin North Am, 13(3):645-50, 1966. [Opt14] Optum. Predictive analytics: Poised to drive population health. [PDS+84] Michael W Pozen, Ralph B D'Agostino, Harry P Selker, Pamela A Sytkowski, and William B Hood Jr. A predictive instrument to improve coronary-care-unit admission practices in acute ischemic heart disease: a prospective multicenter clinical trial. New England Journal of Medicine, 310(20):1273-1278, 1984. [RBS+15] Narges Razavian, Saul Blecker, Ann Marie Schmidt, Aaron Smith-McLallen, Somesh Nigam, and David Sontag. Population-level prediction of type 2 diabetes from claims data and analysis of risk factors. Big Data, 3(4):277-287, 2015. [SRG+10] Suchi Saria, Anand K Rajani, Jeffrey Gould, Daphne Koller, and Anna A Penn. Integration of early physiological responses predicts later illness severity in preterm infants. Science translational medicine, 2(48):48ra65-48ra65, 2010. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 13\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What types of data are used in risk stratification for diabetes?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What types of data are used in risk stratification for diabetes?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What types of data are used in risk stratification for diabetes?', [\"2 Case Study: Early Detection of Type 2 Diabetes 2.1 Background We now consider a case study: risk stratification for Type 2 diabetes. This problem is extremely important, as an estimated 25% of individuals with diabetes in the United States are still undiagnosed, and the number is similar in other countries worldwide. If we are able to discover undiagnosed individuals who currently have diabetes, or identify people who are at high risk of developing diabetes in the future, we can provide interventions that prevent their condition from worsening, such as weight loss programs or first line diabetic treatments. In this section, we discuss the problem of identifying the population of individuals at high-risk of diabetes using machine learning algorithms. Traditional approaches to this problem include point-based metrics similar to the APGAR score. The following image shows a sample questionnaire for evaluating diabetes risk in Finland, which produces a single score quantifying an individual's likelihood of developing diabetes. Finniah Diabetes Association TYPE 2 DIABETES RISK ASSESSMENT FORM Orde add - - point 5. Item yes #### Salar for High blood I us register bent 9a 2g , INTERT bision glucsse a health than M lgw 2g. 5p Ban d. family with 1s - More than fa 30 x gaidparent aunt, under or fen cause the de par parent, bother gitter did 50 paint Sential in DATE est Total Ruit Score the Lower in 100 daily at least 20 - 2-11 who leisure Highly deing N25 daily activity() 12-14 attenuted 1 as © Finnish Diabetes Association. All rights 0-25 1 reserved. This content is excluded from after our Creative Commons license. For more Night Very lp two for than 20 Not information, see https://ocw.mit.edu/ every help/faq-fair-use/ Figure 5: Questionnaire for Diabetes Risk Assessment Unfortunately, these simpler methods have not had much impact and have not been widely used. Automation of the risk stratification process would allow us to avoid these types of manual questionnaires and lead to wider adoption. Instead of evaluating risk for every individual separately, an alternative option is to use machine learning models - trained on data from a health insurance company or other sources - that automatically identify the subpopulation at high risk of developing diabetes out of millions of individuals. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 5\", \"Top History of Disease Odds Ratio 4,17 Impaired Fasting Glucose (Code 790.21) (3.87 4.49) 4.07 Abnormal Glucose NEC (790.29) (3,76 4,41) 3.28 Hypertension (401) (3,17 3.39) 2.98 Constructive Sleep Aprica (327,23) (2.78.320) 2.88 Obesity (278) (2.75 3.02) 2.49 Abnormal Blood Chemistry (790.6) (2.36 2.62) 2.45 Hyperlipidemia (272,4) (2.37 2.53) 2.09 Shodness Of Breath (788.05) (1.99.2.19) 185 Esophageal Reflux (530.81) (1178 1.03) Figure 9: Most Predictive Disease Features The criteria used to evaluate risk stratification models are slightly different from standard diagnosis criteria. One common metric is the model's positive predictive value (PPV). In this case study, this metric corresponds to the proportion of predicted high-risk patients who actually went on to develop diabetes in the prediction window. The results for these particular models are shown in Figure 10, compared with a simpler model that did not perform as well. Traditional risk factors Full model 0.17 0.15 0.1 0.07 0.06 0.06 Top 100 Predictions Top 1000 Predictions Top 10000 Predictions Diabetes 1-year gap Figure 10: Positive Predictive Value (PPV) of Models for Different Groups We evaluate this metric at different levels: for the top 100, top 1000, and top 10000 most risky patients. We can observe that 15% of the top 100 and 10% of the 10000 riskiest patients go on to develop diabetes. By performing these separate analyses, one could target different interventions for patients at different risk levels. Cheap interventions (i.e, an eye checkup for diabetic retinopathy) could be recommended for the top 10,000 riskiest patients. On the other hand, a more expensive intervention could not be implemented at such a large scale, and it may only be recommended for the 100 riskiest patients. 6.S897/HST.956 Machine Learning for Healthcare - Lec4-9\", \"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Why is L1 regularization used in logistic regression for risk stratification?', 'risk_stratification')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Why is L1 regularization used in logistic regression for risk stratification?', 'risk_stratification')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'Why is L1 regularization used in logistic regression for risk stratification?', ['2.4 Model Overview Logistic regression with L1 regularization is used for this task. L1 regularization is useful because it encour- ages sparsity in the feature weights of the trained model, which has multiple benefits: 1. Prevents overfitting in settings with a good risk model containing a small number of features. 2. Improves interpretability. Can potentially enumerate all non-zero features to better understand how the model makes predictions. 3. Improves translatability. If a model has only a small number of features, it is more likely that data needed for the models can be found at many hospitals, allowing the same model to be used more widely. The cost function for such a model is of the form: where l is any loss function, W are the weights of the model, and 11/w/1 is the L1-norm of the weight vector. 2.5 Features Features were designed to account for the large amount of missing data in the records for most patients. In- stead of choosing features in a way that would potentially require the imputation of many values, the models use several binary features indicating whether a particular observation was ever made for an individual in their records. For instance, there are features for each type of specialist a patient could have visited. The correspond- ing feature value is \"1\" if the patient ever visited a particular type of specialist and \"0\" otherwise. Similar features are constructed for the most common medications (\"1\" if a person has ever taken, \"0\" otherwise). A slightly different approach is used for featurizing lab test results. In addition to features indicating whether a patient ever took a particular lab test, there are features for each of the following: Is lab test result high/low/normal? Is result increasing/decreasing? Is result fluctuating? If a patient had never been given a particular lab test, all the corresponding feature values would be 0. As constructed here, all these features are very simple. One could potentially use recurrent neural networks or other models to automatically learn features about the time series data present in lab test results. We will discuss more complex feature construction techniques in future lectures. Each of these features are then computed for different time windows: the last 6 months, the last 24 months, and all of a patient\\'s past history. In the end, a patient\\'s feature vector consists of approximately 42,000 elements. 2.6 Model Evaluation We first examine some of the features that were determined to be most predictive in the trained model. The top feature is found to be a diagnosis of \"Impaired Fasting Glucose\". While one may think that such a diagnosis would indicate that a patient has already been diagnosed as diabetic, these could also correspond to pre-diabetic patients in the dataset who are not guaranteed to develop diabetes. Other top features are shown in Figure 9. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 - 8', \"6.S897/HST.956 Machine Learning for Healthcare Lecture 4: Risk stratification Using EHRs and Insurance Claims Instructors: David Sontag, Peter Szolovits 1 Risk Stratification 1.1 What Is It? At a high level, risk stratification is way of separating a patient population into one of 2+ categories (e.g. separating into patients with high-risk, low-risk or in-between). The reason for risk stratification is to act on these predictions and couple those predictions with known interventions. For patients in the high risk pool, we would attempt to do something for them to prevent whatever outcome is of interest from occurring. Risk stratification is quite different from diagnosis. Diagnosis has a highly stringent criteria on per- formance. A misdiagnosis could lead to severe consequences like the patients being treated for conditions that they don't have, or patients dying because they were not diagnosed in time. The performance char- acteristics of risk stratification are different, instead looking at quantities such as positive predictive value (PPV). In today's economic environment, the goal of risk stratification is reducing cost in the healthcare setting and improving patient outcomes. Definition 1 (Positive predictive value or PPV). Fraction of patients that were predicted to be high risk and are actually high risk. Data used for risk stratification is often different from diagnosis and very diverse. Things you might use include multiple views of the patient or auxiliary data such the patient's demographics or socioeconomic information that would highly affect their risk profile but unused in an unbiased diagnosis of the patient. 1.2 Examples 1.2.1 Predicting preterm infant's risk of severe morbidity The outcomes of premature babies have dramatically improved over the last century. Of the many different interventions that led to this improvement, one of them was having a very good understanding of a particular infant's risk level. A very common score that is used to try to characterize risk for premature infant is the Apgar score [Apg66], but this metric is not as accurate as it could be. Saria et. al uses a machine learning approach to really improve our ability to predict morbidity in infants [SRG+10]. 1.2.2 Predicting if patient needs to be admitted to coronary-care unit (CCU) For patients who coming into the ER with a heart-related condition, the question is: should they be admitted to the CCU, or is it safe for them to be discharged and managed by their physician or cardiologist outside the hospital? A study was performed in 1984 using over 2000 patients, nontrivial amount of variables and logistic regression to predict such cases [PDS+84] The goal was cost-oriented, as identifying patients who are not high-risk and don't have to be admitted to the CCU leads to reduction in the costs associated with CCU admissions. 6.S897/HST.956 Machine Learning for Healthcare - Lec4 1\", \"Top History of Disease Odds Ratio 4,17 Impaired Fasting Glucose (Code 790.21) (3.87 4.49) 4.07 Abnormal Glucose NEC (790.29) (3,76 4,41) 3.28 Hypertension (401) (3,17 3.39) 2.98 Constructive Sleep Aprica (327,23) (2.78.320) 2.88 Obesity (278) (2.75 3.02) 2.49 Abnormal Blood Chemistry (790.6) (2.36 2.62) 2.45 Hyperlipidemia (272,4) (2.37 2.53) 2.09 Shodness Of Breath (788.05) (1.99.2.19) 185 Esophageal Reflux (530.81) (1178 1.03) Figure 9: Most Predictive Disease Features The criteria used to evaluate risk stratification models are slightly different from standard diagnosis criteria. One common metric is the model's positive predictive value (PPV). In this case study, this metric corresponds to the proportion of predicted high-risk patients who actually went on to develop diabetes in the prediction window. The results for these particular models are shown in Figure 10, compared with a simpler model that did not perform as well. Traditional risk factors Full model 0.17 0.15 0.1 0.07 0.06 0.06 Top 100 Predictions Top 1000 Predictions Top 10000 Predictions Diabetes 1-year gap Figure 10: Positive Predictive Value (PPV) of Models for Different Groups We evaluate this metric at different levels: for the top 100, top 1000, and top 10000 most risky patients. We can observe that 15% of the top 100 and 10% of the 10000 riskiest patients go on to develop diabetes. By performing these separate analyses, one could target different interventions for patients at different risk levels. Cheap interventions (i.e, an eye checkup for diabetic retinopathy) could be recommended for the top 10,000 riskiest patients. On the other hand, a more expensive intervention could not be implemented at such a large scale, and it may only be recommended for the 100 riskiest patients. 6.S897/HST.956 Machine Learning for Healthcare - Lec4-9\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is MYCIN and why was it never used in practice?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is MYCIN and why was it never used in practice?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What is MYCIN and why was it never used in practice?', ['6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1', 'to those challenges, patient data is particularly sensitive, SO de-identification is necessary and negotiating data sharing agreements is time-consuming. Due to the complexity of the healthcare system, there is often missing data and different training data VS testing data distributions. Production EHR systems might be difficult to work with, as each commercial system is slightly different. 5 Overview of course syllabus The goals for this class are to provide intuition for healthcare data and machine learning algorithms along with understanding of the subtleties in applying these methods to the real world and challenges for future research. References [Blu19] Robert Blum. RX Project Notes. https://www.bobblum.com/ESSAYS/COMPSCI/rx-project. html, 2019. [Online; accessed 05-February-2019 [Mil10] RA Miller. A history of the internist-1 and quick medical reference (qmr) computer-assisted diagnosis projects, with lessons learned. Yearbook of medical informatics, 19(01):121-136, 2010. [PF96] Will Penny and David Frost. Neural networks in clinical medicine. Medical Decision Making, 16(4):386-398, 1996. [RIZ+17] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv: 1711.05225, 2017. [SA75] Edward H Shortliffe and Stanton G Axline. Computer-based consultations in clinical therapeutics: Explanation and rule acquisition capabilities of the mycin. 1975. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 6', 'KNOWLEDGE FROM MEDICAL LITERATURE SUBSET OF DATABASE KNOWLEDGE BASE STATISTICAL PACKAGE DISCOVERY MODULE STUDY MODULE HYPOTHESIS MEDICAL ENTIRE RESEARCHER DATABASE © Robert Blum. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 1: The RX Cycle 2 Why apply machine learning to healthcare today? From the previous examples, it is clear that researchers have tried to develop computational tools for health- care with relatively little success for 40+ years. Many have found new hope for AI in healthcare because of recent widespread EHR adoption, publicly available datasets, standardization of medical codes, and break- throughs in machine learning. 2.1 EHR Adoption In the last decade, health records transitioned from mostly on paper to mostly electronic. The shift to EHR has been swift, increasing by 9x since 2008, growing from 9.4% of hospitals to nearly 84% See Figure 3 for the adoption trend from 2008 to 2015. This highlights a theme for the rest of the course: that new policy can open the door to innovation. 2.2 Data New medical datasets are now publicly available. Mimic, the only publicly available EHR dataset, was created out of MIT, consisting of intensive care unit patient records. From the MIMIC Physiotnet website, \"MIMIC is an openly available dataset developed by the MIT Lab for Computational Physiology, comprising de-identified health data associated with 40,000 critical care patients. It includes demographics, vital signs, laboratory tests, medications, and more.\" Chexpert, a large publicly available image dataset, was created in collaboration between Stanford and MIT [RIZ+17]. From the Chexpert website, \"CheXpert is a large dataset of chest X-rays and competition for automated chest x-ray interpretation, which features uncertainty labels and radiologist-labeled reference standard evaluation sets.\" The Truven Marketscan data is not a publicly available dataset, but it\\'s available in this class and it\\'s useful because it has \"data on nearly 230 million unique patients since 1995.\" Here\\'s a link to the Marketscan website. Additionally new streams of data that are relevant to health have become available to researchers. Sources of new diverse data streams include: wearable devices, phones, social media, proteomics, and genomics. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 2'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', ['KNOWLEDGE FROM MEDICAL LITERATURE SUBSET OF DATABASE KNOWLEDGE BASE STATISTICAL PACKAGE DISCOVERY MODULE STUDY MODULE HYPOTHESIS MEDICAL ENTIRE RESEARCHER DATABASE © Robert Blum. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 1: The RX Cycle 2 Why apply machine learning to healthcare today? From the previous examples, it is clear that researchers have tried to develop computational tools for health- care with relatively little success for 40+ years. Many have found new hope for AI in healthcare because of recent widespread EHR adoption, publicly available datasets, standardization of medical codes, and break- throughs in machine learning. 2.1 EHR Adoption In the last decade, health records transitioned from mostly on paper to mostly electronic. The shift to EHR has been swift, increasing by 9x since 2008, growing from 9.4% of hospitals to nearly 84% See Figure 3 for the adoption trend from 2008 to 2015. This highlights a theme for the rest of the course: that new policy can open the door to innovation. 2.2 Data New medical datasets are now publicly available. Mimic, the only publicly available EHR dataset, was created out of MIT, consisting of intensive care unit patient records. From the MIMIC Physiotnet website, \"MIMIC is an openly available dataset developed by the MIT Lab for Computational Physiology, comprising de-identified health data associated with 40,000 critical care patients. It includes demographics, vital signs, laboratory tests, medications, and more.\" Chexpert, a large publicly available image dataset, was created in collaboration between Stanford and MIT [RIZ+17]. From the Chexpert website, \"CheXpert is a large dataset of chest X-rays and competition for automated chest x-ray interpretation, which features uncertainty labels and radiologist-labeled reference standard evaluation sets.\" The Truven Marketscan data is not a publicly available dataset, but it\\'s available in this class and it\\'s useful because it has \"data on nearly 230 million unique patients since 1995.\" Here\\'s a link to the Marketscan website. Additionally new streams of data that are relevant to health have become available to researchers. Sources of new diverse data streams include: wearable devices, phones, social media, proteomics, and genomics. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 2', '6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1', \"© source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Funura Regulation The stakeholders: (Gov't Employer's Gov't Individuals) Insurance Payment Coverage Reguration Taxes or Came and Premiums Bill Care/Hearth Services imavidun Patients (Consumer) Doctors) Direct Payment Figure 4: The healthcare system is comprised of several important pieces 3.1.2 Propagating best practices As medical knowledge becomes more specialized, it becomes important to find ways to share best practices. Professor Sontag believes this could be particularly useful in academic medical centers to aid in the training of new doctors and in less populated areas where doctors might need to cover a broader set of conditions. 3.2 Efficient healthcare workflows Machine learning can make many healthcare workflows more efficient. Image processing techniques for chest x-rays and EKGs could help reduce the number of specialist consults. On the administrative side, machine learning can be automate documentation and billing processes. Wearable devices allow for continuous moni- toring, potentially allowing for better management of chronic diseases. With more data, it would be possible to better understand chronic disease progression. Liquid biopsy could potentially lead to earlier diagnoses. 3.3 Facilitating discovery In addition to healthcare management, there are opportunities for data-driven methods to aid in discovery. Machine learning methods could help to identify disease subtypes, search for optimal molecular structures for binding sites, and facilitate new clinical trial designs. The promises of precision medicine become feasible when data is aggregated and analyzed efficiently at scale. 4 What is unique about machine learning for healthcare? Healthcare is different from other machine learning applications because the gravity of life and death decision- making. The algorithms need to be more robust than other common ML applications such as search or object recognition. There need to be deliberate checks and balances to the ML deployment with considerations for both fairness and accountability. Many questions in healthcare do not neatly align with the current advances in machine learning. Many healthcare problems are concerned with semi-supervised or unsupervised learning. Often in healthcare, it is important to identify causal relationships. In addition to the theoretical challenges, implementing data-driven systems has additional challenges in healthcare. It is already a challenge to integrate new technologies into industrial workflows. In addition 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 5\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How can machine learning transform emergency departments?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How can machine learning transform emergency departments?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'How can machine learning transform emergency departments?', [\"Figure 1: Percent of non-Federal acute care hospitals with adoption of at least a Basic EHR with notes system and possession of a certified EHR: 2008-2015 96% Certified EHR 85.2%* 96.9% 94%* 75.5%* 83.8%* 71.9% Basic EHR 59.4% 44,4%* 27.6% 15.6% 12.2% 9.4% 2008 2009 2010 2011 2012 2013 2014 2015 NOTE: Basic DIR adoption requires the EHR system to have a set of EHR functions defined in Table AL A certified EHR is EHR technology that meets the technological capability, functionality, and security requirements adopted by the Department of Health and Human Services. Possession means that the hospital has a legal agreement with the DHR vendor, but is not equivalent to adoption, *Significantly different from previous your (p=0.05). SOURCE: ONC/American Hospital Association (AMA). AHA Annual Survey Information Technology Supplement Courtesy of Health and Human Services. Image is in the public domain. Figure 3: The adoption of EHR by hospitals from 2008-2015. 3 Examples of machine learning applied to healthcare There are opportunities to transform every aspect of the healthcare system. Figure 4 shows some of the key components of the healthcare system and how they interact. In the United States, we have separated payors and providers along with government programs like Medicare and Medicaid, but the UK's National Health Service differs as a more integrated system across payors and providers. Understanding these systems, we can find opportunities to turn the right knobs to make an impact. 3.1 Imagining the emergency department of the future Professor Sontag has been working with Beth Israel Deaconess Medical Center to use technology in their Emergency Department. The ER is an interesting setting because it faces extreme constraints on a daily basis, these include: limited resources, time-sensitive needs, and critical life or death decisions. The following are some concrete examples of AI applications that aim to improve healthcare in both the short and long term. One of the themes of this course will be to highlight the high-value subtle interventions that AI can offer in the healthcare setting. 3.1.1 Behind-the-scenes reasoning about the patients conditions One of the most valuable resources in healthcare is time. Clinicians have many constraints on their time, making data collection less frequent and accurate. If features about patients can be automatically extracted from electronic medical records, then clinicians can spend more time treating patients. Extracting these features would allow for better triage, diagnosis, earlier detection of adverse events, and would likely prevent medical errors. Professor Sontag proposes a system that could predict the clincians needs, providing them with a list of treatment option lists. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 4\", '6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1', \"© source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Funura Regulation The stakeholders: (Gov't Employer's Gov't Individuals) Insurance Payment Coverage Reguration Taxes or Came and Premiums Bill Care/Hearth Services imavidun Patients (Consumer) Doctors) Direct Payment Figure 4: The healthcare system is comprised of several important pieces 3.1.2 Propagating best practices As medical knowledge becomes more specialized, it becomes important to find ways to share best practices. Professor Sontag believes this could be particularly useful in academic medical centers to aid in the training of new doctors and in less populated areas where doctors might need to cover a broader set of conditions. 3.2 Efficient healthcare workflows Machine learning can make many healthcare workflows more efficient. Image processing techniques for chest x-rays and EKGs could help reduce the number of specialist consults. On the administrative side, machine learning can be automate documentation and billing processes. Wearable devices allow for continuous moni- toring, potentially allowing for better management of chronic diseases. With more data, it would be possible to better understand chronic disease progression. Liquid biopsy could potentially lead to earlier diagnoses. 3.3 Facilitating discovery In addition to healthcare management, there are opportunities for data-driven methods to aid in discovery. Machine learning methods could help to identify disease subtypes, search for optimal molecular structures for binding sites, and facilitate new clinical trial designs. The promises of precision medicine become feasible when data is aggregated and analyzed efficiently at scale. 4 What is unique about machine learning for healthcare? Healthcare is different from other machine learning applications because the gravity of life and death decision- making. The algorithms need to be more robust than other common ML applications such as search or object recognition. There need to be deliberate checks and balances to the ML deployment with considerations for both fairness and accountability. Many questions in healthcare do not neatly align with the current advances in machine learning. Many healthcare problems are concerned with semi-supervised or unsupervised learning. Often in healthcare, it is important to identify causal relationships. In addition to the theoretical challenges, implementing data-driven systems has additional challenges in healthcare. It is already a challenge to integrate new technologies into industrial workflows. In addition 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 5\"])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some challenges unique to machine learning in healthcare?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some challenges unique to machine learning in healthcare?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some challenges unique to machine learning in healthcare?', ['6.S897/HST.956 Machine Learning for Healthcare Lecture 1: What makes healthcare unique? Instructors: David Sontag, Peter Szolovits The Problem Healthcare costs in the US amount to over $3 trillion and are rapidly rising. The US has some of the best clinicians in the world, but there are still many cases of chronic diseases being diagnosed too late and man- aged inappropriately. Medical errors are pervasive. The lecture covers 5 topics: 1. Brief history of AI applied to healthcare 2. Why now is the right time to apply machine learning to healthcare 3. Examples of how machine learning will transform healthcare 4. What is unique about ML in healthcare 5. Overview of class syllabus 1 History of artificial intelligence and healthcare AI has been applied to healthcare since the 1970s. 1.1 1970s - MYCIN MYCIN is a ruled-based, expert system that uses the clinical decision criteria of experts to advise physicians on the appropriate antimicrobial therapy for patients with bacterial infections [SA75]. MYCIN beat out human-experts on an acceptability of treatment evaluation, but it was never used in practice due to legal and ethical issues about using computers in medicine. 1.2 1980s - Internist-1/QMR Model and RX Project The Internist-1/QMR Model is a computer-assisted diagnostic tool based on 15 person-years of coding clinicopathological reports [Mil10]. The tool was never used in clinical practice. The main problems were that clinicians had to manually enter the patient symptoms into the system and that the system was difficult to maintain as medical knowledge evolved. The system could not generalize well across different populations. The RX Project is an AI designed for automated knowledge acquisition. Figure 1 displays the discovery system that combines empirical data with a knowledge base that combines with researchers to generate and evaluate hypotheses about causal relationships to create new knowledge that can then be combined with empirical data to refine and build a full knowledge base [Blu19]. 1.3 1990s - Neural Networks in Clinical Medicine Neural networks were applied to clinical medicine [PF96]. See examples in Figure 2. In the 1990s, researchers started to apply neural networks to clinical medicine but made limited progress because of the small number of inputs limited to data from chart reviews. Ultimately, the neural networks lacked sufficient training data, which led to bad generalization performance. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 1', \"© source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Funura Regulation The stakeholders: (Gov't Employer's Gov't Individuals) Insurance Payment Coverage Reguration Taxes or Came and Premiums Bill Care/Hearth Services imavidun Patients (Consumer) Doctors) Direct Payment Figure 4: The healthcare system is comprised of several important pieces 3.1.2 Propagating best practices As medical knowledge becomes more specialized, it becomes important to find ways to share best practices. Professor Sontag believes this could be particularly useful in academic medical centers to aid in the training of new doctors and in less populated areas where doctors might need to cover a broader set of conditions. 3.2 Efficient healthcare workflows Machine learning can make many healthcare workflows more efficient. Image processing techniques for chest x-rays and EKGs could help reduce the number of specialist consults. On the administrative side, machine learning can be automate documentation and billing processes. Wearable devices allow for continuous moni- toring, potentially allowing for better management of chronic diseases. With more data, it would be possible to better understand chronic disease progression. Liquid biopsy could potentially lead to earlier diagnoses. 3.3 Facilitating discovery In addition to healthcare management, there are opportunities for data-driven methods to aid in discovery. Machine learning methods could help to identify disease subtypes, search for optimal molecular structures for binding sites, and facilitate new clinical trial designs. The promises of precision medicine become feasible when data is aggregated and analyzed efficiently at scale. 4 What is unique about machine learning for healthcare? Healthcare is different from other machine learning applications because the gravity of life and death decision- making. The algorithms need to be more robust than other common ML applications such as search or object recognition. There need to be deliberate checks and balances to the ML deployment with considerations for both fairness and accountability. Many questions in healthcare do not neatly align with the current advances in machine learning. Many healthcare problems are concerned with semi-supervised or unsupervised learning. Often in healthcare, it is important to identify causal relationships. In addition to the theoretical challenges, implementing data-driven systems has additional challenges in healthcare. It is already a challenge to integrate new technologies into industrial workflows. In addition 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 5\", 'to those challenges, patient data is particularly sensitive, SO de-identification is necessary and negotiating data sharing agreements is time-consuming. Due to the complexity of the healthcare system, there is often missing data and different training data VS testing data distributions. Production EHR systems might be difficult to work with, as each commercial system is slightly different. 5 Overview of course syllabus The goals for this class are to provide intuition for healthcare data and machine learning algorithms along with understanding of the subtleties in applying these methods to the real world and challenges for future research. References [Blu19] Robert Blum. RX Project Notes. https://www.bobblum.com/ESSAYS/COMPSCI/rx-project. html, 2019. [Online; accessed 05-February-2019 [Mil10] RA Miller. A history of the internist-1 and quick medical reference (qmr) computer-assisted diagnosis projects, with lessons learned. Yearbook of medical informatics, 19(01):121-136, 2010. [PF96] Will Penny and David Frost. Neural networks in clinical medicine. Medical Decision Making, 16(4):386-398, 1996. [RIZ+17] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv: 1711.05225, 2017. [SA75] Edward H Shortliffe and Stanton G Axline. Computer-based consultations in clinical therapeutics: Explanation and rule acquisition capabilities of the mycin. 1975. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 6'])\n",
      "calling <function ContentRetrieverWithFilter.search at 0x000001E86AE60860> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some examples of publicly available healthcare datasets?', 'what_makes_health_unique')\n",
      "calling <function ContentRetrieverWithFilter.retrieve at 0x000001E86AE631A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some examples of publicly available healthcare datasets?', 'what_makes_health_unique')\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetrieverWithFilter object at 0x000001E8691AF010>, 'What are some examples of publicly available healthcare datasets?', ['KNOWLEDGE FROM MEDICAL LITERATURE SUBSET OF DATABASE KNOWLEDGE BASE STATISTICAL PACKAGE DISCOVERY MODULE STUDY MODULE HYPOTHESIS MEDICAL ENTIRE RESEARCHER DATABASE © Robert Blum. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ Figure 1: The RX Cycle 2 Why apply machine learning to healthcare today? From the previous examples, it is clear that researchers have tried to develop computational tools for health- care with relatively little success for 40+ years. Many have found new hope for AI in healthcare because of recent widespread EHR adoption, publicly available datasets, standardization of medical codes, and break- throughs in machine learning. 2.1 EHR Adoption In the last decade, health records transitioned from mostly on paper to mostly electronic. The shift to EHR has been swift, increasing by 9x since 2008, growing from 9.4% of hospitals to nearly 84% See Figure 3 for the adoption trend from 2008 to 2015. This highlights a theme for the rest of the course: that new policy can open the door to innovation. 2.2 Data New medical datasets are now publicly available. Mimic, the only publicly available EHR dataset, was created out of MIT, consisting of intensive care unit patient records. From the MIMIC Physiotnet website, \"MIMIC is an openly available dataset developed by the MIT Lab for Computational Physiology, comprising de-identified health data associated with 40,000 critical care patients. It includes demographics, vital signs, laboratory tests, medications, and more.\" Chexpert, a large publicly available image dataset, was created in collaboration between Stanford and MIT [RIZ+17]. From the Chexpert website, \"CheXpert is a large dataset of chest X-rays and competition for automated chest x-ray interpretation, which features uncertainty labels and radiologist-labeled reference standard evaluation sets.\" The Truven Marketscan data is not a publicly available dataset, but it\\'s available in this class and it\\'s useful because it has \"data on nearly 230 million unique patients since 1995.\" Here\\'s a link to the Marketscan website. Additionally new streams of data that are relevant to health have become available to researchers. Sources of new diverse data streams include: wearable devices, phones, social media, proteomics, and genomics. 6.S897/HST.956 Machine Learning for Healthcare - Lecl - 2', 'to those challenges, patient data is particularly sensitive, SO de-identification is necessary and negotiating data sharing agreements is time-consuming. Due to the complexity of the healthcare system, there is often missing data and different training data VS testing data distributions. Production EHR systems might be difficult to work with, as each commercial system is slightly different. 5 Overview of course syllabus The goals for this class are to provide intuition for healthcare data and machine learning algorithms along with understanding of the subtleties in applying these methods to the real world and challenges for future research. References [Blu19] Robert Blum. RX Project Notes. https://www.bobblum.com/ESSAYS/COMPSCI/rx-project. html, 2019. [Online; accessed 05-February-2019 [Mil10] RA Miller. A history of the internist-1 and quick medical reference (qmr) computer-assisted diagnosis projects, with lessons learned. Yearbook of medical informatics, 19(01):121-136, 2010. [PF96] Will Penny and David Frost. Neural networks in clinical medicine. Medical Decision Making, 16(4):386-398, 1996. [RIZ+17] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv: 1711.05225, 2017. [SA75] Edward H Shortliffe and Stanton G Axline. Computer-based consultations in clinical therapeutics: Explanation and rule acquisition capabilities of the mycin. 1975. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 6', \"Figure 1: Percent of non-Federal acute care hospitals with adoption of at least a Basic EHR with notes system and possession of a certified EHR: 2008-2015 96% Certified EHR 85.2%* 96.9% 94%* 75.5%* 83.8%* 71.9% Basic EHR 59.4% 44,4%* 27.6% 15.6% 12.2% 9.4% 2008 2009 2010 2011 2012 2013 2014 2015 NOTE: Basic DIR adoption requires the EHR system to have a set of EHR functions defined in Table AL A certified EHR is EHR technology that meets the technological capability, functionality, and security requirements adopted by the Department of Health and Human Services. Possession means that the hospital has a legal agreement with the DHR vendor, but is not equivalent to adoption, *Significantly different from previous your (p=0.05). SOURCE: ONC/American Hospital Association (AMA). AHA Annual Survey Information Technology Supplement Courtesy of Health and Human Services. Image is in the public domain. Figure 3: The adoption of EHR by hospitals from 2008-2015. 3 Examples of machine learning applied to healthcare There are opportunities to transform every aspect of the healthcare system. Figure 4 shows some of the key components of the healthcare system and how they interact. In the United States, we have separated payors and providers along with government programs like Medicare and Medicaid, but the UK's National Health Service differs as a more integrated system across payors and providers. Understanding these systems, we can find opportunities to turn the right knobs to make an impact. 3.1 Imagining the emergency department of the future Professor Sontag has been working with Beth Israel Deaconess Medical Center to use technology in their Emergency Department. The ER is an interesting setting because it faces extreme constraints on a daily basis, these include: limited resources, time-sensitive needs, and critical life or death decisions. The following are some concrete examples of AI applications that aim to improve healthcare in both the short and long term. One of the themes of this course will be to highlight the high-value subtle interventions that AI can offer in the healthcare setting. 3.1.1 Behind-the-scenes reasoning about the patients conditions One of the most valuable resources in healthcare is time. Clinicians have many constraints on their time, making data collection less frequent and accurate. If features about patients can be automatically extracted from electronic medical records, then clinicians can spend more time treating patients. Extracting these features would allow for better triage, diagnosis, earlier detection of adverse events, and would likely prevent medical errors. Professor Sontag proposes a system that could predict the clincians needs, providing them with a list of treatment option lists. 6.S897/HST.956 Machine Learning for Healthcare - Lec1 - 4\"])\n"
     ]
    }
   ],
   "source": [
    "for content_type in [\"Video\", \"PDF\"]:\n",
    "    print(f\"\\nEvaluating {content_type} content\")\n",
    "    table_name = f\"{course_name}_{content_type.lower()}\"\n",
    "    retriever = ContentRetrieverWithFilter(snow_session, table_name)\n",
    "    tru_app = TruCustomApp(\n",
    "        retriever,\n",
    "        app_name=f\"{content_type} Retriever\",\n",
    "        app_version=\"metadata filter\",\n",
    "        feedbacks=feedbacks,\n",
    "    )\n",
    "\n",
    "    with tru_app as recording:\n",
    "        for lecture_name, questions in questions_for_lecture.items():\n",
    "            for question in questions:\n",
    "                response = retriever.search(question, lecture_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Chunk Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query: str, data=None):\n",
    "    cursor = snow_conn.cursor()\n",
    "    try:\n",
    "        if data:\n",
    "            cursor.executemany(query, data)\n",
    "        else:\n",
    "            cursor.execute(query)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error executing query: {str(e)}\")\n",
    "    finally:\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(table_name):\n",
    "    print(f\"Creating table: {table_name}\")\n",
    "    table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        text STRING,\n",
    "        start_time INTEGER,\n",
    "        end_time INTEGER,\n",
    "        file_name STRING,\n",
    "        lecture_name STRING\n",
    "    )\n",
    "    \"\"\"\n",
    "    run_query(table_query)\n",
    "\n",
    "def insert_data(table_name, data):\n",
    "    data_query = f\"\"\"\n",
    "    INSERT INTO {table_name} (text, start_time, end_time, file_name, lecture_name)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    run_query(data_query, data)\n",
    "\n",
    "def create_search_service(table_name):\n",
    "    service_query = f\"\"\"\n",
    "    CREATE CORTEX SEARCH SERVICE IF NOT EXISTS {table_name}\n",
    "    ON text\n",
    "    ATTRIBUTES lecture_name\n",
    "    warehouse = COMPUTE_WH\n",
    "    TARGET_LAG = '1 minute'\n",
    "        as (\n",
    "            SELECT *\n",
    "            FROM {table_name}\n",
    "        );\n",
    "        \"\"\"\n",
    "    run_query(service_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_transcripts = {}\n",
    "course_path = f\"courses/{course_name}\"\n",
    "chunk_configs = [(30, 5), (60, 10), (120, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk_size, overlap in chunk_configs:\n",
    "    print(f\"\\nProcessing chunk size: {chunk_size}s with overlap: {overlap}s\")\n",
    "    table_name = f\"{course_name}_video_{chunk_size}_{overlap}\"\n",
    "    create_table(table_name)\n",
    "\n",
    "    for lecture in os.listdir(course_path):\n",
    "        print(f\"\\nProcessing lecture: {lecture}\")\n",
    "        lecture_path = os.path.join(course_path, lecture)\n",
    "        video_file = [\n",
    "            file_name\n",
    "            for file_name in os.listdir(lecture_path)\n",
    "            if file_name.endswith(\".mp4\")\n",
    "        ]\n",
    "        video_path = os.path.join(lecture_path, video_file[0])\n",
    "\n",
    "        video = Video(file_path=video_path)\n",
    "\n",
    "        if lecture not in video_transcripts.keys():\n",
    "            print(f\"Transcribing video for lecture: {lecture}\")\n",
    "            _, _, transcript = video._transcribe()\n",
    "            video_transcripts[lecture] = transcript\n",
    "        else:\n",
    "            print(f\"Using cached transcript for lecture: {lecture}\")\n",
    "            transcript = video_transcripts[lecture]\n",
    "\n",
    "        print(\"Chunking transcript...\")\n",
    "        chunks = video._chunk_text(transcript, chunk_size, overlap)\n",
    "        print(f\"Generated {len(chunks)} chunks\")\n",
    "\n",
    "        data = [\n",
    "            (chunk.text, chunk.start, chunk.end, video_file[0], lecture)\n",
    "            for chunk in chunks\n",
    "        ]\n",
    "        print(f\"Inserting chunks into table: {table_name}\")\n",
    "        insert_data(table_name, data)\n",
    "    \n",
    "    print(f\"\\nCreating search service for table: {table_name}\")\n",
    "    create_search_service(table_name)\n",
    "    print(\"Search service created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Chunk Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating chunk size: 30s with overlap: 5s\n",
      "instrumenting <class '__main__.ContentRetriever'> for base <class '__main__.ContentRetriever'>\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting search\n",
      "skipping base <class 'object'> because of class\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the primary function of the heart in the circulatory system?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the primary function of the heart in the circulatory system?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the primary function of the heart in the circulatory system?', [\"So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps about 5 liters of blood a minute, and with exercise, that can go up 5 to 7 fold or so with with sort of conditioned athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about 3 seconds, you are likely to to to get light headed or pass out.\", \"So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps 5 liters of blood a minute, and with exercise, that can go 5 to 7 fold or so with with sort of condition athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about three seconds, you are likely to to to get light headed or pass out.\", \"So even if you look at those and you sort of look at the bottom here, this still if this is sort of all causes of death age adjusted, cardiovascular disease is still sort of number 1 amongst that. So so certainly it remains important, and and sort of increasingly so in some of the developing world also. So, it's important to think a little bit about what the heart does because this is gonna guide at least the way that diseases have been classified. So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the two circulations the heart conducts in series?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the two circulations the heart conducts in series?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the two circulations the heart conducts in series?', [\"And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So, so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last, last class on the electrical system. So the sinoatrial node is up here in the right atrium, and then conduction sort of goes through. So the p wave on an EKG is is represents the conduction through there. You get through the Savi node where there's a delay, which is the PR interval, and then you get spreading through the ventricles, which is the QRS complex, and then, repolarization is the t wave.\", \"And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last last class on the electrical system. So the sinoatrial node is up here in the right atrium, and then conduction sort of goes through. So the p wave on an EKG is is represents the conduction through there. You get through the Savi node where there's a delay, which is the PR interval, and then you get spreading through the ventricles, which is the QRS complex, and then repolarization is the t wave.\", \"So right ventricle has got some muscle to it. It pumps into the lungs. There, the blood picks up oxygen, so that's why it's sort of shown as being red here. The the oxygenated blood comes through the left atrium and then into the left ventricle through something called the mitral valve. We'll show you some pictures of the mitral valve later on. And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So, so in through the right heart, through the lungs, through the left heart, through the to the rest of the body.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', [\"Echocardiography, which involves sound waves, is ultimately more used for quantifying structure and function, can pick up heart failure, valvular disease, high blood pressure in the lungs. So so that's another modality. MRI, which is just not used all that much in this country, is very expensive but does largely the same things. And you can imagine even though it's beautiful, people have not had an easy time and able to justify why it's any better than this slightly cheaper modality. And then you have angiography, which can either be by CAT scan or by x-ray, and that visualizes the flow of blood through the heart and looks for blockages, which are going to be stented, ballooned up and stented.\", \"Echocardiography, which involves sound waves, is ultimately more used for quantifying structure and function, can pick up heart failure, valvular disease, high blood pressure in the lungs. So so that's another modality. MRI, which is just not used all that much in this country, is very expensive but does largely the same things. And you can imagine even though it's beautiful, people have not had an easy time and able to justify why it's any better than this slightly cheaper modality. And then you have angiography, which can either be by CAT scan or by X-ray, and that visualizes the flow of blood through the heart and looks for blockages, which are gonna be stented, ballooned up and stented.\", \"So, there's a lot of different so so cardiology is is very imaging centric, and, and as a result it's very expensive because because imaging is, you know, costs a lot of money to do. And so I have dollar signs here reflecting the sorts of different tests we do. So you saw the cheapest 1, last last week, the electrocardiogram, so one dollar sign. And that's used for I mean, that's lots of utility. For example, 1 could diagnose an acute heart attack with that. Echocardiography, which involves sound waves, is ultimately more used for quantifying structure and function, can pick up heart failure, valvular disease, high blood pressure in the lungs.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What challenge does cardiac motion pose to high-quality imaging scans?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What challenge does cardiac motion pose to high-quality imaging scans?', [\"And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself. And so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you want to have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately doesn't deal well with with the moving aspect.\", \"And so 1 of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself, and so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you wanna have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately, doesn't deal well with with the moving aspect.\", \"So you typically don't have you have very poor spatial resolution for something that ultimately, doesn't deal well with with the moving aspect. So coronary angiography has very, very fast frame rates. So that's x-ray, and that's sort of very fast. Echocardiography can be quite fast. MRI and CT are not quite as good, and so there's some degradation of the image. As a result, people do something called gating, where they'll take the electrocardiogram, the ECG, and try to line up different portions of different heartbeats and say, well, you know, we'll take this image from here, we'll line it up with 1 from there, 1 from there.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is a significant benefit of applying machine learning to cardiac imaging?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is a significant benefit of applying machine learning to cardiac imaging?', [\"And today's instance is going to be about, about cardiovascular medicine, in particular, about how to use imaging and machine learning on images in that context. And for today's lecture, we're we're, very excited to have, Professor Rahul Deo to speak. Rahul's name kept on showing up as I did research over the last couple of years. First, I my group was starting to get interested in echocardiography and we said, oh, here's an interesting paper to read on it. We read it, and then we read another paper on doing subtyping of of preserved ejection fraction as a type of heart failure, and we read it.\", \"And today's instance is going to be about, about cardiovascular medicine, in particular, about how to use imaging and machine learning on images in that context. And for today's lecture, we're we're, very excited to have, professor Rahul Deo to speak. Rahul's name kept on showing up as I did research over the last couple of years. First, I my group was starting to get interested in echocardiography, and we said, oh, here's an interesting paper to read on it. We read it, and then we wrote another paper on doing subtyping of of ejection fraction as a type of heart failure, and we read it.\", \"So the question was so in you know, cardiac imaging has a very long history. And so there was a period of time where there's these kind of active modelers around morphologies of the heart. And so people have these sort of models around what the heart should look like from many, many, many studies, and they were using that back in the time when you had these relatively coarse, multislice scanners for a CT. They would reconstruct the 3 d image of the heart based on sort of some preexisting geometric model of what the heart should look like. And there's, of course, a benefit to that for some risk in the sense that somebody may be very different in the space that's missing, and you may be and so the question is whether those kind of priors can be introduced in some way.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', [\"Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks, specifically in cancer and also, obviously, risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 2009 to 2016. This started off with about 280,000 cancers. And once we kinda filtered for at least 1 year follow-up, we ended up with this, you know, final setting where we had, 220,000 mammograms for training, and about 26,000 for development and testing.\", \"You see that kind of frame kind of anywhere you know it's a dog, and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just, like, the number of cancers we have, it's gonna be the cancer might be less than 1% of the mammogram and about 0.7% of your images have cancers. Even in this data set, which is from 2000 to 2016 NGH, a massive imaging center, in total, across all of that, we all still have, like, less than 2,000 cancers. And this is super tiny compared to, like, regular object classification data sets. And this is, you know, looking at over a 1,000,000 images if you look at all the four views of the exams.\", \"You see that kind of frame kind of anywhere you know it's a dog and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just like the number of cancers we have, it's gonna be the cancer might be less than one percent of the mammogram and about point seven percent of your images have cancer. So even in this data set which is from 02/2016 in NGH, a massive imaging center, in total across all of that, we all still have like less than two thousand cancers. And this is super tiny compared to like regular object classification data sets. And this is, you know, looking at over a million images, if you look at all 4 views of the exams.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the four categories of breast tissue density used in medical practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the four categories of breast tissue density used in medical practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are the four categories of breast tissue density used in medical practice?', [\"We saw the exact same trend by density. The outline here is very dense breasts, but there's only like a 100 of those on test sets, so like this confidence level actually goes from like 60 to 90. So, as far as we know for the other 3 categories, it is very much tighter confidence interval and very similar, once again around 82. Okay. So we have a decent idea that this model seems at least with a population MGH, actually serve the relevant populations, you know, that exist as far as we know so far. The next question is, how does this how does a model assessment relate to the radiology assessment?\", \"We saw the exact same trend by density. The outline here is very dense breasts, but but there's only like a hundred of those on test set, so like this confidence of actually goes from 60 to 90. So, as far as we know for the 3 categories, it is very much tighter confidence interval and very similar once again around 82. Okay. So we have a decent idea that this model seems at least with a population MGH, actually serve the relevant populations, you know, that exists as far as we know so far. The next question is, how does this how does a model assessment relate to the rate dodge assessment?\", \"People have thought that the image contained something before. The way they've thought about this is through this kind of subjective breast density marker, and the improvements seen across this are kind of marginal from 61 to 63. And as before, the kind of sketch we're gonna go through is data collection, modeling, and analysis. In data collection, we followed a very similar template. We sought for the consecutive mammograms from 2009 to 2012. We took outcomes from the EHR, once again, and the partner's registry. We didn't do exclusions based on race or anything of that sort or implants, but we did exclude negatives for follow-up.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', [\"So this is looking a 100% of mammogram, sensitivity was 90.6 with specificity of 93, And in the simulation, the sensitivity dropped, not significantly to 90.1, but significantly improved to 93.7 while looking at 80% or 81% of the mammograms. So this is like promising preliminary data, but to reevaluate this and go forward, our next step see if I oh, I'm gonna get to that in a second. Our next step is really do clinical implementation, to really figure out, because there's like a core assumption here was that people read it the same way. But if you have this higher incidence, what does that mean?\", \"So it shows that they're kind of picking up on different things and they're where they disagree gives us both areas to improve and some ancillary benefits because now we can reduce false positives. This directly leads into simulating the impact. 1 of the things we did we said, okay, if people retrospectively on the test set as a simulation before we truly plug it in, if people didn't rebuild the triage threshold, so we can't catch any more cancer this way but we can reduce false positives, what would have happened? So at the top, we have the original performance. So this is % of mammogram sensitivity 90.6 with specificity 93 And in the simulation, the sensitivity dropped not significantly 90.1, but significantly improved 93.7 while looking 80% or eighty one percent of the mammograms.\", \"This is a single view of a breast and in that, the actual can show the confer might 50 by 50 pixels. So intuitively, your signal to noise ratio is very different whereas an image in that my dog is like the entire image. She's huge, in real life and in that photo. And the image itself is much smaller. So not only do you have much smaller images, but you're kind of like the relative size of the object in there is much larger. To kind of further compound the difficulty, the pattern that you're looking for inside the mammogram is really context dependent. So if you saw that pattern somewhere else in the breast, it's not doesn't indicate the same thing. And so you really care about where in this kind of global context this comes out and if you kind of take the mammogram at different times with different compressions, you will have this kind of non rigid morphing of the image that's much more difficult to model, whereas that's a more or less context independent dog.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', [\"You see that kind of frame kind of anywhere you know it's a dog and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just like the number of cancers we have, it's gonna be the cancer might be less than one percent of the mammogram and about point seven percent of your images have cancer. So even in this data set which is from 02/2016 in NGH, a massive imaging center, in total across all of that, we all still have like less than two thousand cancers. And this is super tiny compared to like regular object classification data sets. And this is, you know, looking at over a million images, if you look at all 4 views of the exams.\", \"You see that kind of frame kind of anywhere you know it's a dog, and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just, like, the number of cancers we have, it's gonna be the cancer might be less than 1% of the mammogram and about 0.7% of your images have cancers. Even in this data set, which is from 2000 to 2016 NGH, a massive imaging center, in total, across all of that, we all still have, like, less than 2,000 cancers. And this is super tiny compared to, like, regular object classification data sets. And this is, you know, looking at over a 1,000,000 images if you look at all the four views of the exams.\", \"So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', [\"So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts. So in terms of looking at high risk cohorts, our best model plays about 30% of all the cancers in the population in the top 10%, and 3% of all the cancers in the bottom 10%, compared to 185 to the prior state of the art. And so, what this enables you to do if you're gonna say that, you know, this 10% should actually qualify for MRI, you can start fighting this problem of majority of people that get cancer don't have MRI and the majority of people that get it don't need it.\", \"One thing I forgot to mention, that's why I had the slide here to remind me, is that we excluded cancers from the 1st year from the test set, so there's truly a negative screening population. So the way we we kind of disentangle cancer detection from cancer risk. Okay. Cool. So Tyre Cusick is the kind of prior state of the art model. It's a model based out of the UK. They're developed by someone named Sir Cusick, who's knighted over this work. It's very commonly used. So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model?\", \"So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the primary challenge with using billing codes for clinical research?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the primary challenge with using billing codes for clinical research?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the primary challenge with using billing codes for clinical research?', [\"What and and there's a systematic reason, because those billing codes were not created in order to specify what's wrong with the patient. They were created in order to tell an insurance company or Medicare or somebody how much of a payment is deserved by the doctors taking care of them. And so what this means is that, for example, if I clutch my chest and go, and an ambulance rushes me over to Mass General, And they do a whole bunch of tests, and they decide that I'm not having a heart attack. The correct billing code for that visit is myocardial infarction, because, of course, the work that they had to do in order to figure out that I'm not having a heart attack is the same as the work they would have had to do to figure out that I was having a heart attack.\", \"What and and there's a systematic reason, because those billing codes were not created in order to specify what's wrong with the patient. They were created in order to tell an insurance company or Medicare or somebody how much of a payment is deserved by the doctors taking care of them. And so what this means is that, for example, if I clutch my chest and go, and an ambulance rushes me over to Mass General, And they do a whole bunch of tests, and they decide that I'm not having a heart attack. The correct billing code for that visit is myocardial infarction, because, of course, the work that they had to do in order to figure out that I'm not having a heart attack is the same as the work they would have had to do to figure out that I was having a heart attack.\", \"And so, the billing codes, we've talked about this a little bit before, but they're a very imperfect representation of reality. So we said, well, okay. What if we insisted that, you have 3 billing codes for rheumatoid arthritis rather than just one? And that turned out to raise the positive predictive value all the way up to 27%. Okay? So you go, really? How could you get billed 3 times? Right? Well, the answer is that you get billed for, you know, every aspirin you take at the at the hospital.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', [\"And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%. So that was definitely an improvement. So this was published in 2010, and so this is not the latest, hot off the bench results. But to me, it's a very compelling story that says there is real value in these clinical narratives.\", \"And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%. So that was definitely an improvement. So this was published in 2010, and so this is not the latest, hot off the bench results. But to me, it's a very compelling story that says there is real value in these clinical narratives.\", \"And so may let me think about so this is NLP. The focus here is on NLP. So there are couple ways we're doing this. So one rate limiting step was getting the clinicians to come up with a list of terms that are important for a certain condition. You can imagine if you get 5 doctors in a room to try to agree on a list, takes forever. And so we tried to get that out of the way. So one thing we started doing was we took, just common things that are freely available on the Web, Wikipedia, Medline, the Merck Manual, that have medical information.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some goals of NLP in healthcare as discussed in the lecture?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some goals of NLP in healthcare as discussed in the lecture?', [\"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations.\", \"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations.\", \"And so may let me think about so this is NLP. The focus here is on NLP. So there are couple ways we're doing this. So one rate limiting step was getting the clinicians to come up with a list of terms that are important for a certain condition. You can imagine if you get 5 doctors in a room to try to agree on a list, takes forever. And so we tried to get that out of the way. So one thing we started doing was we took, just common things that are freely available on the Web, Wikipedia, Medline, the Merck Manual, that have medical information.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', [\"And so the recursive machine learning problem is how best to identify the things associated with the term. And this is generally known as phenotyping. Now, how many of you have used the UMLS? Just a few. So in 1985 or 'eighty 4, the newly appointed director of the National Library of Medicine, which is one of the NIH institutes, decided to make a big investment in creating this unified medical language system, which was an attempt to take all of the terminologies that various medical professional societies had developed and unify them into a single, what they called a metathesaurus.\", \"And so the recursive machine learning problem is how best to identify the things associated with the term. And this is generally known as phenotyping. Now, how many of you have used the UMLS? Just a few. So in 1985 or 'eighty 4, the newly appointed director of the National Library of Medicine, which is one of the NIH institutes, decided to make a big investment in creating this unified medical language system, which was an attempt to take all of the terminologies that various medical professional societies had developed and unify them into a single, what they called a metathesaurus.\", \"And so one can really understand in a very structured way what medications a patient is on and how those medications relate to one another. A lot of medical data is found not in this structured form, but in free text, in in notes written by doctors. And these notes have often lots of mentions of symptoms and, conditions in them. And one can try to standardize those by mapping them to what's called the Unified Medical Language System, which is a ontology with millions of different medical concepts in them.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the role of term spotting and negation handling in clinical NLP?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the role of term spotting and negation handling in clinical NLP?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the role of term spotting and negation handling in clinical NLP?', [\"And so a whole industry developed of people saying that not only should we use the terms that we got originally from the doctors who were interested in doing these queries, but we can define a machine learning problem, which is how do we learn the set of terms that we should actually use that will give us better results than just the terms we started with? And so I'm gonna talk about a little bit of of that approach. First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works.\", \"And so a whole industry developed of people saying that not only should we use the terms that we got originally from the doctors who were interested in doing these queries, but we can define a machine learning problem, which is how do we learn the set of terms that we should actually use that will give us better results than just the terms we started with? And so I'm gonna talk about a little bit of of that approach. First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works.\", \"First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary. So I'll talk a little bit about that. But basically, it's a dictionary lookup. You look up in this very large database of medical terms and translate them into some kind of expression that represents what that term means.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is risk stratification and why is it important in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is risk stratification and why is it important in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is risk stratification and why is it important in healthcare?', ['So what is risk stratification? At a high level, you should think about risk stratification as a way of taking in a patient population and separating out all of your patients into 1 of 2 or more categories. Patients with high risk, patients with low risk, and maybe patients somewhere in the middle. Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions.', 'So what is risk stratification? At a high level, you should think about risk stratification as a way of taking in a patient population and separating out all of your patients into 1 of 2 or more categories. Patients with high risk, patients with low risk, and maybe patients somewhere in the middle. Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions.', \"And finally, in today's economic environment, risk stratification is very much targeted towards reducing cost of the US health care setting. And so I'll give you a few examples of risk stratification, some of which have cost as a as a as a major goal, others which don't. The first example is that of predicting an infant's risk of severe morbidity. So this is a premature baby. My my niece, for example, was born 3 months premature. It was really scary for for for my sister and for my whole family.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the difference between traditional scoring systems and ML-based risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', [\"But as I mentioned, these scores haven't had the impact that we had hoped that they might have. And and the reason really is because they haven't been actually used nearly as much as they should be. So what we will be thinking through is can we change the way in which risk stratification is done rather than it having to be something which is manually done when you think to do it, we can make it now population wide. We could, for example, take data that's already available from a health insurance company, use machine learning.\", \"But as I mentioned, these scores haven't had the impact that we had hoped that they might have. And and the reason really is because they haven't been actually used nearly as much as they should be. So what we will be thinking through is can we change the way in which risk stratification is done rather than it having to be something which is manually done when you think to do it, we can make it now population wide. We could, for example, take data that's already available from a health insurance company, use machine learning.\", \"Well, the traditional approaches to risk stratification are based on scoring systems. So I mentioned to you a few minutes ago the APGAR scoring system. It's shown here. You're going to say for each of these different criteria, activity, pulse, grimace, appearance, respiration, You look at the baby and you say, well, activity is absent or maybe their active movement. Appearance might be pale or blue, which would get 0 points, or completely pink, which gets 2 points. And for each one of these answers, you add up the corresponding points. So you get a total number of points. And you look over here and you say, okay. Well, baby is at risk, at severe risk.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How is label leakage managed in diabetes prediction models?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How is label leakage managed in diabetes prediction models?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How is label leakage managed in diabetes prediction models?', [\"So for example, for this prediction task, we're going to exclude patients who have developed type 2 diabetes between 2,009 and 2,011. And we're only going to count as positives patients who get newly diagnosed with type 2 diabetes between 2,011 and 2,013. And one of the reasons why you might want to include a gap in the model is because often there's label leakage. So if you look at the very top setup, often what happens is that a clinician might have a really good idea that the patient might be diabetic, but it's not yet coded in a way which our algorithms can pick up.\", \"So for example, for this prediction task, we're going to exclude patients who have developed type 2 diabetes between 2,009 and 2,011. And we're only going to count as positives patients who get newly diagnosed with type 2 diabetes between 2,011 and 2,013. And one of the reasons why you might want to include a gap in the model is because often there's label leakage. So if you look at the very top setup, often what happens is that a clinician might have a really good idea that the patient might be diabetic, but it's not yet coded in a way which our algorithms can pick up.\", \"Rather, we want to find the patients where the diabetes might be more unexpected. And so this is one of the subtleties that really arises when you try to use retrospective clinical data to derive your labels to use within machine learning for risk stratification. So in the result result I'll tell you about, I'm going to use a 1 year gap. Another problem is that the data is highly censored. So, what I mean by censoring is that we often don't have full visibility into the the the data for patients.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What types of data are used in risk stratification for diabetes?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What types of data are used in risk stratification for diabetes?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What types of data are used in risk stratification for diabetes?', [\"Rather, we want to find the patients where the diabetes might be more unexpected. And so this is one of the subtleties that really arises when you try to use retrospective clinical data to derive your labels to use within machine learning for risk stratification. So in the result result I'll tell you about, I'm going to use a 1 year gap. Another problem is that the data is highly censored. So, what I mean by censoring is that we often don't have full visibility into the the the data for patients.\", \"Rather, we want to find the patients where the diabetes might be more unexpected. And so this is one of the subtleties that really arises when you try to use retrospective clinical data to derive your labels to use within machine learning for risk stratification. So in the result result I'll tell you about, I'm going to use a 1 year gap. Another problem is that the data is highly censored. So, what I mean by censoring is that we often don't have full visibility into the the the data for patients.\", \"An example that I'll discuss in about a week and a half when we talk about risk stratification is that algorithms are being used by payers to risk stratify patients. For example, to figure out which patients are likely to be readmitted to the hospital in the next 30 days, are likely to have undiagnosed diabetes, are likely to progress quickly in their diabetes. And based on those predictions, they're doing a number of interventions. For example, they might send nurses to the patient's home. They might offer pay they might offer their members access to a weight loss program.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Why is L1 regularization used in logistic regression for risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Why is L1 regularization used in logistic regression for risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'Why is L1 regularization used in logistic regression for risk stratification?', [\"And based on the answers to those 5 to 20 questions, one could get a pretty good idea of what the risk is of that patient. Right? So the fact that there might be a small number of features that are that are together sufficient is actually a very reasonable prior. And it's one reason why l one regularization is actually very well suited to these types of risk stratification problems on this type of data. The second reason is one of interpretability. If one wants to then ask, well, what are the features that actually were used by this model to make predictions?\", \"And based on the answers to those 5 to 20 questions, one could get a pretty good idea of what the risk is of that patient. Right? So the fact that there might be a small number of features that are that are together sufficient is actually a very reasonable prior. And it's one reason why l one regularization is actually very well suited to these types of risk stratification problems on this type of data. The second reason is one of interpretability. If one wants to then ask, well, what are the features that actually were used by this model to make predictions?\", \"So the the machine learning algorithm used in in that paper which you've read is l one regularized logistic regression. One of the reasons for using l one regularized logistic regression is because it provides a way to use a high dimensional feature set. But at the same time, it allows one to do feature selection. So I'll go more into detail on that in just a moment. I imagine most of you have sorry. All of you should be familiar with the idea of formulating machine learning as an optimization problem, where you have some loss function and you have some regularization term.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is MYCIN and why was it never used in practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is MYCIN and why was it never used in practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What is MYCIN and why was it never used in practice?', [\"If you moused over it, it would show you. Okay. I think what I'm going to do is stop there today so that I can invite Kat to join us and talk about, a, what's happened since 2010, and b, how is this stuff actually used by clinicians and clinician researchers? Cat? Okay. Well, welcome, Cat. Thank you. Nice to see you again. Yes.\", \"If you moused over it, it would show you. Okay. I think what I'm going to do is stop there today so that I can invite Kat to join us and talk about, a, what's happened since 2010, and b, how is this stuff actually used by clinicians and clinician researchers? Cat? Okay. Well, welcome, Cat. Thank you. Nice to see you again. Yes.\", \"So Tuesday, I'll I'll talk a little bit about that system and some of its successors so you'll get a sense of how that works. I should mention also that one of the papers that was on your reading list is a paper out of David Sontag's group, which uses this anchor's concept. And that's very much along the same lines, that it's a way of trying to automate. Just as Kat was saying, you know, if if you if if the doctors mention some term and you discover that that term is very often used with certain other terms by looking at Wikipedia or at the Mayo Clinic data or at wherever your sources are, then that's a good clue that that other term might also be useful.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some reasons why AI in healthcare is more promising today compared to the past?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', [\"Why do I think that despite that the fact that we've had what could arguably be called a failure for the last 30 or 40 years, that we might actually have some chance of succeeding now? And the big differentiator, what I'll call now the opportunity, is data. So whereas in the past, much of the work in artificial intelligence in medicine was not data driven, it was based on trying to elicit as much domain knowledge as one can from clinical domain experts, in some cases, gathering a little bit of data. Today, we have an amazing opportunity because of the prevalence of electronic medical records, both in United States and elsewhere.\", \"Why do I think that despite that the fact that we've had what could arguably be called a failure for the last 30 or 40 years, that we might actually have some chance of succeeding now? And the big differentiator, what I'll call now the opportunity, is data. So whereas in the past, much of the work in artificial intelligence in medicine was not data driven, it was based on trying to elicit as much domain knowledge as one can from clinical domain experts, in some cases, gathering a little bit of data. Today, we have an amazing opportunity because of the prevalence of electronic medical records, both in United States and elsewhere.\", \"And there's a huge amount of industry interest in this field. These are just some examples from, from names I think many of you are familiar with, like DeepMind Health and IBM Watson, to start up companies like Bay Labs and PathAI, which is here in Boston, all of which are really trying to build the next generation of tools for health care now based on machine learning algorithms. There's been quite a 1,000,000,000 of dollars of funding in in the recent quarters towards digital health efforts with hundreds of different start ups that are focused specifically on using artificial intelligence in health care.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How can machine learning transform emergency departments?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How can machine learning transform emergency departments?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'How can machine learning transform emergency departments?', [\"Which is, again, an important question when it comes to deploying algorithms here. So I'll I'll run through a couple of very high level examples, driven from from my own work, focused on the provider space, and then I'll bump up to talk a bit more broadly. So for the last 7 or 8 years, I've been doing a lot of work in collaboration with Beth Israel Deaconess Medical Center across the river with their emergency department. And the emergency department is a really interesting clinical setting because you have a very short period of time from when a patient comes into the hospital to diagnose what's going on with them, to initiate therapy, and then to decide what to do next.\", \"Which is, again, an important question when it comes to deploying algorithms here. So I'll I'll run through a couple of very high level examples, driven from from my own work, focused on the provider space, and then I'll bump up to talk a bit more broadly. So for the last 7 or 8 years, I've been doing a lot of work in collaboration with Beth Israel Deaconess Medical Center across the river with their emergency department. And the emergency department is a really interesting clinical setting because you have a very short period of time from when a patient comes into the hospital to diagnose what's going on with them, to initiate therapy, and then to decide what to do next.\", \"And so that clinical understanding mixed with what we have the resources to address, that's what steers then the application of machine learning to solve a specific problem. Okay. So psychiatric inpatient admission. So these are patients who come to the ER for some psychiatric related problem. And then when they're in the ER, they're admitted to the hospital. They're in the hospital for anywhere from a day to a few days. Yeah. And you wanna you wanna find when are those gonna happen in the future? Yeah. And it could What type of data is useful for that? Sure. And I don't you don't have to just get there with the ED, though.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some challenges unique to machine learning in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some challenges unique to machine learning in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some challenges unique to machine learning in healthcare?', [\"I'll just stick to your independence. We hope. So what's unique about machine learning health care? I gave you already some hints at this. So first, health care is ultimately, unfortunately, about life or death decisions. Right? So we need robust algorithms that don't screw up. A prime example of this, which I'll tell you a little bit more about, in towards the end of the semester, is, from a major software error that occurred something like, 20, 30 years ago, in a, in an x-ray type device where an overwhelming amount of radiation was exposed to a patient just because of a software overflow problem, a bug.\", \"I'll just stick to your independence. We hope. So what's unique about machine learning health care? I gave you already some hints at this. So first, health care is ultimately, unfortunately, about life or death decisions. Right? So we need robust algorithms that don't screw up. A prime example of this, which I'll tell you a little bit more about, in towards the end of the semester, is, from a major software error that occurred something like, 20, 30 years ago, in a, in an x-ray type device where an overwhelming amount of radiation was exposed to a patient just because of a software overflow problem, a bug.\", \"And then we'll close today's lecture with an overview of what's different, what's unique about machine learning health care. All of you have taken some machine learning course in the past, and so you know the basics of supervised prediction. Many of you have studied things like clustering. And you're certainly paying attention to the news where you see news every single day about Google, Facebook, Microsoft's latest advances in speech recognition, computer vision, and so on. So what's really different about trying to apply these techniques in the health care domain? The the answer is that it's there's a huge amount of difference, and there are a lot of subtleties to doing machine learning right here.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some examples of publicly available healthcare datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some examples of publicly available healthcare datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8693EF790>, 'What are some examples of publicly available healthcare datasets?', [\"This is really the only publicly available electronic medical record dataset of any reasonable size in the whole world. And it was created here at MIT. And we'll be using it extensively in our homework assignments as a result. There are other datasets that aren't publicly available, but which have been gathered by by industry. And one prime example is the Truven MarketScan database, which is which was created by a company called Truven, which was later acquired by IBM, as I'll tell you about more in a few minutes. Now this data, and there are many competing companies that that have similar datasets, is created not from electronic medical records, but rather from typically, it's created from insurance claims.\", \"This is really the only publicly available electronic medical record dataset of any reasonable size in the whole world. And it was created here at MIT. And we'll be using it extensively in our homework assignments as a result. There are other datasets that aren't publicly available, but which have been gathered by by industry. And one prime example is the Truven MarketScan database, which is which was created by a company called Truven, which was later acquired by IBM, as I'll tell you about more in a few minutes. Now this data, and there are many competing companies that that have similar datasets, is created not from electronic medical records, but rather from typically, it's created from insurance claims.\", \"And fingers crossed, it looks like we'll get access to this database for our homework and projects for this semester. Now there are a lot a lot of other initiatives that are that are creating large datasets. A really important example here in the US is President Obama's Precision Medicine Initiative, which has since been renamed to the All of Us Initiative. And this initiative is creating a dataset of 1,000,000 patients drawn in a representative manner from across the United States to capture patients, both poor and rich, patients who are healthy and have chronic disease, with a goal of trying to create a research database where all of us and other people, both inside and outside the US, could do research to make medical discoveries.\"])\n",
      "\n",
      "Evaluating chunk size: 60s with overlap: 10s\n",
      "instrumenting <class '__main__.ContentRetriever'> for base <class '__main__.ContentRetriever'>\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting search\n",
      "skipping base <class 'object'> because of class\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the primary function of the heart in the circulatory system?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the primary function of the heart in the circulatory system?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the primary function of the heart in the circulatory system?', [\"So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps about 5 liters of blood a minute, and with exercise, that can go up 5 to 7 fold or so with with sort of conditioned athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about 3 seconds, you are likely to to to get light headed or pass out. So you have to maintain a sort of this rhythmic beat in your heart, and and you can kinda compute what that would be in somewhere around 2,000,000,000 beats in a in a typical lifetime. So I'm gonna show a lot of pictures and videos throughout this, so it's probably worthwhile just to take a pause a little bit and talk about what the what the anatomy of the heart is. So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava.\", \"So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps 5 liters of blood a minute, and with exercise, that can go 5 to 7 fold or so with with sort of condition athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about three seconds, you are likely to to to get light headed or pass out. So you have to maintain a sort of this rhythmic beating your heart, and and you can kinda compute what that would be in somewhere 2000000000 beats in a in a typical lifetime. So I'm gonna show a lot of pictures and videos throughout this, so it's probably worthwhile just to take a pause a little bit and talk about what the what the anatomy of the heart is. So so the heart is sort of sits like this. So the pointy part is kind of sitting up to the side like that. And so so I'm gonna just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava.\", \"So every time people try to get funding for for coronary heart disease, they try to talk up just how important it is. So this is still, you know, we have some battles with with the oncology people, but this is still the leading cause of of death in the world. And and then people are like, oh, you're just you're just you're just emphasizing the developed world. There's, you know, lots of lots of communicable diseases that matter much more. So even if you look at those and you sort of look at the bottom here, this still if this is sort of all causes of death age adjusted, cardiovascular disease is still sort of number 1 amongst that. So so certainly it remains important, and and sort of increasingly so in some of the developing world also. So, it's important to think a little bit about what the heart does because this is gonna guide at least the way that diseases have been classified. So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the two circulations the heart conducts in series?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the two circulations the heart conducts in series?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the two circulations the heart conducts in series?', [\"And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So, so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last, last class on the electrical system. So the sinoatrial node is up here in the right atrium, and then conduction sort of goes through. So the p wave on an EKG is is represents the conduction through there. You get through the Savi node where there's a delay, which is the PR interval, and then you get spreading through the ventricles, which is the QRS complex, and then, repolarization is the t wave. So that's that's sort of the electrical system. And, of course, these things have to kinda work intimately together. Every, sort of like, the every single basic kind of cardiac physiology will show this this diagram called the Wiggers diagram, which really just shows the sort of the interconnectedness of the electrical system. So there's the EKG up there. These are the heart sounds that that a provider would listen to with the stethoscope, and this is capturing the flow of sort of the changes in in pressure in the heart and in the aorta. So heart fills during a period of time called diastole.\", \"And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last last class on the electrical system. So the sinoatrial node is up here in the right atrium, and then conduction sort of goes through. So the p wave on an EKG is is represents the conduction through there. You get through the Savi node where there's a delay, which is the PR interval, and then you get spreading through the ventricles, which is the QRS complex, and then repolarization is the t wave. So that's that's sort of the electrical system. And, of course, these things have to kind of work intimately together. Every sort of like, the every single basic kind of cardiac physiology will show this this diagram called the Wigner's diagram, which really just shows the sort of the interconnectedness of the electrical system. So there's the EKG up there. These are the heart sounds that that a provider would listen to with a stethoscope, and this is capturing the flow of sort of the changes in in pressure in the heart and in the aorta. So heart fills during a period of time called diastole, The mitral valve closes, the ventricle contracts, the pressure increases.\", \"So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava. This is draining from the brain, this is draining from the lower body, and then enters into a chamber called the right atrium. It moves through something called the tricuspid valve into what's called the right ventricle. So right ventricle has got some muscle to it. It pumps into the lungs. There, the blood picks up oxygen, so that's why it's sort of shown as being red here. The the oxygenated blood comes through the left atrium and then into the left ventricle through something called the mitral valve. We'll show you some pictures of the mitral valve later on. And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last last class on the electrical system.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', [\"Echocardiography, which involves sound waves, is ultimately more used for quantifying structure and function, can pick up heart failure, valvular disease, high blood pressure in the lungs. So so that's another modality. MRI, which is just not used all that much in this country, is very expensive but does largely the same things. And you can imagine even though it's beautiful, people have not had an easy time and able to justify why it's any better than this slightly cheaper modality. And then you have angiography, which can either be by CAT scan or by x-ray, and that visualizes the flow of blood through the heart and looks for blockages, which are going to be stented, ballooned up and stented. And then you have these kind of noninvasive technologies like PET and SPECT that use radionuclatides, like technetium, rubidium, and they look for abnormalities in blood flow to detect whether noninvasively there's some patch of the heart that isn't getting enough blood. If you get one of these and it's abnormal, often you go over there. You can take a trip to the movies, as my old teachers used to say, and then you may get, you may find yourself with an angioplasty or stent or a bypass.\", \"Echocardiography, which involves sound waves, is ultimately more used for quantifying structure and function, can pick up heart failure, valvular disease, high blood pressure in the lungs. So so that's another modality. MRI, which is just not used all that much in this country, is very expensive but does largely the same things. And you can imagine even though it's beautiful, people have not had an easy time and able to justify why it's any better than this slightly cheaper modality. And then you have angiography, which can either be by CAT scan or by X-ray, and that visualizes the flow of blood through the heart and looks for blockages, which are gonna be stented, ballooned up and stented. And then you have these kind of noninvasive technologies like PET and SPECT that use radionuclides, like technetium, rubidium, and they look for abnormalities in blood flow to detect whether noninvasively there's some patch of the heart that isn't getting enough blood. If you get 1 of these and it's abnormal, often you go over there. You can take a trip to the movies, as my old teachers used to say, and then you may get, you may find yourself with a angioplasty or stent or a bypass.\", \"And then you have these kind of noninvasive technologies like PET and SPECT that use radionuclatides, like technetium, rubidium, and they look for abnormalities in blood flow to detect whether noninvasively there's some patch of the heart that isn't getting enough blood. If you get one of these and it's abnormal, often you go over there. You can take a trip to the movies, as my old teachers used to say, and then you may get, you may find yourself with an angioplasty or stent or a bypass. So one of the sort of sad things about cardiology is we don't define our diseases by biology. We define our diseases often related to whether the anatomy or the physiology is abnormal or or normal, usually based on some of these images or some of these numbers. Okay. So so we have to make decisions, and we often use these very same things too to be able to make some decisions. So we have to decide whether we wanna put a defibrillator. And if to do so, you often need to to get a echocardiogram to look at the pumping function of the heart. If you wanna decide on whether somebody needs angioplasty, you have to get an angiogram. If you wanna decide to get a valve replacement, you need an echo. But but, some of these other ones actually don't involve any imaging, and this is sort of one of the challenges that I'm gonna talk about is that is that all of the sort of the future, if you can imagine building brand new risk models, new classification models, you're stuck with the data that's out there.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What challenge does cardiac motion pose to high-quality imaging scans?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What challenge does cardiac motion pose to high-quality imaging scans?', [\"And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself. And so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you want to have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately doesn't deal well with with the moving aspect. So coronary angiography has very, very fast frame rates. So that's x-ray, and that's sort of very fast. Echocardiography can be quite fast. MRI and CT are not quite as good, and so there's some degradation of the image. As a result, people do something called gating, where they'll take the electrocardiogram, the ECG, and try to line up different portions of different heartbeats and say, well, you know, we'll take this image from here, we'll line it up with this one from there, this one from there. I'm going to talk a little bit about that from about registration, but ultimately that's a problem that people have to deal with.\", \"And so 1 of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself, and so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you wanna have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately, doesn't deal well with with the moving aspect. So coronary angiography has very, very fast frame rates. So that's x-ray, and that's sort of very fast. Echocardiography can be quite fast. MRI and CT are not quite as good, and so there's some degradation of the image. As a result, people do something called gating, where they'll take the electrocardiogram, the ECG, and try to line up different portions of different heartbeats and say, well, you know, we'll take this image from here, we'll line it up with 1 from there, 1 from there. I'm gonna talk a little bit about that and from about registration, but ultimately that's a problem that people have to deal with.\", \"So you have the raw imaging data, but all the clinical stuff is somewhere else. So you have to sometimes link that, and so you need to get access there. And so just to give you a little bit of an idea of scale, so we're about to get all of the ECGs from Brigham and Women's, which is about 30,000,000, stored kind of historically. And this is all related to cost. So positron emission tomography, you can get about 8,000 or so, and we're one of the busiest centers for that. You know, echocardiograms are in the 300,000 to 500,000 ranges archived, so that gets a little bit more interesting. Okay. So what a DICOM header looks like. You have some sort of, identifiers, and then you have some information there, attributes of the images, patient name, date of birth, frame rate, these kind of things are there, and there's some variability. So it's never never quite easy. Okay. So, these different modalities have some different benefits to them, and this is why they're used for for one disease or the other. And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is a significant benefit of applying machine learning to cardiac imaging?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is a significant benefit of applying machine learning to cardiac imaging?', [\"So welcome, everyone. Today is the first of, what will be a series of of 4 guest lectures throughout the semester. There will be 2 guest lectures the week from starting the week from today, and then there'll be another 1 towards the end of the semester. And what, Pete and I decided to do is to bring in people who know a lot more than us about some area of expertise. And today's instance is going to be about, about cardiovascular medicine, in particular, about how to use imaging and machine learning on images in that context. And for today's lecture, we're we're, very excited to have, Professor Rahul Deo to speak. Rahul's name kept on showing up as I did research over the last couple of years. First, I my group was starting to get interested in echocardiography and we said, oh, here's an interesting paper to read on it. We read it, and then we read another paper on doing subtyping of of preserved ejection fraction as a type of heart failure, and we read it.\", \"So welcome, everyone. Today is the first of what will be a series of 4 guest lectures throughout the semester. There will be 2 guest lectures the week from starting the week from today, and then there'll be another one towards the end of the semester. And what Pete and I decided to do is to bring in people who know a lot more than us about some area of expertise. And today's instance is going to be about, about cardiovascular medicine, in particular, about how to use imaging and machine learning on images in that context. And for today's lecture, we're we're, very excited to have, professor Rahul Deo to speak. Rahul's name kept on showing up as I did research over the last couple of years. First, I my group was starting to get interested in echocardiography, and we said, oh, here's an interesting paper to read on it. We read it, and then we wrote another paper on doing subtyping of of ejection fraction as a type of heart failure, and we read it.\", \"And in some places, radiologist consults could take days depending on the urgency of the condition. So this is an area where data is quite standardized. In fact, MIT just released last week a dataset of 300,000 chest x rays with associated labels on them. And one could try to ask the question of, could we build machine learning algorithms using the convolutional neural network type techniques that we've seen play a big role in object recognition to try to understand what's going on with this patient. For example, in this case, the prediction is the patient has pneumonia from this chest X-ray. And and using those systems, it could help both reduce the load of radiology consults, and it could allow us to really translate these algorithms to settings which are might be much more resource poor, for example, in developing nations. Now the same sort of techniques can be used for other data modalities. So this is an example of of data that could be obtained from an EKG. And from looking at this EKG, one can try to predict, does the patient have a heart condition such as an arrhythmia?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', [\"Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks, specifically in cancer and also, obviously, risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 2009 to 2016. This started off with about 280,000 cancers. And once we kinda filtered for at least 1 year follow-up, we ended up with this, you know, final setting where we had, 220,000 mammograms for training, and about 26,000 for development and testing. And the way we had our outcomes to say, you know, is this a positive mammogram or not? We didn't look at what cancers were caught by the radiologist. We'll say, you know, what was cancer that was fine in any means within a year? And where we looked, we looked through the radiology, HR, and the partners kind of 5 hospital registry. And they were really trying to say if a cancer if any way we can tell a cancer occurred, let's mark it as such, regardless of whether it was caught on MRI or some kind of later stage. And so the thing we're trying to do here is just mimic, you know, the real world of whether we not trying to catch cancer.\", \"Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks specifically in cancer and also obviously risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 02/9 to 2016. This started off with about two hundred eighty thousand cancers and once we kind of filtered for at least one year follow-up, we ended up with this, you know, final setting where we 220000 mammograms for training, and 26000 for development and testing. And the way we had our outcomes to say, you know, is this a positive mammogram or not? We didn't look at what cancers were caught by the radiologist. We'll say, you know, what was cancer that was fine in any means within a year? And when we looked, we looked through the radiology HR and the partners kind of 5 hospital registry. And they were really trying to say if a cancer if any way we can tell a cancer occurred, let's mark it as such regardless of whether it was caught on MRI or some kind of later stage. And so the thing we're trying to do here is just mimic, you know, the real world of what we not trying to catch cancer.\", \"This is a single view of a breast and in that, the actual can show the confer might 50 by 50 pixels. So intuitively, your signal to noise ratio is very different whereas an image in that my dog is like the entire image. She's huge, in real life and in that photo. And the image itself is much smaller. So not only do you have much smaller images, but you're kind of like the relative size of the object in there is much larger. To kind of further compound the difficulty, the pattern that you're looking for inside the mammogram is really context dependent. So if you saw that pattern somewhere else in the breast, it's not doesn't indicate the same thing. And so you really care about where in this kind of global context this comes out and if you kind of take the mammogram at different times with different compressions, you will have this kind of non rigid morphing of the image that's much more difficult to model, whereas that's a more or less context independent dog. You see that kind of frame kind of anywhere you know it's a dog and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just like the number of cancers we have, it's gonna be the cancer might be less than one percent of the mammogram and about point seven percent of your images have cancer.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the four categories of breast tissue density used in medical practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the four categories of breast tissue density used in medical practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are the four categories of breast tissue density used in medical practice?', [\"So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively, and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about?\", \"So the darker the box, the higher the incidence and on the right hand side is random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium when they call it low. So kind of like you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected in case we disagree, it supports the notion that it's not just that the column are just the most dense crazy dense looking breast and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about and viewing really what is the leverage to change once you know someone is high risk?\", \"So if you can tell from an image that is gonna be healthy for a long time, you're really trying to model what's the likelihood of this breast developing cancer in the future. Now, modeling breast cancer risk, as Connie already said, is not a new problem. It's been a quite researched one in the community, and the more classical approach that we're gonna look at, other kind of global health factors, the person's age, their family history, whether or not they've had menopause, and kind of any other or these kind of factor we can try to say our markers of their health to try to predict whether or not those persons at risk of developing breast cancer. People have thought that the image contained something before. The way they've thought about this is through this kind of subjective breast density marker, and the improvements seen across this are kind of marginal from 61 to 63. And as before, the kind of sketch we're gonna go through is data collection, modeling, and analysis. In data collection, we followed a very similar template. We sought for the consecutive mammograms from 2009 to 2012. We took outcomes from the EHR, once again, and the partner's registry. We didn't do exclusions based on race or anything of that sort or implants, but we did exclude negatives for follow-up.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', [\"This is a single view of a breast and in that, the actual can show the confer might 50 by 50 pixels. So intuitively, your signal to noise ratio is very different whereas an image in that my dog is like the entire image. She's huge, in real life and in that photo. And the image itself is much smaller. So not only do you have much smaller images, but you're kind of like the relative size of the object in there is much larger. To kind of further compound the difficulty, the pattern that you're looking for inside the mammogram is really context dependent. So if you saw that pattern somewhere else in the breast, it's not doesn't indicate the same thing. And so you really care about where in this kind of global context this comes out and if you kind of take the mammogram at different times with different compressions, you will have this kind of non rigid morphing of the image that's much more difficult to model, whereas that's a more or less context independent dog. You see that kind of frame kind of anywhere you know it's a dog and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just like the number of cancers we have, it's gonna be the cancer might be less than one percent of the mammogram and about point seven percent of your images have cancer.\", \"So, it shows that they're kind of picking up on different things and where they disagree gives us both areas to improve and some ancillary benefits because now we can reduce false positives. This directly leads into simulating the impact. So one of the things we did, we said, okay, if people retrospectively on the test set as a simulation before we truly plug it in, if people didn't re blow the triage threshold, so we can't catch anymore, catch it this way, but we can reduce false positives, what would have happened? So at the top, we have the original performance. So this is looking a 100% of mammogram, sensitivity was 90.6 with specificity of 93, And in the simulation, the sensitivity dropped, not significantly to 90.1, but significantly improved to 93.7 while looking at 80% or 81% of the mammograms. So this is like promising preliminary data, but to reevaluate this and go forward, our next step see if I oh, I'm gonna get to that in a second. Our next step is really do clinical implementation, to really figure out, because there's like a core assumption here was that people read it the same way. But if you have this higher incidence, what does that mean? Can you focus more on the people that are more suspicious, and is the right way to do this just a single threshold to not read, or have a double ender with the same, these are much more likely to have cancer.\", \"So it shows that they're kind of picking up on different things and they're where they disagree gives us both areas to improve and some ancillary benefits because now we can reduce false positives. This directly leads into simulating the impact. 1 of the things we did we said, okay, if people retrospectively on the test set as a simulation before we truly plug it in, if people didn't rebuild the triage threshold, so we can't catch any more cancer this way but we can reduce false positives, what would have happened? So at the top, we have the original performance. So this is % of mammogram sensitivity 90.6 with specificity 93 And in the simulation, the sensitivity dropped not significantly 90.1, but significantly improved 93.7 while looking 80% or eighty one percent of the mammograms. So this is like promising preliminary data, but to reevaluate this and go forward, our next step see if I oh, I'm gonna get to that in a second. Our next step is really do clinical implementation, to really figure out, because there's like a core assumption here was that people read it the same way. But if you have this higher incidence, what does that mean? Can you focus more on the people that are more suspicious? And is the right way to do this just a single threshold to not read?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', [\"You see that kind of frame kind of anywhere you know it's a dog, and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just, like, the number of cancers we have, it's gonna be the cancer might be less than 1% of the mammogram and about 0.7% of your images have cancers. Even in this data set, which is from 2000 to 2016 NGH, a massive imaging center, in total, across all of that, we all still have, like, less than 2,000 cancers. And this is super tiny compared to, like, regular object classification data sets. And this is, you know, looking at over a 1,000,000 images if you look at all the four views of the exams. And at the same time, it's also too big. So, even if I down sample these images, I can only really fit 3 of them for a single GPU, and so this kind of limits the batch size I can work with. And whereas the kind of comparable, if I took just the regular ImageNet size, I could fit batch sizes of 128, easily happy days, and do all this parallelization stuff, and it's just much easier to play with. And finally, the actual data set itself is quite large, and so you have to do some, there's no uses to deal with in terms of, like, just setting up your server infrastructure to handle these massive data sets, while still being able to train efficiently.\", \"You see that kind of frame kind of anywhere you know it's a dog and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just like the number of cancers we have, it's gonna be the cancer might be less than one percent of the mammogram and about point seven percent of your images have cancer. So even in this data set which is from 02/2016 in NGH, a massive imaging center, in total across all of that, we all still have like less than two thousand cancers. And this is super tiny compared to like regular object classification data sets. And this is, you know, looking at over a million images, if you look at all 4 views of the exams. And at the same time, it's also too big. So, even if I down sample these images, I can only really 3 of them for a single GPU. And so this kind of limits the batch size I can work with. And whereas the kind of comparable, if I took just the regular ImageNet size, I could fit batch sizes of one twenty eight, easily happy days and do all this parallelization stuff and it's just much easier to play with. And finally, the actual data set itself is quite large and so you have to do some, there's new senses to deal with in terms of like just setting up your server infrastructure to handle these massive data sets, while still being able to train efficiently.\", \"So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively, and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', [\"So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts. So in terms of looking at high risk cohorts, our best model plays about 30% of all the cancers in the population in the top 10%, and 3% of all the cancers in the bottom 10%, compared to 185 to the prior state of the art. And so, what this enables you to do if you're gonna say that, you know, this 10% should actually qualify for MRI, you can start fighting this problem of majority of people that get cancer don't have MRI and the majority of people that get it don't need it. It's all about is your risk model actually placed the right people into the right buckets. Now, we saw that this trend of outperforming the prior state of the art held across races, and one of the things that was kind of astonishing was that, though Thai cuisine performed by white women, which makes sense because it was developed only using white women in the UK, it was worse than random in our data set of African American women. And so, this kind of, emphasizes the importance of this kind of analysis to make sure that the kind of data set that you have is reflective of the population you're trying to serve, and actually doing the analysis, accordingly.\", \"Our kind of goals for the analysis as before, we wanna see, does this model actually serve the whole the whole population? Is it gonna be discriminative across race, menopause, status, and family history? And how does this relate to kind of classical portions of risk, and are we actually doing any better? And so just diving directly into that, assuming there's no questions. Good. Just kinda remind you, this is the kind of the setting. One thing I forgot to mention, that's why I had the slide here to remind me, is that we excluded cancers from the 1st year from the test set, so there's truly a negative screening population. So the way we we kind of disentangle cancer detection from cancer risk. Okay. Cool. So Tyre Cusick is the kind of prior state of the art model. It's a model based out of the UK. They're developed by someone named Sir Cusick, who's knighted over this work. It's very commonly used. So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts.\", \"So 1 had an AC of 62 or image only model had an AC about 68 and the 1 had an AC 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk or low risk cohorts. So in terms of looking at high risk cohorts, our best model place about thirty percent of all the cancers in the population in the top ten percent, and three percent of all the cancers in the bottom ten percent compared to eighteen and five to the prior state of the art. And so, what this enables you to do if you're gonna say that, you know, this ten percent should actually qualify for MRI, you can start fighting this problem of majority of people that get cancer don't have MRI and the majority of people that get it don't need it. It's all about is your risk model actually place the right people into the right buckets. Now, we saw that this trend of outperforming the prior state of the art held across races and 1 of the things that was kind of astonishing was that though Thai cuisine performed by white women, which makes sense because it was developed only using white women in The UK, it was worse than random in our data set of African American women. And so this kind of, emphasizes the importance of this kind of analysis to make sure that the kind of data set that you have is reflective of the population you're trying to serve and actually doing the analysis, accordingly.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the primary challenge with using billing codes for clinical research?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the primary challenge with using billing codes for clinical research?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the primary challenge with using billing codes for clinical research?', [\"What and and there's a systematic reason, because those billing codes were not created in order to specify what's wrong with the patient. They were created in order to tell an insurance company or Medicare or somebody how much of a payment is deserved by the doctors taking care of them. And so what this means is that, for example, if I clutch my chest and go, and an ambulance rushes me over to Mass General, And they do a whole bunch of tests, and they decide that I'm not having a heart attack. The correct billing code for that visit is myocardial infarction, because, of course, the work that they had to do in order to figure out that I'm not having a heart attack is the same as the work they would have had to do to figure out that I was having a heart attack. And so, the billing codes, we've talked about this a little bit before, but they're a very imperfect representation of reality. So we said, well, okay. What if we insisted that, you have 3 billing codes for rheumatoid arthritis rather than just one?\", \"What and and there's a systematic reason, because those billing codes were not created in order to specify what's wrong with the patient. They were created in order to tell an insurance company or Medicare or somebody how much of a payment is deserved by the doctors taking care of them. And so what this means is that, for example, if I clutch my chest and go, and an ambulance rushes me over to Mass General, And they do a whole bunch of tests, and they decide that I'm not having a heart attack. The correct billing code for that visit is myocardial infarction, because, of course, the work that they had to do in order to figure out that I'm not having a heart attack is the same as the work they would have had to do to figure out that I was having a heart attack. And so, the billing codes, we've talked about this a little bit before, but they're a very imperfect representation of reality. So we said, well, okay. What if we insisted that, you have 3 billing codes for rheumatoid arthritis rather than just one?\", \"The the I think the biggest challenge right now is the mapping. So ICD 9, you know, is now doesn't map directly to ICD 10 or back because there are diseases that we didn't know when they developed ICD 9 that exist in ICD 10. In ICT 10, they talk about diseases in ways that weren't described in ICD 9. So when you're trying to harmonize the data, and this is actively something we're dealing with right now at the VA, how do you now count the ICD codes? How do you consider that someone has an ICD code for RA? So those are all things that are being developed now. CMS, Center For Medicaid and Medicare, again, this is for billing purposes, has come up with a mapping system that many of us are using now given what we have. And by the way, the the committee that is designing ICD 11 Yeah. Has been very active for years. And so there's another one coming down down the pike. Although from what I understood you posit that?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', [\"So what we did is to say, well, if you train a data set that tries to tell you whether somebody really has rheumatoid arthritis or not based on just codified data. So codified data is things like lab values and prescriptions and demographics and stuff that is in tabular form. Then we were getting a positive predictive value of about 88%. And we said, well, how how well could we do by instead of looking at that codified data, looking at the narrative text in nursing notes, doctors' notes, discharge summaries, various other sources, could we do as well or better? And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%.\", \"So what we did is to say, well, if you train a data set that tries to tell you whether somebody really has rheumatoid arthritis or not based on just codified data. So codified data is things like lab values and prescriptions and demographics and stuff that is in tabular form. Then we were getting a positive predictive value of about 88%. And we said, well, how how well could we do by instead of looking at that codified data, looking at the narrative text in nursing notes, doctors' notes, discharge summaries, various other sources, could we do as well or better? And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%.\", \"And the natural language queries were also extracted in different ways, because Vanderbilt, for example, already had a tool in place where they would try to translate any text in their notes into UMLS concepts, which we'll talk about again in a little while. So my expectation when I heard about this study is that this would be a disaster, okay, that it would simply not work, because there are local effects, local factors, local ways that people have of describing patients that I thought would be very different between Nashville, Chicago, and Boston. And much to my surprise, what they found was that, in fact, it kind of worked. So the model performance, even taking into account that the way the data was extracted out of the notes and the clinical systems was different, was fairly similar. Now one thing that is worrisome is that the PPV of our algorithm on our data, the way we calculated PPV they calculated PPV in this study came in lower than the way we had done it when we when we found it.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some goals of NLP in healthcare as discussed in the lecture?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some goals of NLP in healthcare as discussed in the lecture?', [\"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations. But I'm not sure where the the boundary is going to fall. I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview.\", \"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations. But I'm not sure where the the boundary is going to fall. I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview.\", \"And this is probably not meant to be readable by anybody except the person who wrote it or maybe their immediate friends and colleagues. So this is a real issue and one that we don't have a very good solution for yet. Now what do you use NLP for? Well, I had mentioned that one of the things we want to do is to codify things that appear in a note. So if it says rheumatoid arthritis, we want to say, well, that's equivalent to a particular ICD 9 code. We might want to use natural language processing for de identification of data. I mentioned that before. You know, Mimic, the only way that that Roger Marks' group got permission to release that data and make it available for people like you to use is by persuading the IRB that we had done a good enough job of getting rid of the all the identifying information in all of those records so that it's probably not technically impossible, but it's very difficult to figure out, who the the patients actually were in that cohort, in in that database.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', [\"And so the recursive machine learning problem is how best to identify the things associated with the term. And this is generally known as phenotyping. Now, how many of you have used the UMLS? Just a few. So in 1985 or 'eighty 4, the newly appointed director of the National Library of Medicine, which is one of the NIH institutes, decided to make a big investment in creating this unified medical language system, which was an attempt to take all of the terminologies that various medical professional societies had developed and unify them into a single, what they called a metathesaurus. So it's not really a thesaurus, because it's not completely well integrated, but it does include all of this terminology.\", \"And so the recursive machine learning problem is how best to identify the things associated with the term. And this is generally known as phenotyping. Now, how many of you have used the UMLS? Just a few. So in 1985 or 'eighty 4, the newly appointed director of the National Library of Medicine, which is one of the NIH institutes, decided to make a big investment in creating this unified medical language system, which was an attempt to take all of the terminologies that various medical professional societies had developed and unify them into a single, what they called a metathesaurus. So it's not really a thesaurus, because it's not completely well integrated, but it does include all of this terminology.\", \"So one of the things that we didn't know when we first started out was how many gold standard labels did we need, and how many features did we need, and which of those features would be important. So by features, I mean ICD codes, the diagnosis code, medications, and all that list of NLP terms that might be related to the condition. And so now we have ways to try to whittle down that list before we even use those gold standard labels. And so may let me think about so this is NLP. The focus here is on NLP. So there are couple ways we're doing this. So one rate limiting step was getting the clinicians to come up with a list of terms that are important for a certain condition. You can imagine if you get 5 doctors in a room to try to agree on a list, takes forever. And so we tried to get that out of the way. So one thing we started doing was we took, just common things that are freely available on the Web, Wikipedia, Medline, the Merck Manual, that have medical information. And we actually now process those articles, look for medical terms, pull those out, map them to concepts, and that becomes that term list now that goes into so now instead of if you think about in the old days, we came up with a list.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the role of term spotting and negation handling in clinical NLP?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the role of term spotting and negation handling in clinical NLP?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the role of term spotting and negation handling in clinical NLP?', [\"And then as people did this, they said, well, there must be more sophisticated ways of doing this. And so a whole industry developed of people saying that not only should we use the terms that we got originally from the doctors who were interested in doing these queries, but we can define a machine learning problem, which is how do we learn the set of terms that we should actually use that will give us better results than just the terms we started with? And so I'm gonna talk about a little bit of of that approach. First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary.\", \"And then as people did this, they said, well, there must be more sophisticated ways of doing this. And so a whole industry developed of people saying that not only should we use the terms that we got originally from the doctors who were interested in doing these queries, but we can define a machine learning problem, which is how do we learn the set of terms that we should actually use that will give us better results than just the terms we started with? And so I'm gonna talk about a little bit of of that approach. First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary.\", \"First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary. So I'll talk a little bit about that. But basically, it's a dictionary lookup. You look up in this very large database of medical terms and translate them into some kind of expression that represents what that term means. And then you find 2 kinds of patterns. One pattern is a negation phrase followed within 5 words by one of these UMLS terms, and the other is a UMLS term followed within 5 words by a negation phrase, different set of negation phrases. So if you see no sign of something, that means it's not present. Or if you see ruled out unlikely something, then it's not present.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is risk stratification and why is it important in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is risk stratification and why is it important in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is risk stratification and why is it important in healthcare?', [\"Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring. Now, risk stratification is quite different from diagnosis. Diagnosis often has very, very stringent criteria on performance. If you do a misdiagnosis of something, that can have very severe consequences in terms of patients being treated for conditions that they didn't need to be treated for and patients dying because they were were not diagnosed in time. Now risk stratification, you think of as a little bit more fuzzy in nature. We wanna do our best job of trying to push patients into each of these categories, high dose, low risk, and so on.\", \"Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring. Now, risk stratification is quite different from diagnosis. Diagnosis often has very, very stringent criteria on performance. If you do a misdiagnosis of something, that can have very severe consequences in terms of patients being treated for conditions that they didn't need to be treated for and patients dying because they were were not diagnosed in time. Now risk stratification, you think of as a little bit more fuzzy in nature. We wanna do our best job of trying to push patients into each of these categories, high dose, low risk, and so on.\", \"Although today's lecture is going to be a little bit more high level, next Thursday's lecture is where we're going to really start to get into mathematical details about how one should tackle machine learning problems with sensor data. And then the following lecture after that is going to be on physiological data. And that lecture will also be much more technical in nature compared to the first couple of weeks of the course. So what is risk stratification? At a high level, you should think about risk stratification as a way of taking in a patient population and separating out all of your patients into 1 of 2 or more categories. Patients with high risk, patients with low risk, and maybe patients somewhere in the middle. Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the difference between traditional scoring systems and ML-based risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', [\"And each one of those steps takes a lot of time. Now with these machine learning based approaches, it raises the possibility of a research assistant sitting in a hospital or in a computer science department saying, oh, I think it would be really useful to derive a score for this problem. You apply your machine learning algorithm. And even if it's a condition or an outcome, which occurs very infrequently, if you have access to a large enough data set, you'll be able to get enough samples in order to actually predict that somewhat very narrow outcome. And so as a result, it really opens the door to rethinking about the way that risk stratification can be can be used. But as a result, there are also new dangers that are introduced. And we'll talk about some of those in today's lecture, and we'll continue to talk about those in next Thursday's lecture. So these models are being widely commercialized.\", \"And each one of those steps takes a lot of time. Now with these machine learning based approaches, it raises the possibility of a research assistant sitting in a hospital or in a computer science department saying, oh, I think it would be really useful to derive a score for this problem. You take data that's available, you apply your machine learning algorithm, and even if it's a condition or an outcome, which occurs very infrequently, if you have access to a large enough data set, you'll be able to get enough samples in order to actually predict that somewhat very narrow outcome. And so as a result, it really opens the door to rethinking about the way that risk stratification can be can be used. But as a result, there are also new dangers that are introduced. And we'll talk about some of those in today's lecture, and we'll continue to talk about those in next Thursday's lecture. So these models are being widely commercialized.\", \"Well, the traditional approaches to risk stratification are based on scoring systems. So I mentioned to you a few minutes ago the APGAR scoring system. It's shown here. You're going to say for each of these different criteria, activity, pulse, grimace, appearance, respiration, You look at the baby and you say, well, activity is absent or maybe their active movement. Appearance might be pale or blue, which would get 0 points, or completely pink, which gets 2 points. And for each one of these answers, you add up the corresponding points. So you get a total number of points. And you look over here and you say, okay. Well, baby is at risk, at severe risk. If they have 7 to 10 points, then then the baby is low risk. And there are hundreds of such scoring rules which have been very carefully derived through studies not dissimilar to the one that you read for today's readings and which are actually widely used in the health care system today.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How is label leakage managed in diabetes prediction models?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How is label leakage managed in diabetes prediction models?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How is label leakage managed in diabetes prediction models?', [\"So for example, for this prediction task, we're going to exclude patients who have developed type 2 diabetes between 2,009 and 2,011. And we're only going to count as positives patients who get newly diagnosed with type 2 diabetes between 2,011 and 2,013. And one of the reasons why you might want to include a gap in the model is because often there's label leakage. So if you look at the very top setup, often what happens is that a clinician might have a really good idea that the patient might be diabetic, but it's not yet coded in a way which our algorithms can pick up. And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list.\", \"So for example, for this prediction task, we're going to exclude patients who have developed type 2 diabetes between 2,009 and 2,011. And we're only going to count as positives patients who get newly diagnosed with type 2 diabetes between 2,011 and 2,013. And one of the reasons why you might want to include a gap in the model is because often there's label leakage. So if you look at the very top setup, often what happens is that a clinician might have a really good idea that the patient might be diabetic, but it's not yet coded in a way which our algorithms can pick up. And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list.\", \"And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list. We're gonna say this patient is someone you should be going after. But that's really not an interesting patient to be going after because the clinicians are probably already doing interventions that are relevant for that patient. Rather, we want to find the patients where the diabetes might be more unexpected. And so this is one of the subtleties that really arises when you try to use retrospective clinical data to derive your labels to use within machine learning for risk stratification. So in the result result I'll tell you about, I'm going to use a 1 year gap. Another problem is that the data is highly censored. So, what I mean by censoring is that we often don't have full visibility into the the the data for patients. For example, patients might have only come into the health insurance in 2013.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What types of data are used in risk stratification for diabetes?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What types of data are used in risk stratification for diabetes?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What types of data are used in risk stratification for diabetes?', [\"And so that, then, would be a sign of obesity. So I talked about how the criteria which we use to evaluate risk stratification models are a little bit different from the criteria used to evaluate diagnosis models. Here, I'll tell you, one of the measures that we often use, and it's called positive predictive value. So what we'll do is we'll look at after you've learned your model, look at the top 100 predictions, top 1,000 predictions, top 10,000 predictions, and look to see what fraction of those patients went on to actually develop type 2 diabetes. And, of course, this is done using held out data. Now the reason why you might be interested in different levels is because you might want to target different interventions depending on on the risk and cost. For example, a very low cost intervention, one of the ones that that we did was sending a text message to patients who have who who are who are suspected to have high risk of developing type 2 diabetes.\", \"And so that, then, would be a sign of obesity. So I talked about how the criteria which we use to evaluate risk stratification models are a little bit different from the criteria used to evaluate diagnosis models. Here, I'll tell you, one of the measures that we often use, and it's called positive predictive value. So what we'll do is we'll look at after you've learned your model, look at the top 100 predictions, top 1,000 predictions, top 10,000 predictions, and look to see what fraction of those patients went on to actually develop type 2 diabetes. And, of course, this is done using held out data. Now the reason why you might be interested in different levels is because you might want to target different interventions depending on on the risk and cost. For example, a very low cost intervention, one of the ones that that we did was sending a text message to patients who have who who are who are suspected to have high risk of developing type 2 diabetes.\", \"Creatinine, potassium, glucose, liver enzymes are all the most popular lab tests. And that's not surprising because often, there is a panel called the CBC panel, which is what you would get in your annual physical. And that has many of these top laboratory test results. But then, as you look down into the tail, there are many other laboratory test results that are more specialized in nature. For example, hemoglobin a 1 c is used to track roughly 3 month average of blood glucose and is used to understand a patient's diabetes status. So that's just to give you a sense of what is the data behind the scenes. Now let's think about how do we really derive how do we tackle how do we formulate this risk stratification problem as a machine learning problem? Well, today, I'll give you one example of how to formulate it as a machine learning problem. But in in Tuesday's lecture, I'll tell you several other ways. Here, we're going to think about a reduction to binary classification. And we're going to ask we're gonna go back in time.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Why is L1 regularization used in logistic regression for risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Why is L1 regularization used in logistic regression for risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'Why is L1 regularization used in logistic regression for risk stratification?', [\"1st, it can help prevent overfitting in settings where there exists a very good risk model that uses a small number of features. And to point out, that's not a crazy idea that there might exist a risk model that uses a small number of features. Right? Because remember, think back to that Apgar score or the FINRISK, which was used to predict diabetes in in Finland. Each of those had only 5 to 20 questions. And based on the answers to those 5 to 20 questions, one could get a pretty good idea of what the risk is of that patient. Right? So the fact that there might be a small number of features that are that are together sufficient is actually a very reasonable prior. And it's one reason why l one regularization is actually very well suited to these types of risk stratification problems on this type of data. The second reason is one of interpretability. If one wants to then ask, well, what are the features that actually were used by this model to make predictions? When you find only 20 or a few hundred features, you can enumerate all of them and look to see what they are, and that way understand what is going on into the predictions that are that are made.\", \"1st, it can help prevent overfitting in settings where there exists a very good risk model that uses a small number of features. And to point out, that's not a crazy idea that there might exist a risk model that uses a small number of features. Right? Because remember, think back to that Apgar score or the FINRISK, which was used to predict diabetes in in Finland. Each of those had only 5 to 20 questions. And based on the answers to those 5 to 20 questions, one could get a pretty good idea of what the risk is of that patient. Right? So the fact that there might be a small number of features that are that are together sufficient is actually a very reasonable prior. And it's one reason why l one regularization is actually very well suited to these types of risk stratification problems on this type of data. The second reason is one of interpretability. If one wants to then ask, well, what are the features that actually were used by this model to make predictions? When you find only 20 or a few hundred features, you can enumerate all of them and look to see what they are, and that way understand what is going on into the predictions that are that are made.\", \"Then, we've excluded that patient from the population, and we might be really biasing the results of the model by now taking away a whole set of the of the population where this model would have been really important to apply. So thinking about how you really do this inclusion exclusion, how that changes the generalizability of the model you get is something that should be at the top of your mind. So the the machine learning algorithm used in in that paper which you've read is l one regularized logistic regression. One of the reasons for using l one regularized logistic regression is because it provides a way to use a high dimensional feature set. But at the same time, it allows one to do feature selection. So I'll go more into detail on that in just a moment. I imagine most of you have sorry. All of you should be familiar with the idea of formulating machine learning as an optimization problem, where you have some loss function and you have some regularization term. W, in this case, is the weights of your linear model, which we're trying to learn.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is MYCIN and why was it never used in practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is MYCIN and why was it never used in practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What is MYCIN and why was it never used in practice?', [\"The computer responds, my understanding is the name of the patient is Joe. Respiratory tract is one of the symptoms the patient had. Then the clinician writes, a couple of days before the admission, he had malaise, which is general tiredness. The computer responds, please give me a date of admission. The clinician responds, March 12, 1979, and the computer again confirms that it's understood appropriately. And this is the preface to the later diagnostic stages. So the ideas of how AI can really impact medicine have been around a long time, yet these algorithms, which have been shown to be very effective, even going back to the 19 seventies, didn't translate into clinical care. A second example, oh, so equally impressive in its nature, was work from the 19 eighties at at in Pittsburgh, developing what's known as the Internist 1 or Quick Medical Reference System. This was now used not for infectious diseases, but for primary care. Here, one might ask, how can we try to do diagnosis at a much larger scale where patients might come in with 1 of 100 of different diseases and could report thousands of different symptoms, each one giving you some view, noisy view, into what might be going on with patients' health.\", \"The computer responds, my understanding is the name of the patient is Joe. Respiratory tract is one of the symptoms the patient had. Then the clinician writes, a couple of days before the admission, he had malaise, which is general tiredness. The computer responds, please give me a date of admission. The clinician responds, March 12, 1979, and the computer again confirms that it's understood appropriately. And this is the preface to the later diagnostic stages. So the ideas of how AI can really impact medicine have been around a long time, yet these algorithms, which have been shown to be very effective, even going back to the 19 seventies, didn't translate into clinical care. A second example, oh, so equally impressive in its nature, was work from the 19 eighties at at in Pittsburgh, developing what's known as the Internist 1 or Quick Medical Reference System. This was now used not for infectious diseases, but for primary care. Here, one might ask, how can we try to do diagnosis at a much larger scale where patients might come in with 1 of 100 of different diseases and could report thousands of different symptoms, each one giving you some view, noisy view, into what might be going on with patients' health.\", \"It's a it's an autoimmune condition, where for each patient over a series of different visits, one would record, for example, here it shows this is visit number 1. The date was January 17, 2007, 1979. The knee pain, patients with knee pain was reported as severe. Their fatigue was moderate. Temperature was 38.5 Celsius. The diagnosis for this patient was actually a different autoimmune condition called systemic lupus. We have some laboratory test values for their creatinine and blood urea nitrogen. And we know something about their medication. In this case, they were on prednisone, a steroid. And one has this data at every point in time. This is recorded almost certainly was recorded on paper, and then later, these were collected into into a computer format. But then it provides the possibility to ask questions and make new discoveries. So, for example, in this work, there was a discovery module which would make causal hypotheses about what what aspects might cause other aspects.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some reasons why AI in healthcare is more promising today compared to the past?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', [\"And I'll point out a few examples of that in the rest of today's lecture. So all of this coming together, the data availability, the advances in other fields of machine learning, and the huge amount of financial potential financial gain in health care and the potential social impact it could have has not gone unnoticed. And there's a huge amount of industry interest in this field. These are just some examples from from names I think many of you are familiar with, like DeepMind Health and IBM Watson, to start up companies like Bay Labs and PathAI, which is here in Boston, all of which are really trying to build the next generation of tools for health care now based on machine learning algorithms. There's been quite a 1,000,000,000 of dollars of funding in in the recent quarters towards digital health efforts with hundreds of different start ups that are focused specifically on using artificial intelligence in health care.\", \"And I'll point out a few examples of that in the rest of today's lecture. So all of this coming together, the data availability, the advances in other fields of machine learning, and the huge amount of financial potential financial gain in health care and the potential social impact it could have has not gone unnoticed. And there's a huge amount of industry interest in this field. These are just some examples from, from names I think many of you are familiar with, like DeepMind Health and IBM Watson, to start up companies like Bay Labs and PathAI, which is here in Boston, all of which are really trying to build the next generation of tools for health care now based on machine learning algorithms. There's been quite a 1,000,000,000 of dollars of funding in in the recent quarters towards digital health efforts with hundreds of different start ups that are focused specifically on using artificial intelligence in health care.\", \"They might be 60 neurons, then 7, then 6, for example, in terms of each of the layers of of the of the neural network. By the way, that that sort of makes sense given the type of data that was fed into it. So none of this is new in terms of the goals. So what's changed? Why do I think that despite that the fact that we've had what could arguably be called a failure for the last 30 or 40 years, that we might actually have some chance of succeeding now? And the big differentiator, what I'll call now the opportunity, is data. So whereas in the past, much of the work in artificial intelligence in medicine was not data driven, it was based on trying to elicit as much domain knowledge as one can from clinical domain experts, in some cases, gathering a little bit of data. Today, we have an amazing opportunity because of the prevalence of electronic medical records, both in United States and elsewhere. Now here in the United States, for example, the story wasn't that way even back in 2,008, when the adoption of electronic medical records was under 10% across the US.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How can machine learning transform emergency departments?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How can machine learning transform emergency departments?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'How can machine learning transform emergency departments?', [\"In a few lectures, I'll talk to you about techniques from the eighties nineties, which were based on trying to signal processing, trying to detect where are the peaks of this signal, look at the distance between peaks. And more recently, because of the large wealth of data that's available, we've been using convolutional neural network based approaches to try to understand this data and predict from it. Yet another example from the ER really has to do with not how do we care for the patient today, but how do we get better data, which will then result in taking better care of the patient tomorrow. And so one example of that, which which my group deployed at Beth Israel Deaconess, and it's still running there in the emergency department, has to do with getting higher quality chief complaints. The chief complaint is the, it's usually a very short 2 or 3 word quantity, like, left knee pain, rectal pain, right right upper quadrant, RUQ, abdominal pain. And it's just a very quick summary of why did the patient come into the ER today.\", \"In a few lectures, I'll talk to you about techniques from the eighties nineties, which were based on trying to signal processing, trying to detect where are the peaks of this signal, look at the distance between peaks. And more recently, because of the large wealth of data that's available, we've been using convolutional neural network based approaches to try to understand this data and predict from it. Yet another example from the ER really has to do with not how do we care for the patient today, but how do we get better data, which will then result in taking better care of the patient tomorrow. And so one example of that, which which my group deployed at Beth Israel Deaconess, and it's still running there in the emergency department, has to do with getting higher quality chief complaints. The chief complaint is the, it's usually a very short 2 or 3 word quantity, like, left knee pain, rectal pain, right right upper quadrant, RUQ, abdominal pain. And it's just a very quick summary of why did the patient come into the ER today.\", \"And here's one example where it says, the ED dashboard, the emergency department dashboard, decision support algorithms have determined this patient may be eligible for the atrial cellulitis pathway. Cellulitis is often caused by infections. Please choose from one of the options. Enroll in the pathway, decline. And if you decline, you must include a comment for the reviewers. Now, if you clicked on enroll in the pathway, at that moment, machine learning disappears. Rather, there's a standardized process. It's an algorithm, but it's a deterministic algorithm for how patients with cellulitis should be properly managed, diagnosed, and treated. That algorithm comes from best practices, comes from clinicians coming together, analyzing past data, understanding what would be good ways to treat patients of this type, and then formalizing that in a document. The challenge is that there might be 100 or even 1000 of these best practices.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some challenges unique to machine learning in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some challenges unique to machine learning in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some challenges unique to machine learning in healthcare?', [\"I'll just stick to your independence. We hope. So what's unique about machine learning health care? I gave you already some hints at this. So first, health care is ultimately, unfortunately, about life or death decisions. Right? So we need robust algorithms that don't screw up. A prime example of this, which I'll tell you a little bit more about, in towards the end of the semester, is, from a major software error that occurred something like, 20, 30 years ago, in a, in an x-ray type device where an overwhelming amount of radiation was exposed to a patient just because of a software overflow problem, a bug. And, of course, that resulted in a number of patients dying. So that was a software error from decades ago where there was no machine learning in the loop.\", \"I'll just stick to your independence. We hope. So what's unique about machine learning health care? I gave you already some hints at this. So first, health care is ultimately, unfortunately, about life or death decisions. Right? So we need robust algorithms that don't screw up. A prime example of this, which I'll tell you a little bit more about, in towards the end of the semester, is, from a major software error that occurred something like, 20, 30 years ago, in a, in an x-ray type device where an overwhelming amount of radiation was exposed to a patient just because of a software overflow problem, a bug. And, of course, that resulted in a number of patients dying. So that was a software error from decades ago where there was no machine learning in the loop.\", \"Now more broadly, this is a young field. So for example, there just recently, just about 3 years ago, was created the first conference on machine learning in health care by that name. And new publication venues are being created every single day by Nature, Landsat, and and also machine learning journals for publishing research on machine learning healthcare. Because of some of the issues we talked about, like access to data and not very good benchmarks, reproducibility has been a major challenge. And this is, again, something that the field is only now starting to really grapple with. And so as part of this course, also many of you are going to be are currently PhD students or will soon be PhD students. We're going to think through what are some of the challenges for the research field. What are some of the open problems that you might wanna work on either during your PhD or during your future career?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some examples of publicly available healthcare datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some examples of publicly available healthcare datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E869103790>, 'What are some examples of publicly available healthcare datasets?', [\"And, of course, also medications that are being prescribed as as it goes. And so this is a wealth of data that now one could use to try to study at least study in a very narrow setting of intensive care unit how machine learning could be used in that in that location. And I don't wanna underemphasize the importance of this database, both through this course and to the broader field. This is really the only publicly available electronic medical record dataset of any reasonable size in the whole world. And it was created here at MIT. And we'll be using it extensively in our homework assignments as a result. There are other datasets that aren't publicly available, but which have been gathered by by industry. And one prime example is the Truven MarketScan database, which is which was created by a company called Truven, which was later acquired by IBM, as I'll tell you about more in a few minutes. Now this data, and there are many competing companies that that have similar datasets, is created not from electronic medical records, but rather from typically, it's created from insurance claims.\", \"And, of course, also medications that are being prescribed as as it goes. And so this is a wealth of data that now one could use to try to study at least study in a very narrow setting of intensive care unit how machine learning could be used in that in that location. And I don't wanna underemphasize the importance of this database, both through this course and to the broader field. This is really the only publicly available electronic medical record dataset of any reasonable size in the whole world. And it was created here at MIT. And we'll be using it extensively in our homework assignments as a result. There are other datasets that aren't publicly available, but which have been gathered by by industry. And one prime example is the Truven MarketScan database, which is which was created by a company called Truven, which was later acquired by IBM, as I'll tell you about more in a few minutes. Now this data, and there are many competing companies that that have similar datasets, is created not from electronic medical records, but rather from typically, it's created from insurance claims.\", \"And fingers crossed, it looks like we'll get access to this database for our homework and projects for this semester. Now there are a lot a lot of other initiatives that are that are creating large datasets. A really important example here in the US is President Obama's Precision Medicine Initiative, which has since been renamed to the All of Us Initiative. And this initiative is creating a dataset of 1,000,000 patients drawn in a representative manner from across the United States to capture patients, both poor and rich, patients who are healthy and have chronic disease, with a goal of trying to create a research database where all of us and other people, both inside and outside the US, could do research to make medical discoveries. And this will include data such as data from a baseline health exam where the typical vitals are taken, blood blood is drawn. It'll combine data of the previous tube types I've mentioned, including both data from electronic medical records and health insurance claims. And then a lot of this work is also happening here in Boston.\"])\n",
      "\n",
      "Evaluating chunk size: 120s with overlap: 20s\n",
      "instrumenting <class '__main__.ContentRetriever'> for base <class '__main__.ContentRetriever'>\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting search\n",
      "skipping base <class 'object'> because of class\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the primary function of the heart in the circulatory system?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the primary function of the heart in the circulatory system?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the primary function of the heart in the circulatory system?', [\"So every time people try to get funding for for coronary heart disease, they try to talk up just how important it is. So this is still, you know, we have some battles with with the oncology people, but this is still the leading cause of of death in the world. And and then people are like, oh, you're just you're just you're just emphasizing the developed world. There's, you know, lots of lots of communicable diseases that matter much more. So even if you look at those and you sort of look at the bottom here, this still if this is sort of all causes of death age adjusted, cardiovascular disease is still sort of number 1 amongst that. So so certainly it remains important, and and sort of increasingly so in some of the developing world also. So, it's important to think a little bit about what the heart does because this is gonna guide at least the way that diseases have been classified. So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps about 5 liters of blood a minute, and with exercise, that can go up 5 to 7 fold or so with with sort of conditioned athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about 3 seconds, you are likely to to to get light headed or pass out. So you have to maintain a sort of this rhythmic beat in your heart, and and you can kinda compute what that would be in somewhere around 2,000,000,000 beats in a in a typical lifetime. So I'm gonna show a lot of pictures and videos throughout this, so it's probably worthwhile just to take a pause a little bit and talk about what the what the anatomy of the heart is. So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava. This is draining from the brain, this is draining from the lower body, and then enters into a chamber called the right atrium.\", \"So every time people try to get funding for for coronary heart disease, they try to talk up just how important it is. So this is still, you know, we have some battles with with the oncology people, but this is still the leading cause of of death in the world. And and then people are like, oh, you're just you're just you're just emphasizing the developed world. There's, you know, lots of lots of communicable diseases that matter much more. So even if you look at those and you sort of look at the bottom here, this still if this is sort of all causes of death age adjusted, cardiovascular disease is still sort of 1 amongst that. So so certainly it remains important, and and sort of increasingly so in some of the developing world also. So, it's important to think a little bit about what the heart does because this is gonna guide at least the way that diseases have been classified. So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps 5 liters of blood a minute, and with exercise, that can go 5 to 7 fold or so with with sort of condition athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about three seconds, you are likely to to to get light headed or pass out. So you have to maintain a sort of this rhythmic beating your heart, and and you can kinda compute what that would be in somewhere 2000000000 beats in a in a typical lifetime. So I'm gonna show a lot of pictures and videos throughout this, so it's probably worthwhile just to take a pause a little bit and talk about what the what the anatomy of the heart is. So so the heart is sort of sits like this. So the pointy part is kind of sitting up to the side like that. And so so I'm gonna just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava. This is draining from the brain. This is draining from the lower body, and then enters into a chamber called the right atrium.\", \"So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava. This is draining from the brain, this is draining from the lower body, and then enters into a chamber called the right atrium. It moves through something called the tricuspid valve into what's called the right ventricle. So right ventricle has got some muscle to it. It pumps into the lungs. There, the blood picks up oxygen, so that's why it's sort of shown as being red here. The the oxygenated blood comes through the left atrium and then into the left ventricle through something called the mitral valve. We'll show you some pictures of the mitral valve later on. And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last last class on the electrical system. So the sinoatrial node is up here in the right atrium, and then conduction sort of goes through. So the p wave on an EKG is is represents the conduction through there. You get through the Savi node where there's a delay, which is the PR interval, and then you get spreading through the ventricles, which is the QRS complex, and then repolarization is the t wave. So that's that's sort of the electrical system. And, of course, these things have to kind of work intimately together. Every sort of like, the every single basic kind of cardiac physiology will show this this diagram called the Wigner's diagram, which really just shows the sort of the interconnectedness of the electrical system. So there's the EKG up there. These are the heart sounds that that a provider would listen to with a stethoscope, and this is capturing the flow of sort of the changes in in pressure in the heart and in the aorta. So heart fills during a period of time called diastole, The mitral valve closes, the ventricle contracts, the pressure increases. This is a period of time called systole. Eventually, something called the aortic valve pops open, blood goes through the rest of the body.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the two circulations the heart conducts in series?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the two circulations the heart conducts in series?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the two circulations the heart conducts in series?', [\"So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava. This is draining from the brain, this is draining from the lower body, and then enters into a chamber called the right atrium. It moves through something called the tricuspid valve into what's called the right ventricle. So right ventricle has got some muscle to it. It pumps into the lungs. There, the blood picks up oxygen, so that's why it's sort of shown as being red here. The the oxygenated blood comes through the left atrium and then into the left ventricle through something called the mitral valve. We'll show you some pictures of the mitral valve later on. And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last last class on the electrical system. So the sinoatrial node is up here in the right atrium, and then conduction sort of goes through. So the p wave on an EKG is is represents the conduction through there. You get through the Savi node where there's a delay, which is the PR interval, and then you get spreading through the ventricles, which is the QRS complex, and then repolarization is the t wave. So that's that's sort of the electrical system. And, of course, these things have to kind of work intimately together. Every sort of like, the every single basic kind of cardiac physiology will show this this diagram called the Wigner's diagram, which really just shows the sort of the interconnectedness of the electrical system. So there's the EKG up there. These are the heart sounds that that a provider would listen to with a stethoscope, and this is capturing the flow of sort of the changes in in pressure in the heart and in the aorta. So heart fills during a period of time called diastole, The mitral valve closes, the ventricle contracts, the pressure increases. This is a period of time called systole. Eventually, something called the aortic valve pops open, blood goes through the rest of the body.\", \"So so the heart is sort of sits like this. So the pointy part is kind of sitting up to the side like that. And so so I'm gonna just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava. This is draining from the brain. This is draining from the lower body, and then enters into a chamber called the right atrium. It moves through something called the tricuspid valve into what's called the right ventricle. So right ventricle has got some muscle to it. It pumps into the lungs. There, the blood picks up oxygen, so that's why it's sort of shown as being red here. The the oxygenated blood comes through the left atrium and then into the left ventricle through something called the mitral valve. We'll show you some pictures of the mitral valve later on. And then the left ventricle, which is the big sort of workhorse of the heart, pumps blood through the left through the rest of the body, through a structure called the aorta. So, so in through the right heart, through the lungs, through the left heart, through the to the rest of the body. And then shown here in yellow is the conduction system. So you guys got a little bit of a conversation last, last class on the electrical system. So the sinoatrial node is up here in the right atrium, and then conduction sort of goes through. So the p wave on an EKG is is represents the conduction through there. You get through the Savi node where there's a delay, which is the PR interval, and then you get spreading through the ventricles, which is the QRS complex, and then, repolarization is the t wave. So that's that's sort of the electrical system. And, of course, these things have to kinda work intimately together. Every, sort of like, the every single basic kind of cardiac physiology will show this this diagram called the Wiggers diagram, which really just shows the sort of the interconnectedness of the electrical system. So there's the EKG up there. These are the heart sounds that that a provider would listen to with the stethoscope, and this is capturing the flow of sort of the changes in in pressure in the heart and in the aorta. So heart fills during a period of time called diastole. The mitral valve closes. The ventricle contracts. The pressure increases. This is a period of time called systole. Eventually, something called the aortic valve pops open.\", \"So every time people try to get funding for for coronary heart disease, they try to talk up just how important it is. So this is still, you know, we have some battles with with the oncology people, but this is still the leading cause of of death in the world. And and then people are like, oh, you're just you're just you're just emphasizing the developed world. There's, you know, lots of lots of communicable diseases that matter much more. So even if you look at those and you sort of look at the bottom here, this still if this is sort of all causes of death age adjusted, cardiovascular disease is still sort of number 1 amongst that. So so certainly it remains important, and and sort of increasingly so in some of the developing world also. So, it's important to think a little bit about what the heart does because this is gonna guide at least the way that diseases have been classified. So the main thing the heart does is it's a pump, and it and it delivers oxygenated blood throughout the circulatory system to all the tissues that need it, the brain, the kidneys, the muscles. And oxygen, of course, is required for ATP production. So it's a pretty impressive organ. Pumps about 5 liters of blood a minute, and with exercise, that can go up 5 to 7 fold or so with with sort of conditioned athletes, not me, but but other people can can kinda ramp that up substantially. And we have this sort of need to keep a very, very regular beat. So if you pause for about 3 seconds, you are likely to to to get light headed or pass out. So you have to maintain a sort of this rhythmic beat in your heart, and and you can kinda compute what that would be in somewhere around 2,000,000,000 beats in a in a typical lifetime. So I'm gonna show a lot of pictures and videos throughout this, so it's probably worthwhile just to take a pause a little bit and talk about what the what the anatomy of the heart is. So so the heart is sort of sits like this, so the pointy part is kind of sitting out to the side like that. And so so I'm going to just sort of describe the flow of blood. So the blood comes in something called the inferior vena cava or the superior vena cava. This is draining from the brain, this is draining from the lower body, and then enters into a chamber called the right atrium.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Which imaging technique uses ultrasound and is commonly used for diagnosing heart conditions like heart failure?', [\"Because because, you know, so a typical Echo will have an ECG to use to gate, but the handhelds don't. So we wanna move away from the things that involve the fanciness and all the bells and whistles. We're trying to use the the image alone to be able to tell the cardiac cycle. So that's that's how we did it. Yes, Steve. Since you mentioned handhelds, wouldn't the ultrasound and handhelds look a bit different from these? Or do you think They look pretty similar. I mean, we got some we got we got some now, and we I mean, they look pretty similar in terms of the quality of the images, and you can acquire the very same view. So so I I think we haven't shown that we can do it off those, in part because there just isn't enough training data. But they look pretty nice. And I know, I mean, at UCSF and at at Brigham, all the fellows are using it. It looks pretty much the same in terms of the you know, the transducers are sort of similar, and image quality is very good, resolution is very good, frame rate probably doesn't get up as high necessarily, but for the most part, I don't think it's that different. So that is that is kind of the next phase. Yes. Could you comment on, because you mentioned how each of 3 examples could be used in a surveillance algorithm. Yeah. Could you comment on the sort of the where along this true positive, false positive trade off you would you would actually be realistic to use? Yeah. Yeah. It's a good point. I think I think it would vary for every single 1 of those, and you really wanna have some kind of costs on what the so I would I would typically on the side of higher sensitivity and let, you know, dump it on the cardiologist to be able to to so so I would work in, you know, but but I think I mean, you have to sort of pick some and if you let's say let's say you're a project you're a project manager. Choose 1 of these three and maybe pick some Oh, okay. As long as 3. Yeah. So this is a pretty rare disease. So your priors are pretty low in terms of these individuals. And so I, you know, I think you probably would probably wanna air somewhere along along this this sort of, you know, this area here. And, and so just working on what the so you probably will still be a relatively high rate of false positives even in that space.\", \"And then you have these kind of noninvasive technologies like PET and SPECT that use radionuclatides, like technetium, rubidium, and they look for abnormalities in blood flow to detect whether noninvasively there's some patch of the heart that isn't getting enough blood. If you get one of these and it's abnormal, often you go over there. You can take a trip to the movies, as my old teachers used to say, and then you may get, you may find yourself with an angioplasty or stent or a bypass. So one of the sort of sad things about cardiology is we don't define our diseases by biology. We define our diseases often related to whether the anatomy or the physiology is abnormal or or normal, usually based on some of these images or some of these numbers. Okay. So so we have to make decisions, and we often use these very same things too to be able to make some decisions. So we have to decide whether we wanna put a defibrillator. And if to do so, you often need to to get a echocardiogram to look at the pumping function of the heart. If you wanna decide on whether somebody needs angioplasty, you have to get an angiogram. If you wanna decide to get a valve replacement, you need an echo. But but, some of these other ones actually don't involve any imaging, and this is sort of one of the challenges that I'm gonna talk about is that is that all of the sort of the future, if you can imagine building brand new risk models, new classification models, you're stuck with the data that's out there. And the data that's out there has ultimately been collected because somebody feels like it's worth paying for it already. So if you wanna build a brand new risk model for who's gonna have a myocardial infarction, you're probably not gonna have any echocardiograms to be able to use for that because nobody is gonna have paid for that to be collected in the first place. So so this is a problem, to to be able to innovate. I got to keep on coming back to that because I think you're going to be shocked by the small sample sizes that we face in in some of these things. And part of it is because if you just want to piggyback on what insurers are going to be willing to pay for to get your data, you're going to be stuck with only being able to work off the stuff we already know something about. So much of of my work has been really trying to think about how we can change that. Okay. So just a little bit more and then we can get into sort of a little bit more meat. So so the the sort of the universal standard for how data imaging's data is stored is something called DICOM, so digital imaging and communication standard. And and really at the end of the day, there's some compressed data for the images.\", \"These are the heart sounds that that a provider would listen to with a stethoscope, and this is capturing the flow of sort of the changes in in pressure in the heart and in the aorta. So heart fills during a period of time called diastole, The mitral valve closes, the ventricle contracts, the pressure increases. This is a period of time called systole. Eventually, something called the aortic valve pops open, blood goes through the rest of the body. Heart finally starts to relax. Atrioventricular valve closes, then you fill again. So this happens again and again and again in a cyclical way, and you have this kind of combination of electrical and mechanical properties. Okay. So I have some pictures here. These are all MRIs. I'm going to talk about echocardiography, which is sort of these very ugly, grainy things that I unfortunately have to work with. MRIs are beautiful, but very expensive. So there's a reason for that. So this is something called the the long axis view of the heart. So this is the thick walled left ventricle there, to the left atrium there. And you can see sort of this beautiful turbulent flow of blood in there, and it's flowing from the atrium to the ventricle. So this is the, another patient. It's called the short axis view. There's the left ventricle and the right ventricle there. So we're kind of looking at it somewhat obliquely. And then this is another view called the it's a little bit dull there. I'm sorry. We can brighten it a little bit. This is the this is sort of what's called the 4 chamber view, so you can see the left ventricle and right ventricle here. So so these the the reason for these different views is ultimately that people had have measures of function and measures of disease that go along with these specific views. So you're gonna see them kinda coming back again and again. Okay. So the way that physicians like to organize, disease definitions is really around some of these same kind of functions. So failures of the heart to pump fail pump properly causes a disease called heart failure. And this shows up in terms of being out of breath, having fluid build up in the belly and the legs, and this is treated with medications. Sometimes you can have some artificial devices to help the heart pump, and ultimately you could even have a transplant depending on how severe it is.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What challenge does cardiac motion pose to high-quality imaging scans?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What challenge does cardiac motion pose to high-quality imaging scans?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What challenge does cardiac motion pose to high-quality imaging scans?', [\"So you have the raw imaging data, but all the clinical stuff is somewhere else. So you have to sometimes link that, and so you need to get access there. And so just to give you a little bit of an idea of scale, so we're about to get all of the ECGs from Brigham and Women's, which is about 30,000,000, stored kind of historically. And this is all related to cost. So positron emission tomography, you can get about 8,000 or so, and we're one of the busiest centers for that. You know, echocardiograms are in the 300,000 to 500,000 ranges archived, so that gets a little bit more interesting. Okay. So what a DICOM header looks like. You have some sort of, identifiers, and then you have some information there, attributes of the images, patient name, date of birth, frame rate, these kind of things are there, and there's some variability. So it's never never quite easy. Okay. So, these different modalities have some different benefits to them, and this is why they're used for for one disease or the other. And so one of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself. And so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you want to have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately doesn't deal well with with the moving aspect. So coronary angiography has very, very fast frame rates. So that's x-ray, and that's sort of very fast. Echocardiography can be quite fast. MRI and CT are not quite as good, and so there's some degradation of the image. As a result, people do something called gating, where they'll take the electrocardiogram, the ECG, and try to line up different portions of different heartbeats and say, well, you know, we'll take this image from here, we'll line it up with this one from there, this one from there. I'm going to talk a little bit about that from about registration, but ultimately that's a problem that people have to deal with. So it's a computer vision problem of interest. Okay. Preamble's almost done. Okay. So so why do we even imagine any of this stuff is going to be useful?\", \"So you have the raw imaging data, but all the clinical stuff is somewhere else. So you have to sometimes link that, and so you need to get access there. And so just to give you a little bit of an idea of scale, so we're about to get all the ECGs from Brigham and Women's, which is about 30000000, stored kind of historically. And this is all related to cost. So positron emission tomography, you can get about 8000 or so, and 1 of the busiest centers for that. You know, echocardiograms are in 300000 to 5 hundred thousand ranges archive. So that gets a little bit more interesting. Okay. So what a DICOM header looks like. You have some sort of, identifiers, and then you have some information there, attributes of the images, patient name, date of birth, frame rate, these kind of things are there, and there's some variability. So it's never never quite easy. Okay. So, these different modalities have some different benefits to them, and this is why they're used for for 1 disease or the other. And so 1 of the real headaches is that the heart moves. So the chest wall moves because we breathe, and the heart moves too. So you have to image something that it has enough temporal frequency that you're you're sort of not overwhelmed by the basic movement of the heart itself, and so some of these things aren't great. So so SPECT or PET acquire their images, which are, you know, radioactive counts over minutes. So that's certainly a problem when it comes to something that's moving like that and if you wanna have high resolution. So you typically don't have you have very poor spatial resolution for something that ultimately, doesn't deal well with with the moving aspect. So coronary angiography has very, very fast frame rates. So that's x-ray, and that's sort of very fast. Echocardiography can be quite fast. MRI and CT are not quite as good, and so there's some degradation of the image. As a result, people do something called gating, where they'll take the electrocardiogram, the ECG, and try to line up different portions of different heartbeats and say, well, you know, we'll take this image from here, we'll line it up with 1 from there, 1 from there. I'm gonna talk a little bit about that and from about registration, but ultimately that's a problem that people have to deal with. So it's a computer vision problem of interest. Okay. Preamble's almost done. Okay. So, so why do we even imagine any of this stuff is going to be useful?\", \"This is a not just a problem for us, but a problem for many people in this field. So so we need to be a little bit more adventurous in terms of trying some of these other methods. We did try a little bit of of that and didn't find huge huge gains, but I think ultimately there still needs to be a little bit more work there. Okay. So last thing I'm going to talk about before getting into to to my work is really this idea of image registration. So I talked about how there are sometimes some techniques that have limitations either in terms of spatial resolution or temporal resolution. So this is a PET scan here, this sort of reddish glow here. And in the background, we have a CAT scan of the of the heart. And so clearly this is a poorly registered image where you have this the PET scan kind of floating out here, but it really should be lined up here, and so you have something that's registered better there. Also mentioned this problem about gating. So ultimately, if you have a a image taken from different parts of different cardiac cycles, you're going to have to align them in some way. So this is a very it sounds like a very mature problem in the computer vision world. We haven't done anything in this space, but ultimately it has sort of been around for decades. I thought I would just at least touch it, touch upon it. So this is sort of the old school way, and then now people are starting to use conditional variational autoencoders to be able to learn geometric transformations. This is this is the the Siemens group out in Princeton that has this paper. Again, nothing I'm going to focus on. Just wanted to bring it up as being an area that remains of interest. Okay. So I think we're doing okay. But you said 4. 355. 355. Okay. Alright. And interrupt. Please interrupt. Okay? Don't I'm hoping that I'm not talking too fast. Okay. So so I'm gonna talk about, you know, as David said, I this was not my field. But increasingly there is some interest in terms of getting involved in it, in part because of my frustrations with clinical medicine. So this is one of my frustrations with clinical medicine. So cardiology has not really changed and and and one of the things that fails at miserably is picking up early onset disease.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is a significant benefit of applying machine learning to cardiac imaging?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is a significant benefit of applying machine learning to cardiac imaging?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is a significant benefit of applying machine learning to cardiac imaging?', [\"So welcome, everyone. Today is the first of, what will be a series of of 4 guest lectures throughout the semester. There will be 2 guest lectures the week from starting the week from today, and then there'll be another 1 towards the end of the semester. And what, Pete and I decided to do is to bring in people who know a lot more than us about some area of expertise. And today's instance is going to be about, about cardiovascular medicine, in particular, about how to use imaging and machine learning on images in that context. And for today's lecture, we're we're, very excited to have, Professor Rahul Deo to speak. Rahul's name kept on showing up as I did research over the last couple of years. First, I my group was starting to get interested in echocardiography and we said, oh, here's an interesting paper to read on it. We read it, and then we read another paper on doing subtyping of of preserved ejection fraction as a type of heart failure, and we read it. I wasn't really paying attention to the names on the papers, and then suddenly someone told me there's this guy moving to Boston next month who's doing a lot of interesting work and interested in machine learning. You should go meet him. And of course I meet him and then I tell him about these papers I've read and he said, oh, I wrote all of those papers. He was the senior author in that. So Rahul's been around for a while. He he, is is already, somewhat senior in this field. He started out doing his, his medical school training at Cornell in, Cornell Medical School in, New York City at the same time as doing his PhD at Rockefeller University, and then he spent the first large chunk after his postdoctoral training up at at, up here in Boston at Harvard Medical School. He spent a large chunk of his career, as faculty at UCSF in California and just moved back this past year to take a position as the chief data scientist Is that right?\", \"So welcome, everyone. Today is the first of what will be a series of 4 guest lectures throughout the semester. There will be 2 guest lectures the week from starting the week from today, and then there'll be another one towards the end of the semester. And what Pete and I decided to do is to bring in people who know a lot more than us about some area of expertise. And today's instance is going to be about, about cardiovascular medicine, in particular, about how to use imaging and machine learning on images in that context. And for today's lecture, we're we're, very excited to have, professor Rahul Deo to speak. Rahul's name kept on showing up as I did research over the last couple of years. First, I my group was starting to get interested in echocardiography, and we said, oh, here's an interesting paper to read on it. We read it, and then we wrote another paper on doing subtyping of of ejection fraction as a type of heart failure, and we read it. I wasn't really paying attention to the names on the papers, and then suddenly someone told me there's this guy moving to Boston next month who's doing a lot of interesting work and interested in machine learning. You should go meet him. And, of course, I meet him and then I tell him about these papers I've read, and he said, oh, I wrote all of those papers. He was the senior author in that. So Rahul's been around for a while. He he, is is already somewhat senior in this field. He started out doing his, his medical school training at Cornell in Cornell Medical School in New York City at the same time as doing his PhD at Rockefeller University, and then he spent the first large chunk after his postdoctoral training up at at, up here in Boston at Harvard Medical School. He spent large chunk of his career, as faculty at UCSF in California and just moved back this past year to take a position as the chief data scientist Is that right?\", \"Many of the starting things we're doing are kind of already picking up what everybody else here is already doing, but at the same time so it it's it's it's it's okay from that standpoint, but it really has to make its way. And that means that we have to have some mature understanding of what makes its way into practice, where the resistance will be. So the the lecture will be kind of peppered throughout with some kind of opinions and comments in that, and hopefully that will be useful. So just a quick outline. Just gonna introduce cardiac structure and function. Probably not part of the the sort of the regular undergraduate and graduate training here at MIT. Talk a little bit about what the major sort of cardiac diagnostics are and how they're used. And and all of this is really to help guide the the sort of the thought and the decision making about how we would ever automate and and bring this into sort of how to bring machine learning artificial intelligence to actual clinical practice. Because you need to give enough background so you realize what the sort of the the challenges are. And then the question probably everybody has is where's the data? How how would how would one get access to some of this stuff to be able to potentially do work in this area? And then I'm gonna sort of venture a little bit into computer vision and just talk about some of the the topics that that at least I've been thinking about that are relevant to to what we're doing. And then talk about some of this work around an automated pipeline for echocardiogram, not as a by any means a gold standard, but really just as sort of an initial foray into trying to make make a dent into this. And then thinking a little bit about what lessons David mentioned that you talked about electrocardiograms last last week or last class. And and so a little bit of some of the ideas from there and how they would lend themselves to insights about future types of approaches with automated interpretation. And then, my background is actually more in biology, so I haven't got to kind of come back and say, oh, okay, enough with all this imaging stuff, what about biology? How can we make some insights there? Okay. So every time people try to get funding for for coronary heart disease, they try to talk up just how important it is. So this is still, you know, we have some battles with with the oncology people, but this is still the leading cause of of death in the world. And and then people are like, oh, you're just you're just you're just emphasizing the developed world. There's, you know, lots of lots of communicable diseases that matter much more.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the two primary challenges in mammographic analysis for early breast cancer detection?', [\"Okay. Great. Well, thank you for the great setup. So for this section, I'm gonna talk about some of our work in interpreting mammograms for cancer. Specifically, it's gonna go into cancer detection and triaging mammograms. Next, we'll talk about kind of our technical approach to breast cancer risk. And then finally, close-up in the many many different ways to mess up and the way things can go wrong and how does a poor clinical implementation. So let's kind of look more closely at the numbers of the actual breast cancer screening workflow. So as Kanye already said, you might, you know, see something like a 1,000 patients, all of them take mammograms, and of that 1,000, on average, maybe a 100 be called back for additional imaging. Of that 100, something like 20 will get biopsied and end up with maybe 5 or 6 diagnoses of breast cancer. So one very clear thing you see about, you know, problems when you look at this funnel is that way over 99% of people that you see in a given day are cancer free, so your actual incidence is very low. And so there's kind of a natural question that can come up, what can you do in terms of modeling if you have, you know, an even okay cancer detection model to raise the incidence of this population but automatically reading a portion of the population is healthy? So everybody just follow that broad idea? That's enough head nods. So the broad idea here is we're gonna train a cancer detection model to try to find cancer as well as we can. Given that, we're gonna try to say, what's a threshold on a development set such that we can kinda say, below the threshold, no one has cancer? And if we use that at test time, simulate a clinical computation, what would that look like? And can we actually do better by doing this kind of process? And the kind of broad plan of how I'm gonna talk about this, I'm gonna do this for the next product as well. First, we're gonna talk about the kind of data set collection and how we think about, like, you know, what is good data and how do we, you know, think about that. Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks, specifically in cancer and also, obviously, risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 2009 to 2016. This started off with about 280,000 cancers.\", \"Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks, specifically in cancer and also, obviously, risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 2009 to 2016. This started off with about 280,000 cancers. And once we kinda filtered for at least 1 year follow-up, we ended up with this, you know, final setting where we had, 220,000 mammograms for training, and about 26,000 for development and testing. And the way we had our outcomes to say, you know, is this a positive mammogram or not? We didn't look at what cancers were caught by the radiologist. We'll say, you know, what was cancer that was fine in any means within a year? And where we looked, we looked through the radiology, HR, and the partners kind of 5 hospital registry. And they were really trying to say if a cancer if any way we can tell a cancer occurred, let's mark it as such, regardless of whether it was caught on MRI or some kind of later stage. And so the thing we're trying to do here is just mimic, you know, the real world of whether we not trying to catch cancer. And finally, important details, we always split, by patient so that you're not just your results aren't just memorizing the specific patient didn't have cancer, and so you have some overlap as some bad advice to have. Okay. That was pretty simple. Now, let's go into the modeling. This is gonna kinda follow 2 chunks. One chunk is gonna be on the kind of general challenges and it's kind of shared between the variety of projects, and next is gonna be kind of more specific analysis, for this project. So, a kind of a general question you might be asking, you know, I have some image, I have some outcome. Obviously, this is just image classification. How does it look for ImageNet? Well, it's quite similar. Most lessons are shared, but there are some key differences. So I you know, I give you two examples, one of them is a scene in my kitchen. Can anyone tell me what the object is? This is not a particularly hard question. A dog. Right. Yeah. A dog. It is almost all of those things. So that is my dog, the best dog. Okay. So can anyone tell me, now you had some training with Connie, if this mammogram indicates cancer?\", \"Okay. Great. Well, thank you for the great setup. So for this section, I'm gonna talk about some of our work in interpreting mammograms for cancer. Specifically, it's gonna go into cancer detection and triaging mammograms. Next, we'll talk about kind of our technical approach to breast cancer risk, and then finally close-up in the many many different ways to mess up and the way things can go wrong, and how does a poke in the confrontation. So let's kind of look more closely at the numbers of the actual breast cancer screening workflow. So as Kanye already said, you might, you know, see something like a thousand patients, all of them take mammograms that of that thousand, on average, maybe a hundred be called back for additional imaging. Of that hundred, something like twenty will get biopsied and end up with maybe five or six diagnoses of breast cancer. So one very clear thing you see about, you know, problems when you look at this funnel is that way over ninety nine percent of people that you see in a given day are cancer free, so your actual incidence is very low. And so there's kind of a natural question that can come up, what can you do in terms of modeling if you have, you know, an even okay cancer detection model to raise incidence of this population but automatically reading a portion of the population is healthy? So everybody just follow that broad idea? Okay. It's enough head nods. So the broad idea here is we're gonna train a cancer detection model to try to find cancer as well as we can. Given that, we're gonna try to say, what's a threshold on a development set such that we can kind of say, below the threshold no 1 has cancer? And if we use that at test time, simulate a clinical computation, what would that look like and can we actually do better by doing this kind of process? And the kind of broad plan of how I'm gonna talk about this, I'm gonna do this for the next product as well. First, we're gonna talk about kind of data collection and how we think about like, you know, what is good data and how do we, you know, think about that. Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks specifically in cancer and also obviously risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 02/9 to 2016. This started off with about two hundred eighty thousand cancers and once we kind of filtered for at least one year follow-up, we ended up with this, you know, final setting where we 220000 mammograms for training, and 26000 for development and testing.\"])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\miniconda3\\envs\\snow_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\louis\\miniconda3\\envs\\snow_env\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the four categories of breast tissue density used in medical practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the four categories of breast tissue density used in medical practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are the four categories of breast tissue density used in medical practice?', [\"So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively, and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about? And viewing really, what is the lever to change once you know someone is high risk? Perhaps MRI, perhaps, you know, more frequent screening, and so, like, this is the kind of gap between having a useful technology on the paper side to an actual useful technology in real life. So I am I'm moving on schedule. So now, I'm gonna talk about how to mess up and it's actually quite interesting. There's like so many ways and I've and I've fallen to them a few times myself and it happens. And kind of following the sketch, you can mess up in data collection. It's probably the most common by far. You can mess up in modeling, which I'm doing right now and it's very sad, and you can mess up in analysis, which is really preventable. So in data collection, enriched data sets are the kind of the most common thing you see in the space. If you find a public data set, there's more likely gonna be like 5050 cancer, not cancer, and oftentimes, these data sets collect can have some sort of bias within the way it was collected.\", \"Okay. Raise your hand for right. Here we go. Well done. Well done. Okay. So and the next step, as I said before, is we need to kind of push the clinical rotation because that's where the the rubber hits the road. We identify is there any biases we didn't detect and we can really say, can we deliver this value? So the next project is on assessing breast cancer risk. So this is the same mammogram I heard you earlier. It was diagnosed with breast cancer in 2014. It's actually, my advisor Regina's. And, you can see that, you know, in 2013, you see it's there. In 2012, it looks much less prominent and five years ago, we're looking at breast cancer risk. So if you can tell from an image that is gonna be healthy for a long time, you're really trying to model what's the likelihood of this breast developing cancer in the future. Now, modeling breast cancer risk, as Connie already said, is not a a new problem. It's been a quite researched 1 in the community and the more classical approach that we're gonna look at, other kind of global health factors, the person's age, their family history, whether or not they've had menopause, and kind of any other 1 of these kind of factor we can try to say our markers with their health to try to predict whether or not those persons at risk of developing breast cancer. People have thought that the image contained something before. The way they've thought about this is through this kind of subjective breast density marker and the improvements seen across this are kind of marginal from 61 to 63. And as before, the kind of sketch we're gonna go through is data collection, modeling, and analysis. In data collection, we followed a very similar template. We sought for the consecutive mammograms from 02/9 to 2012. We took outcomes from the EHR once again and the partners registry. We didn't do exclusions based on race or anything of that sort or implants, but we did exclude negatives for follow-up. So if someone didn't have cancer in three years, but like disappear from the system, we didn't count them as negatives that we have some certainty in both the modeling and the analysis. And as always, we split by patients into trained depth test.\", \"Okay. Raise your hand for right. Here we go. Well done. Well done. Okay. So and the next step, as I said before, is really to kinda push the clinical rotation because that's where the the rubber hits the road. We identify, is there any biases we didn't detect? And we can really say, can we deliver this value? So the next project is on assessing breast cancer risk. So this is the same mammogram I heard you earlier. It was diagnosed with breast cancer in 2014. It's actually, my advisor Regina's. And, you can see that, you know, in 2013, you see it's there. In 2012, it looks much less prominent, and 5 years ago, we're looking at breast cancer risk. So if you can tell from an image that is gonna be healthy for a long time, you're really trying to model what's the likelihood of this breast developing cancer in the future. Now, modeling breast cancer risk, as Connie already said, is not a new problem. It's been a quite researched one in the community, and the more classical approach that we're gonna look at, other kind of global health factors, the person's age, their family history, whether or not they've had menopause, and kind of any other or these kind of factor we can try to say our markers of their health to try to predict whether or not those persons at risk of developing breast cancer. People have thought that the image contained something before. The way they've thought about this is through this kind of subjective breast density marker, and the improvements seen across this are kind of marginal from 61 to 63. And as before, the kind of sketch we're gonna go through is data collection, modeling, and analysis. In data collection, we followed a very similar template. We sought for the consecutive mammograms from 2009 to 2012. We took outcomes from the EHR, once again, and the partner's registry. We didn't do exclusions based on race or anything of that sort or implants, but we did exclude negatives for follow-up. So if someone didn't have cancer in 3 years, but, like, disappeared from the system, we didn't count them as negatives that we have some certainty in both the modeling and the analysis. And as always, we split by patients into train that test.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the main advantage of using 3D tomosynthesis over 2D mammography?', [\"So it shows that they're kind of picking up on different things and they're where they disagree gives us both areas to improve and some ancillary benefits because now we can reduce false positives. This directly leads into simulating the impact. 1 of the things we did we said, okay, if people retrospectively on the test set as a simulation before we truly plug it in, if people didn't rebuild the triage threshold, so we can't catch any more cancer this way but we can reduce false positives, what would have happened? So at the top, we have the original performance. So this is % of mammogram sensitivity 90.6 with specificity 93 And in the simulation, the sensitivity dropped not significantly 90.1, but significantly improved 93.7 while looking 80% or eighty one percent of the mammograms. So this is like promising preliminary data, but to reevaluate this and go forward, our next step see if I oh, I'm gonna get to that in a second. Our next step is really do clinical implementation, to really figure out, because there's like a core assumption here was that people read it the same way. But if you have this higher incidence, what does that mean? Can you focus more on the people that are more suspicious? And is the right way to do this just a single threshold to not read? Or have a double ended with the same, these are much more likely to have cancer? And so there is quite a bit of explosion here to say, given we have these tools that give us some probability of cancer, that's not perfect but gives us something, how can we do that to improve care today? So as a quiz, can you tell which of these will be triaged? So this is no cherry picking. I randomly picked 4 mammograms, that were below and above the threshold. Can anyone guess which side, left or right, was triaged? The, this is not a graded quiz, so you know. Chest. Which Oh, wait. Raise your hand for the left. Okay. Raise your hand for right. Here we go. Well done. Well done. Okay. So and the next step, as I said before, is we need to kind of push the clinical rotation because that's where the the rubber hits the road. We identify is there any biases we didn't detect and we can really say, can we deliver this value?\", \"Well, it's quite similar. Most lessons are shared, but there are some key differences. So I, you know, I give you 2 examples, 1 of them is a scene in my kitchen. Can anyone tell me what the object is? This is not a particularly hard question. A dog. Right. Yeah. A dog. It is almost all of those things. So that is my dog, the best dog. Okay, so can anyone tell me, now you had some training with Connie, if this mammogram indicates cancer? Well it does and this is unfair for a couple of reasons. But let's kind of go into like why this is hard. It's unfair in part because, you know, you don't have the training but it's actually a much harder signal to learn. So first, let's kind of delve into it. In this kind of task, the image is really huge. So you have something like a 3 thousand 2 hundred by 2 thousand 6 hundred pixel image. This is a single view of a breast and in that, the actual can show the confer might 50 by 50 pixels. So intuitively, your signal to noise ratio is very different whereas an image in that my dog is like the entire image. She's huge, in real life and in that photo. And the image itself is much smaller. So not only do you have much smaller images, but you're kind of like the relative size of the object in there is much larger. To kind of further compound the difficulty, the pattern that you're looking for inside the mammogram is really context dependent. So if you saw that pattern somewhere else in the breast, it's not doesn't indicate the same thing. And so you really care about where in this kind of global context this comes out and if you kind of take the mammogram at different times with different compressions, you will have this kind of non rigid morphing of the image that's much more difficult to model, whereas that's a more or less context independent dog. You see that kind of frame kind of anywhere you know it's a dog and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just like the number of cancers we have, it's gonna be the cancer might be less than one percent of the mammogram and about point seven percent of your images have cancer. So even in this data set which is from 02/2016 in NGH, a massive imaging center, in total across all of that, we all still have like less than two thousand cancers.\", \"Okay. Great. Well, thank you for the great setup. So for this section, I'm gonna talk about some of our work in interpreting mammograms for cancer. Specifically, it's gonna go into cancer detection and triaging mammograms. Next, we'll talk about kind of our technical approach to breast cancer risk, and then finally close-up in the many many different ways to mess up and the way things can go wrong, and how does a poke in the confrontation. So let's kind of look more closely at the numbers of the actual breast cancer screening workflow. So as Kanye already said, you might, you know, see something like a thousand patients, all of them take mammograms that of that thousand, on average, maybe a hundred be called back for additional imaging. Of that hundred, something like twenty will get biopsied and end up with maybe five or six diagnoses of breast cancer. So one very clear thing you see about, you know, problems when you look at this funnel is that way over ninety nine percent of people that you see in a given day are cancer free, so your actual incidence is very low. And so there's kind of a natural question that can come up, what can you do in terms of modeling if you have, you know, an even okay cancer detection model to raise incidence of this population but automatically reading a portion of the population is healthy? So everybody just follow that broad idea? Okay. It's enough head nods. So the broad idea here is we're gonna train a cancer detection model to try to find cancer as well as we can. Given that, we're gonna try to say, what's a threshold on a development set such that we can kind of say, below the threshold no 1 has cancer? And if we use that at test time, simulate a clinical computation, what would that look like and can we actually do better by doing this kind of process? And the kind of broad plan of how I'm gonna talk about this, I'm gonna do this for the next product as well. First, we're gonna talk about kind of data collection and how we think about like, you know, what is good data and how do we, you know, think about that. Next, the actual methodology and kind of going to the general challenges when you're modeling mammograms for any computer vision tasks specifically in cancer and also obviously risk. And lastly, how we thought about the analysis and some kind of objectives there. So to kind of dive right into it, we took consecutive mammograms. I'll get back into this later. This is actually quite important. We took consecutive mammograms from 02/9 to 2016. This started off with about two hundred eighty thousand cancers and once we kind of filtered for at least one year follow-up, we ended up with this, you know, final setting where we 220000 mammograms for training, and 26000 for development and testing.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Why is the class imbalance a challenge in applying deep learning to mammogram datasets?', [\"You see that kind of frame kind of anywhere you know it's a dog, and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just, like, the number of cancers we have, it's gonna be the cancer might be less than 1% of the mammogram and about 0.7% of your images have cancers. Even in this data set, which is from 2000 to 2016 NGH, a massive imaging center, in total, across all of that, we all still have, like, less than 2,000 cancers. And this is super tiny compared to, like, regular object classification data sets. And this is, you know, looking at over a 1,000,000 images if you look at all the four views of the exams. And at the same time, it's also too big. So, even if I down sample these images, I can only really fit 3 of them for a single GPU, and so this kind of limits the batch size I can work with. And whereas the kind of comparable, if I took just the regular ImageNet size, I could fit batch sizes of 128, easily happy days, and do all this parallelization stuff, and it's just much easier to play with. And finally, the actual data set itself is quite large, and so you have to do some, there's no uses to deal with in terms of, like, just setting up your server infrastructure to handle these massive data sets, while still being able to train efficiently. So, you know, the core challenge here across all of these kind of tasks is how do we make this model actually learn? The core problem is that our signal's longitude score is quite low, so training ends up being quite unstable. And there's a kind of a, you know, a couple simple levers we can play with. The first lever is is often deep learning initialization. Next, we're gonna talk about kind of optimization or architecture choice and how this compares to what people often do in the community, including in a recent paper from yesterday. And then finally, we're gonna talk about stuff more explicit for the triage idea in terms of how we actually use this model once it's trained. Okay. So before I kinda go into how we made these choices, I'm just gonna say what we chose to give you context before I dive in. So we follow some, like, image initialization. We use a relatively large bat size ish of 24. The way we do that is by just taking 4 GPUs and just stepping it a couple times before doing an optimizer step. So you do a couple rounds of of back part first to accumulate those gradients before doing, optimization, and you sample balance batches at training time.\", \"You see that kind of frame kind of anywhere you know it's a dog and so it's a much easier thing to learn in a traditional computer vision setting. And so the core challenge here is that both the image is too big and too small. So if you look at just like the number of cancers we have, it's gonna be the cancer might be less than one percent of the mammogram and about point seven percent of your images have cancer. So even in this data set which is from 02/2016 in NGH, a massive imaging center, in total across all of that, we all still have like less than two thousand cancers. And this is super tiny compared to like regular object classification data sets. And this is, you know, looking at over a million images, if you look at all 4 views of the exams. And at the same time, it's also too big. So, even if I down sample these images, I can only really 3 of them for a single GPU. And so this kind of limits the batch size I can work with. And whereas the kind of comparable, if I took just the regular ImageNet size, I could fit batch sizes of one twenty eight, easily happy days and do all this parallelization stuff and it's just much easier to play with. And finally, the actual data set itself is quite large and so you have to do some, there's new senses to deal with in terms of like just setting up your server infrastructure to handle these massive data sets, while still being able to train efficiently. So, you know, the core challenge here across all of these kind of tasks is how do we make this model actually learn? The core problem is that our signal's long distance is quite low so training ends up being quite unstable and there's a kind of a, you know, a couple simple levers you can play with. The first lever is as often deep learning initialization. Next, we're gonna talk about kind of optimization or architecture choice and how this compares to what people often do in the community including in a recent paper from yesterday. And then finally, we're gonna talk about stuff more explicit for the triage idea in terms of how we actually use this model once it's trained. Okay. So before I kinda go into how we made these choices, I'm just gonna say what we chose to give and give you context before I dive in. So we follow some like image initialization. We use a relatively large bat size ish 24. The way we do this is by just 4 GPUs and just stepping a couple times before doing an optimizer step. So you do a couple rounds of back prop first to accumulate those gradients before doing optimization and you sample balanced batches at training time.\", \"So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach. And by looking at the random images that were selected, in case we disagree, it supports the notion that it's not just that the column are just the most dense, crazy, dense looking breast, and that there's something more subtle that's picking up that's actually indicative of breast cancer risk. Kind of a very similar analysis we looked at is if we look at just by traditional breast density as labeled by the original red dot shows on the development set or on the test set. We end up seeing the same trend, where if someone is non dense, we call them high risk, they're much higher risk than someone that is dense that we call low risk. And as before, the kind of real next step here to make this truly valuable and truly useful is actually implementing it clinically, seeing this prospectively, and with more centers and kind of more population to see, does this work and does it deliver the kind of benefits that we care about? And viewing really, what is the lever to change once you know someone is high risk? Perhaps MRI, perhaps, you know, more frequent screening, and so, like, this is the kind of gap between having a useful technology on the paper side to an actual useful technology in real life. So I am I'm moving on schedule. So now, I'm gonna talk about how to mess up and it's actually quite interesting. There's like so many ways and I've and I've fallen to them a few times myself and it happens. And kind of following the sketch, you can mess up in data collection. It's probably the most common by far. You can mess up in modeling, which I'm doing right now and it's very sad, and you can mess up in analysis, which is really preventable. So in data collection, enriched data sets are the kind of the most common thing you see in the space. If you find a public data set, there's more likely gonna be like 5050 cancer, not cancer, and oftentimes, these data sets collect can have some sort of bias within the way it was collected.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What was the AUC achieved by the hybrid deep learning model (image + classical features) for mammogram risk assessment?', [\"So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts. So in terms of looking at high risk cohorts, our best model plays about 30% of all the cancers in the population in the top 10%, and 3% of all the cancers in the bottom 10%, compared to 185 to the prior state of the art. And so, what this enables you to do if you're gonna say that, you know, this 10% should actually qualify for MRI, you can start fighting this problem of majority of people that get cancer don't have MRI and the majority of people that get it don't need it. It's all about is your risk model actually placed the right people into the right buckets. Now, we saw that this trend of outperforming the prior state of the art held across races, and one of the things that was kind of astonishing was that, though Thai cuisine performed by white women, which makes sense because it was developed only using white women in the UK, it was worse than random in our data set of African American women. And so, this kind of, emphasizes the importance of this kind of analysis to make sure that the kind of data set that you have is reflective of the population you're trying to serve, and actually doing the analysis, accordingly. So we saw that our model kind of held across, races and as well across, you know, we see this trend from across pre postmenopause and with and without family history. One thing we did in terms of a more granular comparison of performance, we looked at if you just look at kind of like the risk thirds for our model and the entire acoustic model, What's the trend that you see or the cases where kind of like which one is right is kind of ambiguous. And what I should show in these boxes is the cancer incidence, the prevalence in that population. So the darker the box, the higher the incidence, and on the right hand side, there's random images from cases that fit within those boxes. Does that make sense for everyone? Great. So a clear trend that you see is that, for example, if, TCVA calls you, high risk but we call it low, that is a lower incidence than if we call it, medium and they call it low. So kind of like, you kind of see this straight column wise pattern showing that discrimination truly does follow the deep learning model and not the classical approach.\", \"We took outcomes from the EHR, once again, and the partner's registry. We didn't do exclusions based on race or anything of that sort or implants, but we did exclude negatives for follow-up. So if someone didn't have cancer in 3 years, but, like, disappeared from the system, we didn't count them as negatives that we have some certainty in both the modeling and the analysis. And as always, we split by patients into train that test. The modeling is very similar it's the same kind of template and lessons as from triage, except we experimented with a model that's only the image, and for the sake of analysis, a model that's the image model I described to you before, concatenated with those traditional risk factors at the last layer and trained only. That make sense for everyone? So we're gonna call that image only and image plus RF or hybrid. Okay, cool. Our kind of goals for the analysis as before, we wanna see, does this model actually serve the whole the whole population? Is it gonna be discriminative across race, menopause, status, and family history? And how does this relate to kind of classical portions of risk, and are we actually doing any better? And so just diving directly into that, assuming there's no questions. Good. Just kinda remind you, this is the kind of the setting. One thing I forgot to mention, that's why I had the slide here to remind me, is that we excluded cancers from the 1st year from the test set, so there's truly a negative screening population. So the way we we kind of disentangle cancer detection from cancer risk. Okay. Cool. So Tyre Cusick is the kind of prior state of the art model. It's a model based out of the UK. They're developed by someone named Sir Cusick, who's knighted over this work. It's very commonly used. So that one had an AC of 62, or image only model had an AC about 68, and the hybrid one had an AC of 70. So, you know, what is this kind of AC thing give you when you look using a risk model? What it gives you is the ability to create better high risk and low risk cohorts. So in terms of looking at high risk cohorts, our best model plays about 30% of all the cancers in the population in the top 10%, and 3% of all the cancers in the bottom 10%, compared to 185 to the prior state of the art.\", \"That way, the average probability you would expect to actually fit the incidence and then you don't get this kind of like crazy off kilter probabilities. Okay. So analysis. The objectives of what we're gonna try to do here is kind of similar across all the projects. 1, does this thing work? 2, does this thing work across all the people it's supposed to work for? So we did a subgroup analysis. 1st, we looked at the AUC of this model, so the ability to discriminate cancer is not. We did it across races. We have, across MGH, age groups, and density categories. And finally, how does this relate to rate analysis assessments? And if we actually use this at test time on the test set, what would have happened? Kind of a simulation before full clinical implementation. So our overall AUC here was 82 with some, you know, some confidence of 80 to 85, and when we did our analysis by age, we found that the performance was pretty similar across every age group. What's not shown here is the confidence intervals. So, for example but the kind of key core takeaway here is that the there was no noticeable gap in terms of by age group. We repeated this analysis by race and we saw, the same trend again. The performance kind of ranged generally around 82, and in places where the gap was bigger, the just confidence interval was bigger accordingly, due to smaller sample sizes because MGH is 80% white. We saw the exact same trend by density. The outline here is very dense breasts, but there's only like a 100 of those on test sets, so like this confidence level actually goes from like 60 to 90. So, as far as we know for the other 3 categories, it is very much tighter confidence interval and very similar, once again around 82. Okay. So we have a decent idea that this model seems at least with a population MGH, actually serve the relevant populations, you know, that exist as far as we know so far. The next question is, how does this how does a model assessment relate to the radiology assessment? So to look at that, we looked at on the test side, if you look at the radiology, true positives, false positives, true negatives, false negatives, where do they fall within the model distribution of, like, percentile risk? And if it's below the threshold, we're gonna color it in this kind of cyan color, and if it's above the threshold, we're gonna color it in this, purple color.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the primary challenge with using billing codes for clinical research?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the primary challenge with using billing codes for clinical research?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the primary challenge with using billing codes for clinical research?', [\"And so, the billing codes, we've talked about this a little bit before, but they're a very imperfect representation of reality. So we said, well, okay. What if we insisted that, you have 3 billing codes for rheumatoid arthritis rather than just one? And that turned out to raise the positive predictive value all the way up to 27%. Okay? So you go, really? How could you get billed 3 times? Right? Well, the answer is that you get billed for, you know, every aspirin you take at the at the hospital. And so, for example, it it's very easy to accumulate 3 billing codes for the same thing, because you go see a doctor. The doctor bills you for a rheumatoid arthritis visit. You he he or she sends you to a a radiologist to take an x-ray of your fingers, your joints. That bill is another billing code for RA. The doctor also sends you to the lab to have a blood drawn so that they can check your anti CCP titer. That's another billing code for rheumatoid arthritis. And it may be that all of all of this is negative, and you don't actually have the disease. Right? So this is something that's really important, to, to think about and to remember when you're analyzing these data. And so we started off in this project saying, well, we need to get a positive predictive value more on the order of 95%, because we wanted a very pure sample of people who really did have the disease, because we were going to take blood samples from those patients, pay a bunch of money to the Broad to analyze them, and then hopefully come up with a better understanding of the relationship between their genetics and their disease.\", \"And so, the billing codes, we've talked about this a little bit before, but they're a very imperfect representation of reality. So we said, well, okay. What if we insisted that, you have 3 billing codes for rheumatoid arthritis rather than just one? And that turned out to raise the positive predictive value all the way up to 27%. Okay? So you go, really? How could you get billed 3 times? Right? Well, the answer is that you get billed for, you know, every aspirin you take at the at the hospital. And so, for example, it it's very easy to accumulate 3 billing codes for the same thing, because you go see a doctor. The doctor bills you for a rheumatoid arthritis visit. You he he or she sends you to a a radiologist to take an x-ray of your fingers, your joints. That bill is another billing code for RA. The doctor also sends you to the lab to have a blood drawn so that they can check your anti CCP titer. That's another billing code for rheumatoid arthritis. And it may be that all of all of this is negative, and you don't actually have the disease. Right? So this is something that's really important, to, to think about and to remember when you're analyzing these data. And so we started off in this project saying, well, we need to get a positive predictive value more on the order of 95%, because we wanted a very pure sample of people who really did have the disease, because we were going to take blood samples from those patients, pay a bunch of money to the Broad to analyze them, and then hopefully come up with a better understanding of the relationship between their genetics and their disease.\", \"I mean, how many people think it's more than 50%? Okay. That would be nice, but it's not. How many people think it's more than 25%? God, you guys are getting really pessimistic. Well, it also isn't. So it turned it turned out to be something like 19% in in this cohort. Now before you start calling, you know, the fraud investigators, you have to ask yourself, why is it that this data is so lousy? Right? What and and there's a systematic reason, because those billing codes were not created in order to specify what's wrong with the patient. They were created in order to tell an insurance company or Medicare or somebody how much of a payment is deserved by the doctors taking care of them. And so what this means is that, for example, if I clutch my chest and go, and an ambulance rushes me over to Mass General, And they do a whole bunch of tests, and they decide that I'm not having a heart attack. The correct billing code for that visit is myocardial infarction, because, of course, the work that they had to do in order to figure out that I'm not having a heart attack is the same as the work they would have had to do to figure out that I was having a heart attack. And so, the billing codes, we've talked about this a little bit before, but they're a very imperfect representation of reality. So we said, well, okay. What if we insisted that, you have 3 billing codes for rheumatoid arthritis rather than just one? And that turned out to raise the positive predictive value all the way up to 27%.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How does natural language processing (NLP) contribute to improving positive predictive value (PPV) in clinical studies?', [\"And so we started off in this project saying, well, we need to get a positive predictive value more on the order of 95%, because we wanted a very pure sample of people who really did have the disease, because we were going to take blood samples from those patients, pay a bunch of money to the Broad to analyze them, and then hopefully come up with a better understanding of the relationship between their genetics and their disease. And, of course, if you talk to a biostatistician, as we did, they told us that if we have more than about 5% corruption of that database, then we're going to get meaningless results from it. Okay? So that's the goal here. So what we did is to say, well, if you train a data set that tries to tell you whether somebody really has rheumatoid arthritis or not based on just codified data. So codified data is things like lab values and prescriptions and demographics and stuff that is in tabular form. Then we were getting a positive predictive value of about 88%. And we said, well, how how well could we do by instead of looking at that codified data, looking at the narrative text in nursing notes, doctors' notes, discharge summaries, various other sources, could we do as well or better? And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%. So that was definitely an improvement. So this was published in 2010, and so this is not the latest, hot off the bench results.\", \"And so we started off in this project saying, well, we need to get a positive predictive value more on the order of 95%, because we wanted a very pure sample of people who really did have the disease, because we were going to take blood samples from those patients, pay a bunch of money to the Broad to analyze them, and then hopefully come up with a better understanding of the relationship between their genetics and their disease. And, of course, if you talk to a biostatistician, as we did, they told us that if we have more than about 5% corruption of that database, then we're going to get meaningless results from it. Okay? So that's the goal here. So what we did is to say, well, if you train a data set that tries to tell you whether somebody really has rheumatoid arthritis or not based on just codified data. So codified data is things like lab values and prescriptions and demographics and stuff that is in tabular form. Then we were getting a positive predictive value of about 88%. And we said, well, how how well could we do by instead of looking at that codified data, looking at the narrative text in nursing notes, doctors' notes, discharge summaries, various other sources, could we do as well or better? And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%. So that was definitely an improvement. So this was published in 2010, and so this is not the latest, hot off the bench results.\", \"And the answer turned out that we were getting about 89 about, yeah, 89% using only the natural language processing on these nodes. And not surprisingly, when you put them together, the, joint model gave us about 94%. So that was definitely an improvement. So this was published in 2010, and so this is not the latest, hot off the bench results. But to me, it's a very compelling story that says there is real value in these clinical narratives. Okay. So how did we do this? Well, we took about 4,000,000 patients in the EMR. We selected about 29,000 of them by requiring that they have at least one ICD 9 code for rheumatoid arthritis or that they've had an anti CCP titer done in the lab. And then we oh, it was 500, not 400. So we looked at 500 cases, which we got gold standard readings on, and then we trained an algorithm that predicted whether this patient really had RA or not. And that predicted about 3585 cases. We then sampled a validation set of 400 of those. We threatened our rheumatologists with bodily harm if they didn't read all those cases and give us a gold standard judgment. No. I'm kidding. I mean, they're actually really cooperative. And there are some details here that you can look at in the slide. And I had a pointer to the original paper if you're interested in the details.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some goals of NLP in healthcare as discussed in the lecture?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some goals of NLP in healthcare as discussed in the lecture?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some goals of NLP in healthcare as discussed in the lecture?', [\"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations. But I'm not sure where the the boundary is going to fall. I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview. So roughly, the outline of these two lectures is that I want to talk a little bit about why we care about clinical text. And then I'm going to talk about some conceptually very appealing, but practically not very feasible methods that involve analyzing these narrative texts as linguistic entities, as linguistic objects, in the way that a linguist might approach them. And then we're going to talk about what is very often done, which is a kind of term spotting approach that says, well, we may not be able to understand exactly everything that that goes on in the narratives, but we can identify certain words and certain phrases that are very highly indicative that the patient has a certain disease, a certain symptom, that some particular thing was done to them.\", \"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations. But I'm not sure where the the boundary is going to fall. I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview. So roughly, the outline of these two lectures is that I want to talk a little bit about why we care about clinical text. And then I'm going to talk about some conceptually very appealing, but practically not very feasible methods that involve analyzing these narrative texts as linguistic entities, as linguistic objects, in the way that a linguist might approach them. And then we're going to talk about what is very often done, which is a kind of term spotting approach that says, well, we may not be able to understand exactly everything that that goes on in the narratives, but we can identify certain words and certain phrases that are very highly indicative that the patient has a certain disease, a certain symptom, that some particular thing was done to them.\", \"And this is probably not meant to be readable by anybody except the person who wrote it or maybe their immediate friends and colleagues. So this is a real issue and one that we don't have a very good solution for yet. Now what do you use NLP for? Well, I had mentioned that one of the things we want to do is to codify things that appear in a note. So if it says rheumatoid arthritis, we want to say, well, that's equivalent to a particular ICD 9 code. We might want to use natural language processing for de identification of data. I mentioned that before. You know, Mimic, the only way that that Roger Marks' group got permission to release that data and make it available for people like you to use is by persuading the IRB that we had done a good enough job of getting rid of the all the identifying information in all of those records so that it's probably not technically impossible, but it's very difficult to figure out, who the the patients actually were in that cohort, in in that database. And the reason we ask you to sign a data use agreement is is to deal with that residual, you know, difficult but not necessarily impossible because of correlations with other data. And then you have little problems like mister Huntington suffers from Huntington's disease, in which the first Huntington is protected health information because it's a patient's name. The second Huntington is actually an important medical fact. And so you wouldn't want to get rid of that one. You want to determine aspects of each entity, its time, its location, its degree of certainty. You want to look for relationships between different entities that are identified in the text. For example, does one precede another? Does it cause it?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Explain the significance of the Unified Medical Language System (UMLS) in NLP for healthcare.', [\"And so the recursive machine learning problem is how best to identify the things associated with the term. And this is generally known as phenotyping. Now, how many of you have used the UMLS? Just a few. So in 1985 or 'eighty 4, the newly appointed director of the National Library of Medicine, which is one of the NIH institutes, decided to make a big investment in creating this unified medical language system, which was an attempt to take all of the terminologies that various medical professional societies had developed and unify them into a single, what they called a metathesaurus. So it's not really a thesaurus, because it's not completely well integrated, but it does include all of this terminology. And then they spent a lot of both human and machine resources in order to identify cases in which 2 different expressions from different terminologies really meant the same thing. So for example, myocardial infarction and heart attack really mean exactly the same thing, And in some terminologies, it's called acute myocardial infarction, or acute infarct or acute, you know, whatever. And they paid people and they paid machines, to scour those entire databases and come up with a mapping that said, okay. We're gonna have some concept, you know, c 398752, I just made that up, which corresponds to that particular concept, and then they mapped all those together. So that's an enormous help in 2 ways. It helps you normalize databases that come from different places and that are described differently.\", \"And so the recursive machine learning problem is how best to identify the things associated with the term. And this is generally known as phenotyping. Now, how many of you have used the UMLS? Just a few. So in 1985 or 'eighty 4, the newly appointed director of the National Library of Medicine, which is one of the NIH institutes, decided to make a big investment in creating this unified medical language system, which was an attempt to take all of the terminologies that various medical professional societies had developed and unify them into a single, what they called a metathesaurus. So it's not really a thesaurus, because it's not completely well integrated, but it does include all of this terminology. And then they spent a lot of both human and machine resources in order to identify cases in which 2 different expressions from different terminologies really meant the same thing. So for example, myocardial infarction and heart attack really mean exactly the same thing, And in some terminologies, it's called acute myocardial infarction, or acute infarct or acute, you know, whatever. And they paid people and they paid machines, to scour those entire databases and come up with a mapping that said, okay. We're gonna have some concept, you know, c 398752, I just made that up, which corresponds to that particular concept, and then they mapped all those together. So that's an enormous help in 2 ways. It helps you normalize databases that come from different places and that are described differently.\", \"Here are the UMLS semantic concepts of various or the semantic types. So you see that the most common semantic type is this t 061, which stands for therapeutic or preventive procedure, and there are 260,000 of those concepts in the metathesaurus. There are 233,000 findings, 172,000 drugs, organic chemicals, pharmacologic substances, amino acid peptide or protein, invertebrate. So the data does not come only from human medicine, but also from veterinary medicine and bioinformatics research and all over the place. But you see that these are a useful listing of appropriate semantic types that you can then look for in such a database. And the types are hierarchically organized. So, for example, the relations are organized so there's an effects relation which has sub relations, manages, treats, disrupts, complicates, interacts with, or prevents. Something like biological function can be a physiologic function or a pathologic function. And again, each of these has subcategories. So the idea is that each concept, each unique concept, is labeled with at least one of these semantic types. And that helps to identify things when you're looking through the data. There are also some tools that deal with the typical linguistic problems that if I want to say bleeds or bleed or bleeding, those are really all the same concept. And so there's this lexical variant generator that helps us normalize that.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the role of term spotting and negation handling in clinical NLP?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the role of term spotting and negation handling in clinical NLP?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the role of term spotting and negation handling in clinical NLP?', [\"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations. But I'm not sure where the the boundary is going to fall. I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview. So roughly, the outline of these two lectures is that I want to talk a little bit about why we care about clinical text. And then I'm going to talk about some conceptually very appealing, but practically not very feasible methods that involve analyzing these narrative texts as linguistic entities, as linguistic objects, in the way that a linguist might approach them. And then we're going to talk about what is very often done, which is a kind of term spotting approach that says, well, we may not be able to understand exactly everything that that goes on in the narratives, but we can identify certain words and certain phrases that are very highly indicative that the patient has a certain disease, a certain symptom, that some particular thing was done to them.\", \"Okay. So today and next Tuesday, we're talking about the role of natural language processing in machine learning in health care. And this is going to be a heterogeneous kind of presentation. Mainly today, I'm gonna talk about stuff that happened or that takes advantage of methods that are not based on neural network representations. And on Tuesday, I'm gonna speak mostly about stuff that does depend on neural network representations. But I'm not sure where the the boundary is going to fall. I've also invited doctor Katherine Liao over there, who will join me in a question and answer session and interview like we did a couple weeks ago with David. Kat is a a rheumatologist, in the Partners Health Care System. And, and you'll actually be hearing about some of the work that we've done together in the past before we go to the interview. So roughly, the outline of these two lectures is that I want to talk a little bit about why we care about clinical text. And then I'm going to talk about some conceptually very appealing, but practically not very feasible methods that involve analyzing these narrative texts as linguistic entities, as linguistic objects, in the way that a linguist might approach them. And then we're going to talk about what is very often done, which is a kind of term spotting approach that says, well, we may not be able to understand exactly everything that that goes on in the narratives, but we can identify certain words and certain phrases that are very highly indicative that the patient has a certain disease, a certain symptom, that some particular thing was done to them.\", \"First of all, for negation, Wendy Chapman, now at Utah but at the time at Pittsburgh, published this paper in 2,001 called A Simple Algorithm for Identifying Negated Findings of Diseases and Discharge Summaries. And it is indeed a very simple algorithm, and here's how it works. You find all the UMLS terms in each sentence of a discharge summary. So I'll talk a little bit about that. But basically, it's a dictionary lookup. You look up in this very large database of medical terms and translate them into some kind of expression that represents what that term means. And then you find 2 kinds of patterns. One pattern is a negation phrase followed within 5 words by one of these UMLS terms, and the other is a UMLS term followed within 5 words by a negation phrase, different set of negation phrases. So if you see no sign of something, that means it's not present. Or if you see ruled out unlikely something, then it's not present. Absence of not demonstrated, denies, etcetera. And post modifiers, if you say something declined or something unlikely, that also indicates that it's not present. And then they hacked up a bunch of exceptions where, for example, if you say gram negative, that doesn't mean that it's negative or whatever follows it or whatever precedes it. Right? Etcetera. So there are a bunch of exceptions. And what they found is that this actually, considering how incredibly simple it is, does reasonably well. So if you look at sentences that do not contain a negation phrase and looked at 500 of them, you find that you get a sensitivity and specificity of 88 52%.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is risk stratification and why is it important in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is risk stratification and why is it important in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is risk stratification and why is it important in healthcare?', [\"Although today's lecture is going to be a little bit more high level, next Thursday's lecture is where we're going to really start to get into mathematical details about how one should tackle machine learning problems with sensor data. And then the following lecture after that is going to be on physiological data. And that lecture will also be much more technical in nature compared to the first couple of weeks of the course. So what is risk stratification? At a high level, you should think about risk stratification as a way of taking in a patient population and separating out all of your patients into 1 of 2 or more categories. Patients with high risk, patients with low risk, and maybe patients somewhere in the middle. Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring. Now, risk stratification is quite different from diagnosis. Diagnosis often has very, very stringent criteria on performance. If you do a misdiagnosis of something, that can have very severe consequences in terms of patients being treated for conditions that they didn't need to be treated for and patients dying because they were were not diagnosed in time. Now risk stratification, you think of as a little bit more fuzzy in nature. We wanna do our best job of trying to push patients into each of these categories, high dose, low risk, and so on. And as I'll show you throughout today's lecture, the performance characteristics that we'll often care about are gonna be a bit different.\", \"Although today's lecture is going to be a little bit more high level, next Thursday's lecture is where we're going to really start to get into mathematical details about how one should tackle machine learning problems with sensor data. And then the following lecture after that is going to be on physiological data. And that lecture will also be much more technical in nature compared to the first couple of weeks of the course. So what is risk stratification? At a high level, you should think about risk stratification as a way of taking in a patient population and separating out all of your patients into 1 of 2 or more categories. Patients with high risk, patients with low risk, and maybe patients somewhere in the middle. Now the reason why we might wanna do risk stratification is because we usually want to try to act on those predictions. So the goals are often one of coupling those predictions with known interventions. So for example, patients in the high risk pool, patients to prevent whatever that outcome is of interest from occurring. Now, risk stratification is quite different from diagnosis. Diagnosis often has very, very stringent criteria on performance. If you do a misdiagnosis of something, that can have very severe consequences in terms of patients being treated for conditions that they didn't need to be treated for and patients dying because they were were not diagnosed in time. Now risk stratification, you think of as a little bit more fuzzy in nature. We wanna do our best job of trying to push patients into each of these categories, high dose, low risk, and so on. And as I'll show you throughout today's lecture, the performance characteristics that we'll often care about are gonna be a bit different.\", \"But every single project that I've been a part of has been an effort to bring in data that has always been there, but we haven't been able to to learn from until now. And whether that's, you know, at the VA building out their genomic, science infrastructure and recruiting and enrolling a million veterans to to to donate their blood and their EMR or at Ariadne Labs over out of Harvard School of Public Health in the Brigham, improving childbirth in India. It it's all about how can we get a little bit better over and over again to make health care, you know, better place for folks. So so tell me, what is risk stratification from your perspective? Right? Defining that, I found to be one of the most difficult parts of today's lecture. Well, thank you for challenging me with it. So So it's a rather generic term, and I think it depends entirely on the problem you're trying to solve. And every time I I go at this, you really have to ground yourself in the problem that you're trying to solve. Risk could be running out of a medical supply, in an operating room. Risk could be an APGAR score. Risk could be, from pre diabetic to diabetic. Risk could be an older person falling down in their home. So it's really what is it to me? I'm very much caught up in the tools analogy. Right? These are wonderful tools with which a skilled craftsman surrounded by others that have skills could go ahead and solve very specific problems. So, this is a hammer. It's one that that we spend a lot of time refining and applying to solve problems in health care. So why don't you tell us about some of the areas where where your company has been applying risk stratification today, at a very high level, and then we'll dive we'll choose one of them to dive a bit deeper into. Sure. So so we do the the way we describe what we do is it's performance improvement. And, and I'm just giving you a little background because it'll tell you which problems I'm focused on. So it it's performance improvement. And and to be candid, the types of things we like to improve the performance of are, like, how do we keep people out of the hospital? I'm not gonna soapbox on this too much, but I think it matters.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the difference between traditional scoring systems and ML-based risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is the difference between traditional scoring systems and ML-based risk stratification?', [\"Well, the traditional approaches to risk stratification are based on scoring systems. So I mentioned to you a few minutes ago the APGAR scoring system. It's shown here. You're going to say for each of these different criteria, activity, pulse, grimace, appearance, respiration, You look at the baby and you say, well, activity is absent or maybe their active movement. Appearance might be pale or blue, which would get 0 points, or completely pink, which gets 2 points. And for each one of these answers, you add up the corresponding points. So you get a total number of points. And you look over here and you say, okay. Well, baby is at risk, at severe risk. If they have 7 to 10 points, then then the baby is low risk. And there are hundreds of such scoring rules which have been very carefully derived through studies not dissimilar to the one that you read for today's readings and which are actually widely used in the health care system today. But the times have been changing quite rapidly in the last 5, 10 years. And now, what most of the industry is moving towards are machine learning based methods that can work with a much higher dimensional set of features and solve a number of key challenges of these early approaches. First and this is perhaps the most important aspect they can fit more easily into clinical workflows. So the scores I showed you earlier are often done manually. So one has to think to do the score. One has to figure out what the corresponding inputs are. And as a result of that, often they're not used as frequently as they should be. 2nd, the new machine learning approaches can get higher accuracy, potentially, due to their ability to use many more features than the traditional approaches.\", \"Well, the traditional approaches to risk stratification are based on scoring systems. So I mentioned to you a few minutes ago the APGAR scoring system. It's shown here. You're going to say for each of these different criteria, activity, pulse, grimace, appearance, respiration, You look at the baby and you say, well, activity is absent or maybe their active movement. Appearance might be pale or blue, which would get 0 points, or completely pink, which gets 2 points. And for each one of these answers, you add up the corresponding points. So you get a total number of points. And you look over here and you say, okay. Well, baby is at risk, at severe risk. If they have 7 to 10 points, then then the baby is low risk. And there are hundreds of such scoring rules which have been very carefully derived through studies not dissimilar to the one that you read for today's readings and which are actually widely used in the health care system today. But the times have been changing quite rapidly in the last 5, 10 years. And now, what most of the industry is moving towards are machine learning based methods that can work with a much higher dimensional set of features and solve a number of key challenges of these early approaches. First and this is perhaps the most important aspect they can fit more easily into clinical workflows. So the scores I showed you earlier are often done manually. So one has to think to do the score. One has to figure out what the corresponding inputs are. And as a result of that, often they're not used as frequently as they should be. 2nd, the new machine learning approaches can get higher accuracy, potentially, due to their ability to use many more features than the traditional approaches.\", \"So one has to think to do the score. One has to figure out what the corresponding inputs are. And as a result of that, often they're not used as frequently as they should be. 2nd, the new machine learning approaches can get higher accuracy, potentially, due to their ability to use many more features than the traditional approaches. And finally, they can be much quicker to drive. So all of the traditional scoring systems had a very long research and development process that lead that led to their adoption. First, you gather the data, then you build the models, then you sanity check the models, then you do an evaluation in 1 hospital, then you do a prospective evaluation in many hospitals. And each one of those steps takes a lot of time. Now with these machine learning based approaches, it raises the possibility of a research assistant sitting in a hospital or in a computer science department saying, oh, I think it would be really useful to derive a score for this problem. You take data that's available, you apply your machine learning algorithm, and even if it's a condition or an outcome, which occurs very infrequently, if you have access to a large enough data set, you'll be able to get enough samples in order to actually predict that somewhat very narrow outcome. And so as a result, it really opens the door to rethinking about the way that risk stratification can be can be used. But as a result, there are also new dangers that are introduced. And we'll talk about some of those in today's lecture, and we'll continue to talk about those in next Thursday's lecture. So these models are being widely commercialized. Here's just an example from one of many companies that are building risk stratification tools. This is from Optum. And what I'm showing you here is the output from one of their models, which is predicting COPD related hospitalizations.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How is label leakage managed in diabetes prediction models?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How is label leakage managed in diabetes prediction models?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How is label leakage managed in diabetes prediction models?', [\"And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list. We're gonna say this patient is someone you should be going after. But that's really not an interesting patient to be going after because the clinicians are probably already doing interventions that are relevant for that patient. Rather, we want to find the patients where the diabetes might be more unexpected. And so this is one of the subtleties that really arises when you try to use retrospective clinical data to derive your labels to use within machine learning for risk stratification. So in the result result I'll tell you about, I'm going to use a 1 year gap. Another problem is that the data is highly censored. So, what I mean by censoring is that we often don't have full visibility into the the the data for patients. For example, patients might have only come into the health insurance in 2013. And so January 1,009, we had no data on them. They didn't even exist in the system at all. So there are 2 types of censoring. One type of censoring is is called left censoring. It means when we don't have data to the left, for example, in the feature construction window. Another type of censoring is called right censoring. It mean it means when we don't have data about the patient to the right of that time line. And for each one of these, in our work here, we tackle it in a different way. For left centering, we're going to deal with it. We're going to say, Okay, we might have limited data on patient, but we will use whatever data is available from the past 2 years in order to make our predictions. And for patients who have less data available, that's fine. We have a more sparse feature vector. For right censoring, it's a little bit more challenging to deal with in this binary reduction because if you don't know what the label is, it's really hard to use within, for example, a supervised machine learning approach.\", \"And so in 2,009, in January 1, 2009, the primary care physician, for example, for the patient might be well aware that this patient is diabetic, might already be doing interventions based on it. But our algorithm doesn't know that. And so that patient, because of the signals that are present in the data, is going to be at the very top of our prediction list. We're gonna say this patient is someone you should be going after. But that's really not an interesting patient to be going after because the clinicians are probably already doing interventions that are relevant for that patient. Rather, we want to find the patients where the diabetes might be more unexpected. And so this is one of the subtleties that really arises when you try to use retrospective clinical data to derive your labels to use within machine learning for risk stratification. So in the result result I'll tell you about, I'm going to use a 1 year gap. Another problem is that the data is highly censored. So, what I mean by censoring is that we often don't have full visibility into the the the data for patients. For example, patients might have only come into the health insurance in 2013. And so January 1,009, we had no data on them. They didn't even exist in the system at all. So there are 2 types of censoring. One type of censoring is is called left censoring. It means when we don't have data to the left, for example, in the feature construction window. Another type of censoring is called right censoring. It mean it means when we don't have data about the patient to the right of that time line. And for each one of these, in our work here, we tackle it in a different way. For left centering, we're going to deal with it. We're going to say, Okay, we might have limited data on patient, but we will use whatever data is available from the past 2 years in order to make our predictions. And for patients who have less data available, that's fine. We have a more sparse feature vector. For right censoring, it's a little bit more challenging to deal with in this binary reduction because if you don't know what the label is, it's really hard to use within, for example, a supervised machine learning approach.\", \"We're going to say, Okay, we might have limited data on patient, but we will use whatever data is available from the past 2 years in order to make our predictions. And for patients who have less data available, that's fine. We have a more sparse feature vector. For right censoring, it's a little bit more challenging to deal with in this binary reduction because if you don't know what the label is, it's really hard to use within, for example, a supervised machine learning approach. In Tuesday's lecture, I'll talk about a way to deal with right censoring. In today's lecture, we're going to just ignore it. And the way that we'll ignore it is by changing inclusion and exclusion criteria. We will exclude patients for whom we don't know the label. And to be clear, that can be really problematic. So for example, imagine that that you if you go back to to this picture here, imagine that we're in this scenario. And imagine that we if we only have data on a patient up to 2011, we remove them from the data set, okay, because we don't have full visibility into the 2010 to 2012 time window. Well, suppose that exactly the day before the patient was going to be removed from the data set exactly right before the data disappears to the patient because, for example, they might change health insurers, they were diagnosed with type 2 diabetes. And maybe the reason why they changed health insurers had to do with them being diagnosed with type 2 diabetes. Then, we've excluded that patient from the population, and we might be really biasing the results of the model by now taking away a whole set of the of the population where this model would have been really important to apply. So thinking about how you really do this inclusion exclusion, how that changes the generalizability of the model you get is something that should be at the top of your mind. So the the machine learning algorithm used in in that paper which you've read is l one regularized logistic regression.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What types of data are used in risk stratification for diabetes?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What types of data are used in risk stratification for diabetes?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What types of data are used in risk stratification for diabetes?', [\"But as I mentioned, these scores haven't had the impact that we had hoped that they might have. And and the reason really is because they haven't been actually used nearly as much as they should be. So what we will be thinking through is can we change the way in which risk stratification is done rather than it having to be something which is manually done when you think to do it, we can make it now population wide. We could, for example, take data that's already available from a health insurance company, use machine learning. Maybe we don't have access to all of those features I showed you earlier. Like, maybe we don't know the patient's weight, but we'll we'll use machine learning on the data that we do have to try to find other surrogates of those things we don't have, which might predict diabetes risk. And then we can apply it automatically behind the scenes for millions of different patients and find the high risk population and perform interventions for those patients. And by the way, the work that I'm telling you about today is work that really came out of my lab's research in the last few years. So this is an example going back to the set of stakeholders, which we talked about in the first lecture. This is an example of a risk stratification done at the payer level. So the data which is going to be used for this problem is administrative data, data that you typically find in in health insurance companies. So I'm showing you here a single patient's timeline and the type of data that you expect for to be available for that patient across time. You in red, it's showing their eligibility records. You know, when have they been enrolled in that health insurance. And that's really important because if they're not enrolled in the health insurance on some month, then the lack of data for that patient isn't because nothing happened. It's because we just don't have visibility into it. It's missing. Associated with diagnosis codes that Pete talked about last week, procedure codes, CPT codes.\", \"But as I mentioned, these scores haven't had the impact that we had hoped that they might have. And and the reason really is because they haven't been actually used nearly as much as they should be. So what we will be thinking through is can we change the way in which risk stratification is done rather than it having to be something which is manually done when you think to do it, we can make it now population wide. We could, for example, take data that's already available from a health insurance company, use machine learning. Maybe we don't have access to all of those features I showed you earlier. Like, maybe we don't know the patient's weight, but we'll we'll use machine learning on the data that we do have to try to find other surrogates of those things we don't have, which might predict diabetes risk. And then we can apply it automatically behind the scenes for millions of different patients and find the high risk population and perform interventions for those patients. And by the way, the work that I'm telling you about today is work that really came out of my lab's research in the last few years. So this is an example going back to the set of stakeholders, which we talked about in the first lecture. This is an example of a risk stratification done at the payer level. So the data which is going to be used for this problem is administrative data, data that you typically find in in health insurance companies. So I'm showing you here a single patient's timeline and the type of data that you expect for to be available for that patient across time. You in red, it's showing their eligibility records. You know, when have they been enrolled in that health insurance. And that's really important because if they're not enrolled in the health insurance on some month, then the lack of data for that patient isn't because nothing happened. It's because we just don't have visibility into it. It's missing. Associated with diagnosis codes that Pete talked about last week, procedure codes, CPT codes.\", \"And so this is an indicator that the patient has been previously flagged as being prediabetic. And it obviously makes sense that that would be at the very top of of the predictive variables. But there are so many things that are a little bit less obvious. For example, here we see obstructive sleep apnea and esophageal reflux as being chosen by the model to be predictive of the patient developing type 2 diabetes. What we would conjecture is that those variables, in fact, act as surrogates for the patient being obese. Because obesity is very seldom coded in commercial health insurance claims. And so with this variable, despite the fact that the patient might be obese, if this variable is not observed, then patients who are obese often have what's called sleep apnea. So they might stop breathing for short periods of time during their sleep. And so that, then, would be a sign of obesity. So I talked about how the criteria which we use to evaluate risk stratification models are a little bit different from the criteria used to evaluate diagnosis models. Here, I'll tell you, one of the measures that we often use, and it's called positive predictive value. So what we'll do is we'll look at after you've learned your model, look at the top 100 predictions, top 1,000 predictions, top 10,000 predictions, and look to see what fraction of those patients went on to actually develop type 2 diabetes. And, of course, this is done using held out data. Now the reason why you might be interested in different levels is because you might want to target different interventions depending on on the risk and cost. For example, a very low cost intervention, one of the ones that that we did was sending a text message to patients who have who who are who are suspected to have high risk of developing type 2 diabetes. If they've not been to see their eye doctor in the last year, we send them a text message saying, maybe you wanna go see your eye doctor.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Why is L1 regularization used in logistic regression for risk stratification?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Why is L1 regularization used in logistic regression for risk stratification?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'Why is L1 regularization used in logistic regression for risk stratification?', [\"Well, the solution the optimal solution is going to be, in essence, the closest point along the circle, which gets as close as possible to the middle of that level set. So over here, the closest point is over is that one. And you'll see that this point has a non zero w 1 and w 2. Over here, the closest point is over here. Right? Notice that that has a zero value of w 1 and a non zero value of w 2. Thus, it's found a sparser solution than this one. So this is just to give you some intuition about why using l one regularization results in sparse solutions to your optimization problem. And that can be beneficial for 2 purposes. 1st, it can help prevent overfitting in settings where there exists a very good risk model that uses a small number of features. And to point out, that's not a crazy idea that there might exist a risk model that uses a small number of features. Right? Because remember, think back to that Apgar score or the FINRISK, which was used to predict diabetes in in Finland. Each of those had only 5 to 20 questions. And based on the answers to those 5 to 20 questions, one could get a pretty good idea of what the risk is of that patient. Right? So the fact that there might be a small number of features that are that are together sufficient is actually a very reasonable prior. And it's one reason why l one regularization is actually very well suited to these types of risk stratification problems on this type of data. The second reason is one of interpretability. If one wants to then ask, well, what are the features that actually were used by this model to make predictions? When you find only 20 or a few hundred features, you can enumerate all of them and look to see what they are, and that way understand what is going on into the predictions that are that are made. And that also has a very big impact when it comes to translation.\", \"Well, the solution the optimal solution is going to be, in essence, the closest point along the circle, which gets as close as possible to the middle of that level set. So over here, the closest point is over is that one. And you'll see that this point has a non zero w 1 and w 2. Over here, the closest point is over here. Right? Notice that that has a zero value of w 1 and a non zero value of w 2. Thus, it's found a sparser solution than this one. So this is just to give you some intuition about why using l one regularization results in sparse solutions to your optimization problem. And that can be beneficial for 2 purposes. 1st, it can help prevent overfitting in settings where there exists a very good risk model that uses a small number of features. And to point out, that's not a crazy idea that there might exist a risk model that uses a small number of features. Right? Because remember, think back to that Apgar score or the FINRISK, which was used to predict diabetes in in Finland. Each of those had only 5 to 20 questions. And based on the answers to those 5 to 20 questions, one could get a pretty good idea of what the risk is of that patient. Right? So the fact that there might be a small number of features that are that are together sufficient is actually a very reasonable prior. And it's one reason why l one regularization is actually very well suited to these types of risk stratification problems on this type of data. The second reason is one of interpretability. If one wants to then ask, well, what are the features that actually were used by this model to make predictions? When you find only 20 or a few hundred features, you can enumerate all of them and look to see what they are, and that way understand what is going on into the predictions that are that are made. And that also has a very big impact when it comes to translation.\", \"Then, we've excluded that patient from the population, and we might be really biasing the results of the model by now taking away a whole set of the of the population where this model would have been really important to apply. So thinking about how you really do this inclusion exclusion, how that changes the generalizability of the model you get is something that should be at the top of your mind. So the the machine learning algorithm used in in that paper which you've read is l one regularized logistic regression. One of the reasons for using l one regularized logistic regression is because it provides a way to use a high dimensional feature set. But at the same time, it allows one to do feature selection. So I'll go more into detail on that in just a moment. I imagine most of you have sorry. All of you should be familiar with the idea of formulating machine learning as an optimization problem, where you have some loss function and you have some regularization term. W, in this case, is the weights of your linear model, which we're trying to learn. For those of you who've seen support vector machines before, support vector machines will use what's called l two regularization, where we'll be putting a penalty on the L 2 norm of the weight factor. Instead, what we did in this paper is we used L 1 regularization. So this penalty is defined over here. It's summing over the features and looking at the absolute value of the weight for each for each of the weights and summing those up. So one of the reasons why l one regularization has what's known as a sparsity benefit can be explained by this picture. So this is just a demonstration by sketch. Suppose that we're trying to solve this optimization problem here. So this is the level set of your loss function. It's a quadratic function. And suppose that instead of adding on your regularization as a second term to your optimization problem, you were to instead put in a constraint.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is MYCIN and why was it never used in practice?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is MYCIN and why was it never used in practice?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What is MYCIN and why was it never used in practice?', [\"So so I'm gonna talk about, you know, as David said, I this was not my field. But increasingly there is some interest in terms of getting involved in it, in part because of my frustrations with clinical medicine. So this is one of my frustrations with clinical medicine. So cardiology has not really changed and and and one of the things that fails at miserably is picking up early onset disease. So so here's here's here's the kind of the typical profile, a little facetious. So so people like me in our in our early forties start to already have some problems with some of these numbers. So I like to joke that since I came back to the Harvard system from California, my blood pressure has gone up 10 points, which is true unfortunately. But but so these these changes already start to happen, and and nobody does anything about it. So you can go to your doctor and, you know, you're also saying no, I don't want to be on any medicine. They're like no, no, no, you shouldn't be on any medicine. So you kind of hem and haw and a decade goes by, 15 years go by. And then finally you're like, okay, well it looks like at least my coworker is on some medicine, so maybe I'll be willing to do that. And so there'll be lots of stuff you can be treated with, but but it is often very difficult. And and you see this at the doctor level too. Yes. Just for the optimal values, how much what kind of personal deviation is there from the the frequency? So the optimal value is is is fixed and is just like a reference value. And you can be off by so blood pressure, let's say. So so people consider optimal to be less than 120 over less than 80. People are in the 200, people are in the 2, you know. So so you'd be treated in the 200, but there'll be lots of people in the 1 forties and the 1 fifties, and there'll be a degree of kind of nihilism about that for some time. And and and my patients would be like, oh, I got into the fight with the parking attendant. Oh, I, you know, I just, you know, I had a really bad phone I mean, you know, there's there's, like, countless excuses for why it is that one shouldn't start a medication, and this can go on for a long time. Yes? Reshore of rain, like, how can you assess the risk of Yeah.\", \"The most radical version of this was a guy named de Holm, who I met in 1983 in Paris. He was a doctor at at La Pitier Sol Petriere, which is one of these medieval hospitals in in Paris. And it's a wonderful place, although when they built it, it was just a place to die because they really couldn't do much for you. So, de Holm convinced the chief of cardiology at that hospital that he would develop an artificial language for taking notes about cardiac patients. He would teach this to all of the, fellows and and junior doctors, in the cardiology department at the hospital, and they would be required by the chief, who's very powerful in France, to use this artificial language to write notes instead of using French to write notes. And they actually did this for a month. And when I met Dahome, he he was in the middle of of analyzing the data that he had collected. And, what he found was that, the language was not expressive enough. There were things that people wanted to say that they couldn't say in this artificial language he had created. And so he went back to create version 2, and then he went back to the cardiologist and said, well, let's do this again. And then they threatened to kill him. So the experiment was not repeated. Okay. So back to term spotting. Traditionally, if you were trying to do this, what you would do is you would sit down with a bunch of medical experts, and you would say, all right. Tell me all the words that you think might appear in a note that are indicative of some condition that I'm interested in.\", \"The most radical version of this was a guy named de Holm, who I met in 1983 in Paris. He was a doctor at at La Pitier Sol Petriere, which is one of these medieval hospitals in in Paris. And it's a wonderful place, although when they built it, it was just a place to die because they really couldn't do much for you. So, de Holm convinced the chief of cardiology at that hospital that he would develop an artificial language for taking notes about cardiac patients. He would teach this to all of the, fellows and and junior doctors, in the cardiology department at the hospital, and they would be required by the chief, who's very powerful in France, to use this artificial language to write notes instead of using French to write notes. And they actually did this for a month. And when I met Dahome, he he was in the middle of of analyzing the data that he had collected. And, what he found was that, the language was not expressive enough. There were things that people wanted to say that they couldn't say in this artificial language he had created. And so he went back to create version 2, and then he went back to the cardiologist and said, well, let's do this again. And then they threatened to kill him. So the experiment was not repeated. Okay. So back to term spotting. Traditionally, if you were trying to do this, what you would do is you would sit down with a bunch of medical experts, and you would say, all right. Tell me all the words that you think might appear in a note that are indicative of some condition that I'm interested in.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some reasons why AI in healthcare is more promising today compared to the past?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some reasons why AI in healthcare is more promising today compared to the past?', [\"They might be 60 neurons, then 7, then 6, for example, in terms of each of the layers of of the of the neural network. By the way, that that sort of makes sense given the type of data that was fed into it. So none of this is new in terms of the goals. So what's changed? Why do I think that despite that the fact that we've had what could arguably be called a failure for the last 30 or 40 years, that we might actually have some chance of succeeding now? And the big differentiator, what I'll call now the opportunity, is data. So whereas in the past, much of the work in artificial intelligence in medicine was not data driven, it was based on trying to elicit as much domain knowledge as one can from clinical domain experts, in some cases, gathering a little bit of data. Today, we have an amazing opportunity because of the prevalence of electronic medical records, both in United States and elsewhere. Now here in the United States, for example, the story wasn't that way even back in 2,008, when the adoption of electronic medical records was under 10% across the US. But then there was an economic disaster in the US. And as part of the economic stimulus package, which president Obama initiated, there was something like $30,000,000,000 allocated to hospitals purchasing electronic medical records. And this is already a first example that we see of policy being really influential to create the to open the stage to the types of work that we're going to be able to do in this course today. So money was made available as incentives for hospitals to purchase electronic medical records. And as a result, the adoption increased dramatically. This is a really old number from 2015 of 80 4% of hospitals. And now today, it's actually much larger. So data is being collected in electronic form, and that presents an opportunity to try to do research on it.\", \"They might be 60 neurons, then 7, then 6, for example, in terms of each of the layers of of the of the neural network. By the way, that that sort of makes sense given the type of data that was fed into it. So none of this is new in terms of the goals. So what's changed? Why do I think that despite that the fact that we've had what could arguably be called a failure for the last 30 or 40 years, that we might actually have some chance of succeeding now? And the big differentiator, what I'll call now the opportunity, is data. So whereas in the past, much of the work in artificial intelligence in medicine was not data driven, it was based on trying to elicit as much domain knowledge as one can from clinical domain experts, in some cases, gathering a little bit of data. Today, we have an amazing opportunity because of the prevalence of electronic medical records, both in United States and elsewhere. Now here in the United States, for example, the story wasn't that way even back in 2,008, when the adoption of electronic medical records was under 10% across the US. But then there was an economic disaster in the US. And as part of the economic stimulus package, which president Obama initiated, there was something like $30,000,000,000 allocated to hospitals purchasing electronic medical records. And this is already a first example that we see of policy being really influential to create the to open the stage to the types of work that we're going to be able to do in this course today. So money was made available as incentives for hospitals to purchase electronic medical records. And as a result, the adoption increased dramatically. This is a really old number from 2015 of 80 4% of hospitals. And now today, it's actually much larger. So data is being collected in electronic form, and that presents an opportunity to try to do research on it.\", \"The the answer is that it's there's a huge amount of difference, and there are a lot of subtleties to doing machine learning right here. And we'll talk about that throughout the whole entire semester. So to begin, this isn't a new field. Artificial intelligence in medicine goes back to the 19 seventies or sometime even in the sixties. One of the earliest examples of trying to use artificial intelligence for diagnosis was this Mison system developed at Stanford where the goal was try to identify bacteria that might might cause infection and then to try to guide what would be the appropriate therapy for that bacteria. Now it was found that this algorithm, this machine learning, this simple AI algorithm, was able to propose a good therapy in 69% of cases, which at the time was better than the best or very good infectious disease experts. Now it also had some other elements of it, which which were quite interesting. So those of you who've been following the latest in chat bots might find this a little prescient. So there's a dialogue interface where the computer says, I am ready. The computer the the the clinician responds, this is a 26 year old male patient. The computer tests its understanding of what's going on. It says the age of the patient is 26. The sex of the patient is male. The clinician writes, 5 days ago, he had respiratory tract infections. The computer asks, what is his name? Joe. The computer responds, my understanding is the name of the patient is Joe. Respiratory tract is one of the symptoms the patient had. Then the clinician writes, a couple of days before the admission, he had malaise, which is general tiredness. The computer responds, please give me a date of admission. The clinician responds, March 12, 1979, and the computer again confirms that it's understood appropriately.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How can machine learning transform emergency departments?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How can machine learning transform emergency departments?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'How can machine learning transform emergency departments?', [\"In a few lectures, I'll talk to you about techniques from the eighties nineties, which were based on trying to signal processing, trying to detect where are the peaks of this signal, look at the distance between peaks. And more recently, because of the large wealth of data that's available, we've been using convolutional neural network based approaches to try to understand this data and predict from it. Yet another example from the ER really has to do with not how do we care for the patient today, but how do we get better data, which will then result in taking better care of the patient tomorrow. And so one example of that, which which my group deployed at Beth Israel Deaconess, and it's still running there in the emergency department, has to do with getting higher quality chief complaints. The chief complaint is the, it's usually a very short 2 or 3 word quantity, like, left knee pain, rectal pain, right right upper quadrant, RUQ, abdominal pain. And it's just a very quick summary of why did the patient come into the ER today. And despite the fact that it's so few words, it plays a huge role in the care of a patient. If you look at the big screens in the ER, which summarize who are the patients at what beds, they have the chief complaint next to it. Chief complaints are used as criteria for enrolling patients in clinical trials. It's used as criteria for doing retrospective quality research to see how do we care for patients of a particular type. So it plays a very big role. But unfortunately, the data that we've been getting has been crap. And that's because it was free text and it was sufficiently high dimensional that just attempting to standardize it with a big drop down list like you see over here would have killed the clinical workflow, would have taken way too much time for clinicians to try to find the relevant one. And so it just wouldn't have been used. And that's where some very simple machine learning algorithms turn out to be really valuable. So for example, we changed the workflow altogether. Rather than the chief complaint being the first thing that the triage nurse, assigns when the patient comes in, it's the last thing.\", \"In a few lectures, I'll talk to you about techniques from the eighties nineties, which were based on trying to signal processing, trying to detect where are the peaks of this signal, look at the distance between peaks. And more recently, because of the large wealth of data that's available, we've been using convolutional neural network based approaches to try to understand this data and predict from it. Yet another example from the ER really has to do with not how do we care for the patient today, but how do we get better data, which will then result in taking better care of the patient tomorrow. And so one example of that, which which my group deployed at Beth Israel Deaconess, and it's still running there in the emergency department, has to do with getting higher quality chief complaints. The chief complaint is the, it's usually a very short 2 or 3 word quantity, like, left knee pain, rectal pain, right right upper quadrant, RUQ, abdominal pain. And it's just a very quick summary of why did the patient come into the ER today. And it despite the fact that it's so few words, it plays a huge role in the care of a patient. If you look at the big screens in the ER, which summarize who are the patients at what beds, they have the chief complaint next to it. Chief complaints are used as criteria for enrolling patients in clinical trials. It's used as criteria for doing retrospective quality research to see how do we care for patients of a particular type. So it plays a very big role. But unfortunately, the data that we've been getting has been crap. And that's because it was free text and it was sufficiently high dimensional that just attempting to standardize it with a big drop down list like you see over here would have killed the clinical workflow, would have taken way too much time for clinicians to try to find the relevant one. And so it just wouldn't have been used. And that's where some very simple machine learning algorithms turn out to be really valuable. So for example, we changed the workflow altogether. Rather than the chief complaint being the first thing that the triage nurse, assigns when the patient comes in, it's the last thing.\", \"And here's one example where it says, the ED dashboard, the emergency department dashboard, decision support algorithms have determined this patient may be eligible for the atrial cellulitis pathway. Cellulitis is often caused by infections. Please choose from one of the options. Enroll in the pathway, decline. And if you decline, you must include a comment for the reviewers. Now, if you clicked on enroll in the pathway, at that moment, machine learning disappears. Rather, there's a standardized process. It's an algorithm, but it's a deterministic algorithm for how patients with cellulitis should be properly managed, diagnosed, and treated. That algorithm comes from best practices, comes from clinicians coming together, analyzing past data, understanding what would be good ways to treat patients of this type, and then formalizing that in a document. The challenge is that there might be 100 or even 1000 of these best practices. And in an academic medical center where you have patients coming, where you have medical students or residents who are very quickly rotating through the system and thus may not be familiar with what are the most appropriate clinical guidelines to use for any one patient in this institution. Or if you go to a rural site where where this academic nature of thinking through what the right clinical guidelines are is a little bit less of the of the mainstream everyday activity, The question of which one to use when is very challenging. And so that's where the machine learning algorithms can come in. By reasoning about what's going on with patients, you might have a good guess of what might be appropriate for this patient, and you use that to automatically surface the right clinical decision support trigger. Another example is by just trying to anticipate clinician needs. So, for example, if you think that, this patient, might be coming in for a psychiatric condition or maybe you recognize that the patient came in and that triage was complaining of chest pain, then there might be a psych order set, which includes both which includes laboratory test results that are relevant for psychiatric patients, or a chest pain order set, which includes both both laboratory tests and interventions, like aspirin, that might be suggested.\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some challenges unique to machine learning in healthcare?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some challenges unique to machine learning in healthcare?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some challenges unique to machine learning in healthcare?', [\"I'll just stick to your independence. We hope. So what's unique about machine learning health care? I gave you already some hints at this. So first, health care is ultimately, unfortunately, about life or death decisions. Right? So we need robust algorithms that don't screw up. A prime example of this, which I'll tell you a little bit more about, in towards the end of the semester, is, from a major software error that occurred something like, 20, 30 years ago, in a, in an x-ray type device where an overwhelming amount of radiation was exposed to a patient just because of a software overflow problem, a bug. And, of course, that resulted in a number of patients dying. So that was a software error from decades ago where there was no machine learning in the loop. And as a result of that and similar types of disasters, including in the space industry, in airplanes, and so on, led to a whole area of research in computer science in formal methods. And how do we design computer algorithms that can check that a piece of software would do what it's supposed to do and will not make and and that there are no bugs in it? But now that we're going to start to bring data and machine learning algorithms into the picture, we are really suffering for lack of good tools for doing similar formal checking of our algorithms and their behavior. And so this is going to be really important in the future decade as machine learning gets deployed, not just in settings like health care, but also in other settings of life and death such as in autonomous driving. And it's something that we'll we'll we'll touch on throughout the semester.\", \"I'll just stick to your independence. We hope. So what's unique about machine learning health care? I gave you already some hints at this. So first, health care is ultimately, unfortunately, about life or death decisions. Right? So we need robust algorithms that don't screw up. A prime example of this, which I'll tell you a little bit more about, in towards the end of the semester, is, from a major software error that occurred something like, 20, 30 years ago, in a, in an x-ray type device where an overwhelming amount of radiation was exposed to a patient just because of a software overflow problem, a bug. And, of course, that resulted in a number of patients dying. So that was a software error from decades ago where there was no machine learning in the loop. And as a result of that and similar types of disasters, including in the space industry, in airplanes, and so on, led to a whole area of research in computer science in formal methods. And how do we design computer algorithms that can check that a piece of software would do what it's supposed to do and will not make and and that there are no bugs in it? But now that we're going to start to bring data and machine learning algorithms into the picture, we are really suffering for lack of good tools for doing similar formal checking of our algorithms and their behavior. And so this is going to be really important in the future decade as machine learning gets deployed, not just in settings like health care, but also in other settings of life and death such as in autonomous driving. And it's something that we'll we'll we'll touch on throughout the semester.\", \"And so the next two lectures after today are going to focus on what health care is really like and what is the health care data that's created by the practice of health care like. We want you to get intuition for how to formalize machine learning challenges as health care problems. And that formalization step is often the most tricky and something that you'll spend a lot of time thinking through as part of your problem sets. Not all machine learning algorithms are equally useful. And so one theme that I'll return to throughout the semester is that despite the fact that deep learning is good for many speech recognition and computer vision problems, it actually isn't the best match to many problems in health care. And you'll explore that OSHA is part of your problem sets or at least one of them. And we want you to understand also the subtleties in robustly and safely deploying machine learning algorithms. Now more broadly, this is a young field. So for example, there just recently, just about 3 years ago, was created the first conference on machine learning in health care by that name. And new publication venues are being created every single day by Nature, Landsat, and and also machine learning journals for publishing research on machine learning healthcare. Because of some of the issues we talked about, like access to data and not very good benchmarks, reproducibility has been a major challenge. And this is, again, something that the field is only now starting to really grapple with. And so as part of this course, also many of you are going to be are currently PhD students or will soon be PhD students. We're going to think through what are some of the challenges for the research field. What are some of the open problems that you might wanna work on either during your PhD or during your future career?\"])\n",
      "calling <function ContentRetriever.search at 0x000001E868627BA0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some examples of publicly available healthcare datasets?')\n",
      "calling <function ContentRetriever.retrieve at 0x000001E8686277E0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some examples of publicly available healthcare datasets?', 3)\n",
      "calling <function ContentRetriever.complete at 0x000001E8686276A0> with (<__main__.ContentRetriever object at 0x000001E8676253D0>, 'What are some examples of publicly available healthcare datasets?', [\"And, of course, also medications that are being prescribed as as it goes. And so this is a wealth of data that now one could use to try to study at least study in a very narrow setting of intensive care unit how machine learning could be used in that in that location. And I don't wanna underemphasize the importance of this database, both through this course and to the broader field. This is really the only publicly available electronic medical record dataset of any reasonable size in the whole world. And it was created here at MIT. And we'll be using it extensively in our homework assignments as a result. There are other datasets that aren't publicly available, but which have been gathered by by industry. And one prime example is the Truven MarketScan database, which is which was created by a company called Truven, which was later acquired by IBM, as I'll tell you about more in a few minutes. Now this data, and there are many competing companies that that have similar datasets, is created not from electronic medical records, but rather from typically, it's created from insurance claims. So every time you go to see a doctor, there's usually some record of that that is associated to the billing of that visit. So your provider will send a a bill to your health insurance saying basically what happened, so what procedures were performed, providing diagnoses that are used to justify the cost of those procedures and tests. And from that data, you now get a holistic view, a longitudinal view, of what's happened to that patient's health. And then there's a lot of money that passes behind the scenes between insurers and hospitals to corporate companies such as Truven, which collect that data and then resell it for research purposes. And one of the biggest purchasers of data like this is the pharmaceutical industry. So this data, unfortunately, is not usually publicly available, and that's actually a big problem both in US and elsewhere.\", \"And, of course, also medications that are being prescribed as as it goes. And so this is a wealth of data that now one could use to try to study at least study in a very narrow setting of intensive care unit how machine learning could be used in that in that location. And I don't wanna underemphasize the importance of this database, both through this course and to the broader field. This is really the only publicly available electronic medical record dataset of any reasonable size in the whole world. And it was created here at MIT. And we'll be using it extensively in our homework assignments as a result. There are other datasets that aren't publicly available, but which have been gathered by by industry. And one prime example is the Truven MarketScan database, which is which was created by a company called Truven, which was later acquired by IBM, as I'll tell you about more in a few minutes. Now this data, and there are many competing companies that that have similar datasets, is created not from electronic medical records, but rather from typically, it's created from insurance claims. So every time you go to see a doctor, there's usually some record of that that is associated to the billing of that visit. So your provider will send a a bill to your health insurance saying basically what happened, so what procedures were performed, providing diagnoses that are used to justify the cost of those procedures and tests. And from that data, you now get a holistic view, a longitudinal view, of what's happened to that patient's health. And then there's a lot of money that passes behind the scenes between insurers and hospitals to corporate companies such as Truven, which collect that data and then resell it for research purposes. And one of the biggest purchasers of data like this is the pharmaceutical industry. So this data, unfortunately, is not usually publicly available, and that's actually a big problem both in US and elsewhere.\", \"And then there's a lot of money that passes behind the scenes between insurers and hospitals to corporate companies such as Truven, which collect that data and then resell it for research purposes. And one of the biggest purchasers of data like this is the pharmaceutical industry. So this data, unfortunately, is not usually publicly available, and that's actually a big problem both in US and elsewhere. It's a big obstacle to research in this field that only people who have 1,000,000 of dollars to pay for it really get access to it. It's something that I'm gonna return to throughout the semester. It's, again, something where I think policy can make a big difference. But luckily, here at MIT, the story is gonna be a bit different. So thanks to the MIT IBM Watson AI Lab. MIT has a close relationship with IBM. And fingers crossed, it looks like we'll get access to this database for our homework and projects for this semester. Now there are a lot a lot of other initiatives that are that are creating large datasets. A really important example here in the US is President Obama's Precision Medicine Initiative, which has since been renamed to the All of Us Initiative. And this initiative is creating a dataset of 1,000,000 patients drawn in a representative manner from across the United States to capture patients, both poor and rich, patients who are healthy and have chronic disease, with a goal of trying to create a research database where all of us and other people, both inside and outside the US, could do research to make medical discoveries. And this will include data such as data from a baseline health exam where the typical vitals are taken, blood blood is drawn. It'll combine data of the previous tube types I've mentioned, including both data from electronic medical records and health insurance claims. And then a lot of this work is also happening here in Boston. So right across the street at the Broad Institute, there's a team which is creating all of the software infrastructure to accommodate this data. And there are a large number of recruitment sites here in the boss broader Boston area where patients or any one of you really could go and volunteer to be part of the study.\"])\n"
     ]
    }
   ],
   "source": [
    "for chunk_size, overlap in chunk_configs:\n",
    "    print(f\"\\nEvaluating chunk size: {chunk_size}s with overlap: {overlap}s\")\n",
    "    table_name = f\"{course_name}_video_{chunk_size}_{overlap}\"\n",
    "    retriever = ContentRetriever(snow_session, table_name)\n",
    "    tru_app = TruCustomApp(\n",
    "        retriever,\n",
    "        app_name=\"Video Retriever\",\n",
    "        app_version=f's_{chunk_size}_o_{overlap}',\n",
    "        feedbacks=feedbacks,\n",
    "    )\n",
    "\n",
    "    with tru_app as recording:\n",
    "        for question in eval_questions:\n",
    "            response = retriever.search(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
